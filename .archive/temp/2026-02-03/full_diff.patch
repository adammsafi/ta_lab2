diff --git a/.github/.release-please-manifest.json b/.github/.release-please-manifest.json
new file mode 100644
index 0000000..466df71
--- /dev/null
+++ b/.github/.release-please-manifest.json
@@ -0,0 +1,3 @@
+{
+  ".": "0.1.0"
+}
diff --git a/.github/release-please-config.json b/.github/release-please-config.json
new file mode 100644
index 0000000..5e20aea
--- /dev/null
+++ b/.github/release-please-config.json
@@ -0,0 +1,12 @@
+{
+  "release-type": "python",
+  "package-name": "ta_lab2",
+  "changelog-path": "CHANGELOG.md",
+  "skip-github-release": true,
+  "include-v-in-tag": true,
+  "bump-minor-pre-major": true,
+  "extra-files": [
+    "pyproject.toml",
+    "src/ta_lab2/__init__.py"
+  ]
+}
diff --git a/.github/workflows/publish-release.yml b/.github/workflows/publish-release.yml
new file mode 100644
index 0000000..877728c
--- /dev/null
+++ b/.github/workflows/publish-release.yml
@@ -0,0 +1,32 @@
+      - name: Generate release notes
+        id: notes
+        run: |
+          VERSION="${GITHUB_REF_NAME}"   # e.g., v0.1.0
+          DATE="$(date +'%B %e, %Y')"
+
+          cat > notes.md <<'EOF'
+## ðŸš€ **ta_lab2 v0.1.0 â€” First Major Release**
+
+### ðŸ§­ Overview
+This release marks the first full, modular version of **ta_lab2**, a Python toolkit for technical analysis and regime detection.
+It introduces a unified configuration system, expanded feature library, and an advanced volatility engine designed for large-scale analytics.
+
+---
+
+### âš™ï¸ Core Refactor
+- Moved configuration logic from `src/ta_lab2/config.py` â†’ root-level `config.py`.
+- Added `project_root()` to auto-detect the repo root for path normalization.
+- Centralized settings in `config/default.yaml` for portable project setup.
+
+---
+
+### ðŸ“¦ Packaging & CLI
+... (all your Markdown body above) ...
+
+---
+
+**Tag:** ${{ github.ref_name }}
+**Release Date:** ${DATE}
+EOF
+
+          echo "notes_file=notes.md" >> $GITHUB_OUTPUT
diff --git a/.github/workflows/release-please.yml b/.github/workflows/release-please.yml
new file mode 100644
index 0000000..474c5c5
--- /dev/null
+++ b/.github/workflows/release-please.yml
@@ -0,0 +1,21 @@
+name: release-please
+
+on:
+  push:
+    branches: [ main ]
+  workflow_dispatch:
+
+permissions:
+  contents: write
+  pull-requests: write
+
+jobs:
+  release-please:
+    runs-on: ubuntu-latest
+    steps:
+      - name: Run release-please
+        uses: google-github-actions/release-please-action@v4
+        with:
+          command: manifest
+          config-file: .github/release-please-config.json
+          manifest-file: .github/.release-please-manifest.json
diff --git a/changelog.md b/changelog.md
new file mode 100644
index 0000000..64a2fe2
--- /dev/null
+++ b/changelog.md
@@ -0,0 +1,48 @@
+# ðŸ§¾ Changelog
+
+All notable changes to **ta_lab2** will be documented here.
+
+---
+
+## [0.1.0] - 2025-11-01
+### ðŸŽ¯ Overview
+First major update of `ta_lab2`: introduces a modular configuration system, full volatility suite, and technical indicator + correlation modules.
+
+---
+
+### âš™ï¸ Core Refactor
+- Moved configuration logic from `src/ta_lab2/config.py` to top-level `config.py`.
+- Added path resolution via `project_root()` for robust portability.
+- Introduced root-level YAML file (`config/default.yaml`) for user settings.
+
+### ðŸ“¦ Packaging & CLI
+- Added proper `pyproject.toml` build system (setuptools â‰¥ 68).
+- Added `ta-lab2` command-line entry point via `[project.scripts]`.
+- CLI now loads settings from root-level config and runs the BTC pipeline modularly.
+
+### ðŸ“ˆ Features
+- Introduced **technical indicators** (`rsi`, `macd`, `stoch_kd`, `bollinger`, `adx`, `obv`, `mfi`).
+- Added **correlation utilities** (`acf`, `pacf_yw`, `rolling_autocorr`, `xcorr`).
+
+### ðŸ“Š Volatility Module Overhaul
+- Rewrote `vol.py` to include:
+  - Parkinson, Rogersâ€“Satchell, and Garmanâ€“Klass volatility estimators.
+  - Rolling realized volatility (annualized and multi-window).
+  - Rolling historical volatility from log or percent returns.
+  - Unified `add_volatility_features()` orchestrator for one-call analysis.
+
+### ðŸ§  Pipeline Improvements
+- Simplified `run_btc_pipeline()` â€” removed hardcoded paths, made fully callable.
+- Prepares project for composable feature + regime detection pipeline.
+
+### ðŸ§ª Developer Experience
+- Added dev dependencies: `pytest`, `mypy`, `ruff`, `hypothesis`, `pytest-benchmark`.
+- Normalized project structure for testing and CI/CD compatibility.
+
+---
+
+## [Unreleased]
+- Add rolling correlation matrices
+- Implement feature-store export
+- Integrate regime clustering and labeling
+- Add unit tests for volatility and indicator modules
diff --git a/config.py b/config.py
new file mode 100644
index 0000000..7c8d64f
--- /dev/null
+++ b/config.py
@@ -0,0 +1,241 @@
+# config.py
+"""
+Central configuration loader for ta_lab2.
+
+- Reads config/default.yaml (or any YAML path)
+- Normalizes paths against project root
+- Converts nested mappings into typed dataclasses
+- Supports safe forward-compatibility (unknown keys ignored)
+
+Note:
+- If `data_csv` or `out_dir` are inside the project root, we now store them
+  as **relative paths** (so `(project_root() / cfg.data_csv)` works cleanly).
+  If they are outside the project, we keep them absolute.
+"""
+
+from __future__ import annotations
+from dataclasses import dataclass, field
+from pathlib import Path
+from typing import Any
+import os
+import yaml
+
+
+# -----------------------------
+# Small, typed sub-configs
+# -----------------------------
+@dataclass
+class CalendarSettings:
+    """Calendar & seasonality feature options."""
+    expand_columns: list[str] = field(default_factory=lambda: ["timestamp"])
+    add_moon: bool = True
+    us_week_start_sunday: bool = True
+
+
+@dataclass
+class TrendSettings:
+    """Slope-based trend labeling settings."""
+    window: int = 21
+    mode: str = "flat_zone"      # "binary" | "three_state" | "flat_zone"
+    flat_thresh: float = 0.0     # 0 => auto percentile threshold
+
+
+@dataclass
+class SegmentsSettings:
+    """Regime segmentation parameters."""
+    price_col: str = "close"
+    state_col: str = "trend_state"
+
+
+@dataclass
+class VolRealizedSettings:
+    """Range-based (realized) volatility estimators."""
+    estimators: list[str] = field(
+        default_factory=lambda: ["parkinson", "rogers_satchell", "garman_klass", "atr"]
+    )
+    windows: list[int] = field(default_factory=lambda: [10, 21, 50])
+
+
+@dataclass
+class VolHistoricalSettings:
+    """Return-based (historical) volatility parameters."""
+    modes: list[str] = field(default_factory=lambda: ["log", "pct"])
+    windows: list[int] = field(default_factory=lambda: [10, 21, 50])
+    annualize: bool = True
+
+
+@dataclass
+class VolatilitySettings:
+    """Combined realized + historical volatility settings."""
+    realized: VolRealizedSettings = field(default_factory=VolRealizedSettings)
+    historical: VolHistoricalSettings = field(default_factory=VolHistoricalSettings)
+
+
+@dataclass
+class PipelineSettings:
+    """Global pipeline options."""
+    resample: str | None = None           # e.g., "1H", "1D"
+    returns_modes: list[str] = field(default_factory=lambda: ["log", "pct"])
+    returns_windows: list[int] = field(default_factory=lambda: [10, 21, 50])
+
+
+# -----------------------------
+# Top-level Settings
+# -----------------------------
+@dataclass
+class Settings:
+    """
+    Root configuration object for ta_lab2.
+    This dataclass holds everything parsed from YAML.
+    """
+
+    # Required
+    data_csv: str
+
+    # Optional
+    out_dir: str = "artifacts"
+    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100, 200])
+
+    # Nested groups (dictionaries or dataclasses)
+    indicators: dict[str, Any] | None = None
+    correlations: dict[str, Any] | None = None
+    volatility: VolatilitySettings = field(default_factory=VolatilitySettings)
+    calendar: CalendarSettings = field(default_factory=CalendarSettings)
+    trend: TrendSettings = field(default_factory=TrendSettings)
+    segments: SegmentsSettings = field(default_factory=SegmentsSettings)
+    pipeline: PipelineSettings = field(default_factory=PipelineSettings)
+
+
+# -----------------------------
+# Helpers
+# -----------------------------
+def project_root(start: str | Path | None = None) -> Path:
+    """
+    Walk upward from 'start' (or this file) until a folder containing pyproject.toml is found.
+    """
+    cur = Path(start or __file__).resolve()
+    for p in [cur, *cur.parents]:
+        if (p / "pyproject.toml").exists():
+            return p
+    return Path(__file__).resolve().parent
+
+
+def _as(obj: Any, cls: Any):
+    """
+    Minimal recursive 'constructor' to turn nested dicts into dataclass instances.
+    Ignores unknown keys so YAML can be slightly ahead of code.
+    """
+    if obj is None or isinstance(obj, cls):
+        return obj if obj is not None else cls()
+    if isinstance(obj, dict):
+        hints = {f.name for f in cls.__dataclass_fields__.values()}
+        kwargs = {k: v for k, v in obj.items() if k in hints}
+        for name, field_info in cls.__dataclass_fields__.items():
+            typ = field_info.type
+            if isinstance(kwargs.get(name), dict) and hasattr(typ, "__dataclass_fields__"):
+                kwargs[name] = _as(kwargs[name], typ)
+        return cls(**kwargs)
+    return cls()
+
+
+def load_settings(yaml_path: str | Path = "configs/default.yaml") -> Settings:
+    """
+    Load YAML into Settings, normalize paths relative to project root,
+    and coerce nested mappings into typed dataclasses.
+    Also merges environment overrides if set (DATA_CSV, OUT_DIR).
+
+    Gracefully accepts either 'config/default.yaml' or 'configs/default.yaml'.
+    """
+    root = project_root()
+    yml = Path(yaml_path)
+    p = (root / yml).resolve() if not yml.is_absolute() else yml
+
+    if not p.exists():
+        # Try swapping 'configs' <-> 'config'
+        parts = list(yml.parts)
+        if "configs" in parts:
+            parts[parts.index("configs")] = "config"
+        elif "config" in parts:
+            parts[parts.index("config")] = "configs"
+        alt = (root / Path(*parts)).resolve()
+        if alt.exists():
+            p = alt
+        else:
+            raise FileNotFoundError(f"Configuration file not found: {p}")
+
+    data = yaml.safe_load(p.read_text(encoding="utf-8")) | {}
+
+    # --- Environment variable overrides ---
+    if os.getenv("DATA_CSV"):
+        data["data_csv"] = os.getenv("DATA_CSV")
+    if os.getenv("OUT_DIR"):
+        data["out_dir"] = os.getenv("OUT_DIR")
+
+    # --- Top-level scalars ---
+    data_csv = data.get("data_csv")
+    if not data_csv:
+        raise ValueError("`data_csv` is required in config/default.yaml")
+
+    out_dir = data.get("out_dir", "artifacts")
+    ema_windows = data.get("ema_windows", [21, 50, 100, 200])
+    indicators = data.get("indicators")
+    correlations = data.get("correlations")
+
+    # --- Structured sections ---
+    volatility = _as(data.get("volatility"), VolatilitySettings)
+    calendar = _as(data.get("calendar"), CalendarSettings)
+    trend = _as(data.get("trend"), TrendSettings)
+    segments = _as(data.get("segments"), SegmentsSettings)
+    pipeline = _as(data.get("pipeline"), PipelineSettings)
+
+    # --- Build Settings object ---
+    settings = Settings(
+        data_csv=str(data_csv),
+        out_dir=str(out_dir),
+        ema_windows=list(ema_windows),
+        indicators=indicators,
+        correlations=correlations,
+        volatility=volatility,
+        calendar=calendar,
+        trend=trend,
+        segments=segments,
+        pipeline=pipeline,
+    )
+
+    # --- Normalize paths (now relative-if-inside-root) ---
+    dc = Path(settings.data_csv)
+    pabs_dc = (root / dc).resolve() if not dc.is_absolute() else dc.resolve()
+    try:
+        # Store relative when under project root (fixes tests expecting root / cfg.data_csv)
+        settings.data_csv = pabs_dc.relative_to(root).as_posix()
+    except ValueError:
+        # Outside project root -> keep absolute
+        settings.data_csv = str(pabs_dc)
+
+    od = Path(settings.out_dir)
+    pabs_od = (root / od).resolve() if not od.is_absolute() else od.resolve()
+    try:
+        settings.out_dir = pabs_od.relative_to(root).as_posix()
+    except ValueError:
+        settings.out_dir = str(pabs_od)
+
+    return settings
+
+
+def preview_settings(settings: Settings) -> None:
+    """
+    Pretty-print a summary of the current config for debugging / CLI startup.
+    """
+    import pprint
+    print("=== ta_lab2 Configuration ===")
+    flat = {
+        "data_csv": settings.data_csv,
+        "out_dir": settings.out_dir,
+        "ema_windows": settings.ema_windows,
+        "returns_modes": settings.pipeline.returns_modes,
+        "returns_windows": settings.pipeline.returns_windows,
+    }
+    pprint.pprint(flat)
+    print("Nested groups:")
+    for grp in ["volatility", "calendar", "trend", "segments"]:
+        print(f"  - {grp}: {getattr(settings, grp)}")
diff --git a/configs/default.yaml b/configs/default.yaml
new file mode 100644
index 0000000..b3fe2e2
--- /dev/null
+++ b/configs/default.yaml
@@ -0,0 +1,124 @@
+# configs/default.yaml
+# -----------------------------------------------------------------------------
+# ta_lab2 default configuration
+# - Keeps legacy knobs (adx/obv/mfi, bar-to-bar return settings, etc.)
+# - Adds explicit sections for volatility, rolling vol, EMA slopes/helpers,
+#   regime/comovement, and segment building.
+# - All keys line up with the shims + pipeline so callers can override selectively.
+# -----------------------------------------------------------------------------
+
+# --- IO / paths ---
+data_csv: data/btcusd.csv         # relative to repo root; tests place a placeholder file here
+out_dir: artifacts                # where to write plots/exports (if/when used)
+
+# --- Sampling ---
+resample: null                    # e.g. "1H", "4H", "1D", or null to keep native frequency
+
+# --- Core price columns used across pipeline ---
+price_cols: [open, high, low, close]
+
+# --- EMA windows (used for trend/segments/comovement) ---
+ema_windows: [21, 50, 100, 200]
+
+# --- Indicators (all optional; pipeline only joins what is enabled) ---
+indicators:
+  enabled: [rsi, macd, bollinger, adx, obv, mfi]  # restore full list
+  rsi:
+    period: 14
+    price_col: close
+  macd:
+    fast: 12
+    slow: 26
+    signal: 9
+    price_col: close
+  bollinger:
+    window: 20
+    stdev: 2
+    price_col: close
+  adx:
+    periods: [14]              # legacy support; vectorized internally
+  obv: true                     # boolean toggle; uses volume + price
+  mfi:
+    periods: [14]               # Money Flow Index windows
+
+# --- Bar-to-bar returns (shims accept legacy kwargs) ---
+bar_to_bar:
+  round_places: 6
+  direction: newest_top         # legacy-friendly default
+  open_col: open
+  close_col: close
+  pct:
+    cols: []                    # if empty, pipeline will compute for price_cols + ["close-open"] when present
+    extra_cols: []              # "range" is auto-added by pipeline when available
+  log:
+    cols: []                    # same behavior as pct
+    extra_cols: []
+    prefix: _log_delta          # legacy prefix kept
+    add_intraday: true          # keep old behavior
+
+# --- Rolling returns (used for realized volatility) ---
+returns:
+  modes: [log, pct]             # compute both log and pct by default
+  windows: [10, 21, 50]         # short/mid/long examples
+
+# --- Single-bar + Parkinson/RS/GK + ATR (vectorized) ---
+volatility:
+  atr:
+    periods: [14]
+  parkinson: true               # high/low based
+  rogers_satchell: true         # aka RS
+  garman_klass: true            # aka GK
+
+# --- Realized volatility from returns (annualized) ---
+rolling_vol:
+  price_col: close
+  modes: [log, pct]
+  windows: [10, 21, 50]
+  annualize: true
+  direction: newest_top
+
+# --- EMA derivatives & helpers ---
+ema:
+  slopes:
+    d1: true
+    d2: true
+    round_places: 6
+    direction: newest_top
+    overwrite: false
+  helpers:
+    scale: bps                   # provides *_bps helper cols for comovement/segments
+
+# --- Regime detection via EMA co-movement ---
+regimes:
+  comovement:
+    periods: [21, 50, 100, 200]
+    close_col: close
+    return_col: close_pct_delta  # produced by bar_to_bar pct shim
+    direction: newest_top
+
+# --- Segments from EMA slope sign-flips (thin wrapper around features.segments) ---
+segments:
+  fields: [close]                # base field(s) to build EMA ladders for
+  periods: [21, 50, 100, 200]
+  date_col: timestamp
+  scale: bps
+  direction: newest_top
+  ema_name_fmt: "{field}_ema_{period}"
+
+# --- Pipeline-level defaults / toggles (nothing removed) ---
+pipeline:
+  resample: null                 # overrides top-level resample if provided
+  returns_modes: [log, pct]
+  returns_windows: [10, 21, 50]
+  # Stage toggles (set false to skip stage)
+  do_calendar: true
+  do_indicators: true
+  do_returns: true
+  do_volatility: true
+  do_ema: true
+  do_regimes: true
+  do_segments: true
+
+# --- Output / labeling ---
+labels:
+  trend_label_col: trend_state   # column where regime label is stored
diff --git a/data/btcusd.csv b/data/btcusd.csv
new file mode 100644
index 0000000..7420906
--- /dev/null
+++ b/data/btcusd.csv
@@ -0,0 +1 @@
+timestamp,open,high,low,close,volume
diff --git a/diff.txt b/diff.txt
new file mode 100644
index 0000000..91280df
--- /dev/null
+++ b/diff.txt
@@ -0,0 +1,863 @@
+diff --git a/config.py b/config.py
+new file mode 100644
+index 0000000..d511080
+--- /dev/null
++++ b/config.py
+@@ -0,0 +1,41 @@
++# config.py (at repo root)
++from __future__ import annotations
++from dataclasses import dataclass, field
++from pathlib import Path
++from typing import Any
++import yaml
++
++@dataclass
++class Settings:
++    # required
++    data_csv: str
++    # optional
++    out_dir: str = "out"
++    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100])
++    resample: dict[str, Any] = field(default_factory=lambda: {"weekly": "W-SUN", "monthly": "MS"})
++    indicators: dict[str, Any] | None = None
++    correlations: dict[str, Any] | None = None
++
++def project_root(start: str | Path | None = None) -> Path:
++    """Walk up from 'start' (or this file) until we find a folder containing pyproject.toml."""
++    cur = Path(start or __file__).resolve()
++    for p in [cur, *cur.parents]:
++        if (p / "pyproject.toml").exists():
++            return p
++    # fallback: repo root is parent of this file
++    return Path(__file__).resolve().parent
++
++def load_settings(yaml_path: str | Path) -> Settings:
++    """Load YAML into Settings, then normalize relative paths against the project root."""
++    root = project_root()
++    p = (root / yaml_path).resolve() if not Path(yaml_path).is_absolute() else Path(yaml_path)
++    data = yaml.safe_load(p.read_text(encoding="utf-8")) or {}
++
++    # Build Settings
++    s = Settings(**data)
++
++    # Normalize paths (make absolute, anchored to repo root)
++    s.data_csv = str((root / s.data_csv).resolve()) if not Path(s.data_csv).is_absolute() else s.data_csv
++    s.out_dir  = str((root / s.out_dir).resolve())  if not Path(s.out_dir).is_absolute()  else s.out_dir
++
++    return s
+diff --git a/config/default.yaml b/config/default.yaml
+new file mode 100644
+index 0000000..ea337c4
+--- /dev/null
++++ b/config/default.yaml
+@@ -0,0 +1,23 @@
++data_csv: data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv
++out_dir: out
++ema_windows: [21, 50, 100]
++resample:
++  weekly: "W-SUN"
++  monthly: "MS"
++
++indicators:
++  rsi: [14, 28]
++  macd: {fast: 12, slow: 26, signal: 9}
++  stoch: {k: 14, d: 3}
++  bollinger: {window: 20, n_sigma: 2}
++  atr: [14]
++  adx: [14]
++  obv: true
++  mfi: [14]
++
++correlations:
++  acf: {nlags: 40, on: "returns"}   # "returns" or "close"
++  pacf: {nlags: 20, on: "returns"}
++  rolling_autocorr:
++    - {lag: 1, window: 100, on: "returns"}
++    - {lag: 5, window: 100, on: "returns"}
+diff --git a/pyproject.toml b/pyproject.toml
+index 9a6a43d..96032a0 100644
+--- a/pyproject.toml
++++ b/pyproject.toml
+@@ -1,21 +1,34 @@
+- [project]
+- name = "ta_lab2"
+- version = "0.1.0"
+- requires-python = ">=3.10"
+- dependencies = [
+--    # your runtime deps here
+-+    "pandas",
+-+    "pyyaml",
+- ]
+-
+-+[project.optional-dependencies]
+-+dev = [
+-+    "pytest",
+-+    "mypy",
+-+    "ruff",
+-+    "pytest-benchmark",
+-+    "hypothesis",
+-+]
+-+
+-+[project.scripts]
+-+ta-lab2 = "ta_lab2.cli:main"
++[build-system]
++requires = ["setuptools>=68", "wheel"]
++build-backend = "setuptools.build_meta"
++
++[project]
++name = "ta_lab2"
++version = "0.1.0"
++description = "Technical analysis & regime-detection toolkit"
++readme = "README.md"
++requires-python = ">=3.10"
++dependencies = [
++  "pandas",
++  "pyyaml",
++]
++
++[project.optional-dependencies]
++dev = [
++  "pytest",
++  "mypy",
++  "ruff",
++  "pytest-benchmark",
++  "hypothesis",
++]
++
++[project.scripts]
++ta-lab2 = "ta_lab2.cli:main"
++
++# Tell setuptools to find packages under src/
++[tool.setuptools.packages.find]
++where = ["src"]
++
++# Also install the top-level config.py module (so `from config import ...` works)
++[tool.setuptools]
++py-modules = ["config"]
+diff --git a/src/ta_lab2/__init__.py b/src/ta_lab2/__init__.py
+index 7840e43..1bdc623 100644
+--- a/src/ta_lab2/__init__.py
++++ b/src/ta_lab2/__init__.py
+@@ -1,5 +1,4 @@
+--# current content
+-+from .regimes.run_btc_pipeline import run_btc_pipeline
+-+
+-+__all__ = ["run_btc_pipeline"]
+-+__version__ = "0.1.0"
++from .regimes.run_btc_pipeline import run_btc_pipeline
++
++__all__ = ["run_btc_pipeline"]
++__version__ = "0.1.0"
+diff --git a/src/ta_lab2/cli.py b/src/ta_lab2/cli.py
+index 3131e8d..1b8350c 100644
+--- a/src/ta_lab2/cli.py
++++ b/src/ta_lab2/cli.py
+@@ -1,27 +1,39 @@
+ from __future__ import annotations
+ import argparse
+ from pathlib import Path
+-from .config import load_settings, project_root
+-from .regimes.run_btc_pipeline import run_btc_pipeline
++
++# Import from root-level config.py, not from ta_lab2.config
++from config import load_settings, project_root
++from ta_lab2.regimes.run_btc_pipeline import run_btc_pipeline
++
+
+ def main(argv: list[str] | None = None) -> int:
+     ap = argparse.ArgumentParser(prog="ta-lab2", description="ta_lab2 CLI")
+-    ap.add_argument("--config", "-c", default="configs/default.yaml",
+-                    help="Path to YAML config relative to project root")
++    ap.add_argument(
++        "--config", "-c",
++        default="config/default.yaml",
++        help="Path to YAML config relative to project root (default: config/default.yaml)"
++    )
+     args = ap.parse_args(argv)
+
+-    root = project_root()
+-    cfg_path = (root / args.config).resolve()
+-    settings = load_settings(cfg_path)
++    # Load settings from YAML via the root-level config.py
++    settings = load_settings(args.config)
+
+-    csv = (root / settings.data_csv).resolve()
+-    out_dir = (root / settings.out_dir).resolve()
++    # Resolve absolute paths for input and output
++    csv = Path(settings.data_csv)
++    out_dir = Path(settings.out_dir)
++
++    # Run main pipeline
++    result = run_btc_pipeline(
++        csv_path=csv,
++        out_dir=out_dir,
++        ema_windows=settings.ema_windows,
++        resample=settings.resample
++    )
+
+-    result = run_btc_pipeline(csv_path=csv, out_dir=out_dir,
+-                              ema_windows=settings.ema_windows,
+-                              resample=settings.resample)
+     print("Pipeline complete:", result)
+     return 0
+
++
+ if __name__ == "__main__":
+     raise SystemExit(main())
+diff --git a/src/ta_lab2/config.py b/src/ta_lab2/config.py
+deleted file mode 100644
+index b1797bd..0000000
+--- a/src/ta_lab2/config.py
++++ /dev/null
+@@ -1,24 +0,0 @@
+-from __future__ import annotations
+-from dataclasses import dataclass, field
+-from pathlib import Path
+-import yaml
+-
+-@dataclass
+-class Settings:
+-    data_csv: str
+-    out_dir: str = "out"
+-    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100])
+-    resample: dict = field(default_factory=lambda: {"weekly": "W-SUN", "monthly": "MS"})
+-
+-def load_settings(path: str | Path) -> Settings:
+-    p = Path(path)
+-    data = yaml.safe_load(p.read_text(encoding="utf-8"))
+-    return Settings(**data)
+-
+-def project_root(start: str | Path | None = None) -> Path:
+-    # walk up until we find pyproject.toml
+-    cur = Path(start or __file__).resolve()
+-    for ancestor in [cur, *cur.parents]:
+-        if (ancestor / "pyproject.toml").exists():
+-            return ancestor
+-    return cur  # fallback
+diff --git a/src/ta_lab2/config/default.yaml b/src/ta_lab2/config/default.yaml
+deleted file mode 100644
+index 4da5e13..0000000
+--- a/src/ta_lab2/config/default.yaml
++++ /dev/null
+@@ -1,9 +0,0 @@
+-# Paths are relative to the project root (where pyproject.toml lives)
+-data_csv: data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv
+-out_dir: out
+-
+-# Pipeline parameters (exampleâ€”extend as your code supports)
+-ema_windows: [21, 50, 100]
+-resample:
+-  weekly: "W-SUN"
+-  monthly: "MS"
+\ No newline at end of file
+diff --git a/src/ta_lab2/features/__init__.py b/src/ta_lab2/features/__init__.py
+index 9fa317e..b169b79 100644
+--- a/src/ta_lab2/features/__init__.py
++++ b/src/ta_lab2/features/__init__.py
+@@ -2,3 +2,23 @@ from .calendar import expand_datetime_features_inplace
+ from .ema import add_ema_columns, add_ema_d1, add_ema_d2
+ from .returns import add_returns
+ from .vol import add_atr
++
++# New imports for technical indicators
++from .indicators import rsi, macd, stoch_kd, bollinger, atr, adx, obv, mfi
++
++# New imports for correlation-based features
++from .correlation import acf, pacf_yw, rolling_autocorr, xcorr
++
++
++__all__ = [
++    # Core features
++    "expand_datetime_features_inplace",
++    "add_ema_columns", "add_ema_d1", "add_ema_d2",
++    "add_returns", "add_atr",
++
++    # Technical indicators
++    "rsi", "macd", "stoch_kd", "bollinger", "atr", "adx", "obv", "mfi",
++
++    # Correlation utilities
++    "acf", "pacf_yw", "rolling_autocorr", "xcorr",
++]
+diff --git a/src/ta_lab2/features/correlation.py b/src/ta_lab2/features/correlation.py
+new file mode 100644
+index 0000000..bd96500
+--- /dev/null
++++ b/src/ta_lab2/features/correlation.py
+@@ -0,0 +1,63 @@
++from __future__ import annotations
++import numpy as np
++import pandas as pd
++
++def acf(x: pd.Series, nlags: int = 40, demean: bool = True) -> pd.Series:
++    s = pd.Series(x).dropna().astype(float)
++    if len(s) == 0:
++        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="acf")
++    if demean:
++        s = s - s.mean()
++    var = (s**2).sum()
++    ac = [1.0]
++    for k in range(1, nlags + 1):
++        cov = (s.iloc[k:] * s.iloc[:-k]).sum()
++        ac.append(float(cov / var) if var != 0 else np.nan)
++    return pd.Series(ac, index=range(0, nlags + 1), name="acf")
++
++def pacf_yw(x: pd.Series, nlags: int = 20) -> pd.Series:
++    s = pd.Series(x).dropna().astype(float)
++    if len(s) == 0:
++        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="pacf")
++    s = s - s.mean()
++    # autocov sequence
++    gamma = np.array([
++        (s[:len(s)-k] @ s[k:]) / len(s) if k > 0 else (s @ s) / len(s)
++        for k in range(0, nlags+1)
++    ])
++    pac = np.zeros(nlags+1)
++    pac[0] = 1.0
++    phi = np.zeros((nlags+1, nlags+1))
++    var = gamma[0]
++    for k in range(1, nlags+1):
++        num = gamma[k] - np.sum(phi[k-1,1:k] * gamma[1:k][::-1])
++        den = var - np.sum(phi[k-1,1:k] * gamma[1:k])
++        phi[k,k] = num / den if den != 0 else np.nan
++        for j in range(1, k):
++            phi[k,j] = phi[k-1,j] - phi[k,k]*phi[k-1,k-j]
++        pac[k] = phi[k,k]
++    return pd.Series(pac, index=range(0, nlags+1), name="pacf")
++
++def rolling_autocorr(s: pd.Series, lag: int = 1, window: int = 100) -> pd.Series:
++    return s.rolling(window).corr(s.shift(lag)).rename(f"roll_ac_{lag}_{window}")
++
++def xcorr(a: pd.Series, b: pd.Series, max_lag: int = 20, demean: bool = True) -> pd.Series:
++    A = pd.Series(a).astype(float)
++    B = pd.Series(b).astype(float)
++    A, B = A.align(B, join="inner")
++    if len(A) == 0:
++        return pd.Series([np.nan]*(2*max_lag+1), index=range(-max_lag, max_lag+1), name="xcorr")
++    if demean:
++        A, B = A - A.mean(), B - B.mean()
++    var = np.sqrt((A**2).sum() * (B**2).sum())
++    vals = []
++    lags = range(-max_lag, max_lag + 1)
++    for k in lags:
++        if k < 0:
++            cov = (A[:k] * B[-k:]).sum()
++        elif k > 0:
++            cov = (A[k:] * B[:-k]).sum()
++        else:
++            cov = (A * B).sum()
++        vals.append(float(cov / var) if var != 0 else np.nan)
++    return pd.Series(vals, index=list(lags), name="xcorr")
+diff --git a/src/ta_lab2/features/indicators.py b/src/ta_lab2/features/indicators.py
+new file mode 100644
+index 0000000..a71a0a4
+--- /dev/null
++++ b/src/ta_lab2/features/indicators.py
+@@ -0,0 +1,94 @@
++from __future__ import annotations
++import numpy as np
++import pandas as pd
++
++# ---- helpers ----
++def _ema(s: pd.Series, span: int) -> pd.Series:
++    return s.ewm(span=span, adjust=False).mean()
++
++def _sma(s: pd.Series, window: int) -> pd.Series:
++    return s.rolling(window, min_periods=window).mean()
++
++def _tr(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:
++    prev_close = close.shift(1)
++    return pd.concat([
++        (high - low).abs(),
++        (high - prev_close).abs(),
++        (low - prev_close).abs()
++    ], axis=1).max(axis=1)
++
++# ---- indicators ----
++def rsi(close: pd.Series, window: int = 14) -> pd.Series:
++    delta = close.diff()
++    gain = delta.clip(lower=0)
++    loss = -delta.clip(upper=0)
++    avg_gain = gain.ewm(alpha=1/window, adjust=False).mean()
++    avg_loss = loss.ewm(alpha=1/window, adjust=False).mean()
++    rs = avg_gain / (avg_loss.replace(0, np.nan))
++    out = 100 - (100 / (1 + rs))
++    return out.rename(f"rsi_{window}")
++
++def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:
++    ema_fast = _ema(close, fast)
++    ema_slow = _ema(close, slow)
++    macd_line = ema_fast - ema_slow
++    signal_line = _ema(macd_line, signal)
++    hist = macd_line - signal_line
++    return pd.DataFrame({
++        f"macd_{fast}_{slow}": macd_line,
++        f"macd_signal_{signal}": signal_line,
++        f"macd_hist_{fast}_{slow}_{signal}": hist
++    })
++
++def stoch_kd(high: pd.Series, low: pd.Series, close: pd.Series, k: int = 14, d: int = 3) -> pd.DataFrame:
++    lowest = low.rolling(k, min_periods=k).min()
++    highest = high.rolling(k, min_periods=k).max()
++    k_line = 100 * (close - lowest) / (highest - lowest)
++    d_line = k_line.rolling(d, min_periods=d).mean()
++    return pd.DataFrame({f"stoch_k_{k}": k_line, f"stoch_d_{d}": d_line})
++
++def bollinger(close: pd.Series, window: int = 20, n_sigma: float = 2.0) -> pd.DataFrame:
++    ma = _sma(close, window)
++    std = close.rolling(window, min_periods=window).std()
++    upper = ma + n_sigma * std
++    lower = ma - n_sigma * std
++    bw = (upper - lower) / ma
++    return pd.DataFrame({
++        f"bb_ma_{window}": ma,
++        f"bb_up_{window}_{n_sigma}": upper,
++        f"bb_lo_{window}_{n_sigma}": lower,
++        f"bb_width_{window}": bw
++    })
++
++def atr(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
++    tr = _tr(high, low, close)
++    out = tr.rolling(window, min_periods=window).mean()
++    return out.rename(f"atr_{window}")
++
++def adx(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
++    up = high.diff()
++    dn = -low.diff()
++    plus_dm  = np.where((up > dn) and isinstance(up, pd.Series) and (up > 0), up, 0.0)
++    minus_dm = np.where((dn > up) and isinstance(dn, pd.Series) and (dn > 0), dn, 0.0)
++    tr = _tr(high, low, close)
++    atr_ = tr.rolling(window, min_periods=window).mean()
++    plus_di  = 100 * pd.Series(plus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
++    minus_di = 100 * pd.Series(minus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
++    dx = ((plus_di - minus_di).abs() / (plus_di + minus_di)) * 100
++    adx_ = dx.rolling(window, min_periods=window).mean()
++    return adx_.rename(f"adx_{window}")
++
++def obv(close: pd.Series, volume: pd.Series) -> pd.Series:
++    direction = np.sign(close.diff().fillna(0))
++    return (direction * volume).fillna(0).cumsum().rename("obv")
++
++def mfi(high: pd.Series, low: pd.Series, close: pd.Series, volume: pd.Series, window: int = 14) -> pd.Series:
++    tp = (high + low + close) / 3.0
++    raw = tp * volume
++    pos = raw.where(tp.diff() > 0, 0.0)
++    neg = raw.where(tp.diff() < 0, 0.0)
++    mr = pos.rolling(window, min_periods=window).sum() / (
++        neg.rolling(window, min_periods=window).sum().replace(0, np.nan)
++    )
++    out = 100 - (100 / (1 + mr))
++    return out.rename(f"mfi_{window}")
+diff --git a/src/ta_lab2/features/vol.py b/src/ta_lab2/features/vol.py
+index 64a9858..50a0575 100644
+--- a/src/ta_lab2/features/vol.py
++++ b/src/ta_lab2/features/vol.py
+@@ -1,15 +1,306 @@
+-
+-import pandas as pd
++# src/ta_lab2/features/vol.py
+ import numpy as np
++import pandas as pd
++from typing import Iterable, Literal, Sequence
+
+-def add_atr(df: pd.DataFrame, period: int = 14,
+-            high_col="high", low_col="low", close_col="close"):
++
++# =============================================================================
++# Single-bar realized volatility estimators
++# =============================================================================
++
++def add_atr(
++    df: pd.DataFrame,
++    period: int = 14,
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++) -> pd.DataFrame:
++    """
++    Average True Range (Wilder EMA smoothing).
++    """
+     high = df[high_col].astype(float)
+-    low  = df[low_col].astype(float)
++    low = df[low_col].astype(float)
+     close = df[close_col].astype(float)
+     prev_close = close.shift(1)
++
+     tr = (high - low).abs()
+     tr = np.maximum(tr, (high - prev_close).abs())
+     tr = np.maximum(tr, (low - prev_close).abs())
+-    df[f"atr_{period}"] = tr.ewm(alpha=1/period, adjust=False).mean()
++
++    df[f"atr_{period}"] = tr.ewm(alpha=1 / period, adjust=False).mean()
++    return df
++
++
++def add_parkinson_vol(
++    df: pd.DataFrame,
++    high_col: str = "high",
++    low_col: str = "low",
++    out_col: str = "vol_parkinson",
++) -> pd.DataFrame:
++    """
++    Ïƒ_P = sqrt( (1 / (4 * ln(2))) * (ln(H/L))^2 )
++    """
++    hl2 = np.log(df[high_col] / df[low_col]) ** 2
++    df[out_col] = np.sqrt((1.0 / (4.0 * np.log(2.0))) * hl2)
++    return df
++
++
++def add_rogers_satchell_vol(
++    df: pd.DataFrame,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++    out_col: str = "vol_rs",
++) -> pd.DataFrame:
++    """
++    Ïƒ_RS = sqrt( ln(H/C)ln(H/O) + ln(L/C)ln(L/O) )
++    """
++    term = (
++        np.log(df[high_col] / df[close_col]) * np.log(df[high_col] / df[open_col])
++        + np.log(df[low_col] / df[close_col]) * np.log(df[low_col] / df[open_col])
++    ).clip(lower=0)
++    df[out_col] = np.sqrt(term)
++    return df
++
++
++def add_garman_klass_vol(
++    df: pd.DataFrame,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++    out_col: str = "vol_gk",
++) -> pd.DataFrame:
++    """
++    Ïƒ_GK = sqrt( 0.5(ln(H/L))^2 - (2ln2 - 1)(ln(C/O))^2 )
++    """
++    term1 = 0.5 * (np.log(df[high_col] / df[low_col])) ** 2
++    term2 = (2 * np.log(2) - 1) * (np.log(df[close_col] / df[open_col])) ** 2
++    inner = term1 - term2
++    df[out_col] = np.sqrt(np.abs(inner))
++    return df
++
++
++# =============================================================================
++# Rolling volatility from returns (log / percent / both) â€” batch
++# =============================================================================
++
++def add_rolling_vol_from_returns_batch(
++    df: pd.DataFrame,
++    *,
++    close_col: str = "close",
++    windows: Sequence[int] = (20, 63, 126),
++    types: Literal["log", "pct", "both"] = "log",
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    ddof: int = 0,
++    prefix: str = "vol",
++) -> pd.DataFrame:
++    """
++    Compute rolling historical volatility from (log|pct) returns
++    for multiple windows and (optionally) both return types.
++
++    Adds columns:
++      - f"{prefix}_log_roll_{W}" for log returns (if types includes "log")
++      - f"{prefix}_pct_roll_{W}" for pct returns (if types includes "pct")
++    """
++    px = df[close_col].astype(float)
++    r_log = np.log(px / px.shift(1))
++    r_pct = px.pct_change()
++
++    need_log = types in ("log", "both")
++    need_pct = types in ("pct", "both")
++
++    for w in windows:
++        if need_log:
++            vol = r_log.rolling(w, min_periods=w).std(ddof=ddof)
++            if annualize:
++                vol = vol * np.sqrt(periods_per_year)
++            df[f"{prefix}_log_roll_{w}"] = vol
++
++        if need_pct:
++            vol = r_pct.rolling(w, min_periods=w).std(ddof=ddof)
++            if annualize:
++                vol = vol * np.sqrt(periods_per_year)
++            df[f"{prefix}_pct_roll_{w}"] = vol
++
++    return df
++
++
++# =============================================================================
++# Rolling realized volatility (Parkinson / RS / GK) â€” batch
++# =============================================================================
++
++def add_rolling_parkinson(
++    df: pd.DataFrame,
++    *,
++    high_col: str = "high",
++    low_col: str = "low",
++    window: int = 20,
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    out_col: str | None = None,
++) -> pd.DataFrame:
++    if out_col is None:
++        out_col = f"vol_parkinson_roll_{window}"
++    hl2 = (np.log(df[high_col] / df[low_col])) ** 2
++    base = (1.0 / (4.0 * np.log(2.0))) * hl2
++    vol = base.rolling(window, min_periods=window).mean().pow(0.5)
++    if annualize:
++        vol = vol * np.sqrt(periods_per_year)
++    df[out_col] = vol
++    return df
++
++
++def add_rolling_rogers_satchell(
++    df: pd.DataFrame,
++    *,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++    window: int = 20,
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    out_col: str | None = None,
++) -> pd.DataFrame:
++    if out_col is None:
++        out_col = f"vol_rs_roll_{window}"
++    term = (
++        np.log(df[high_col] / df[close_col]) * np.log(df[high_col] / df[open_col])
++        + np.log(df[low_col] / df[close_col]) * np.log(df[low_col] / df[open_col])
++    ).clip(lower=0)
++    vol = term.rolling(window, min_periods=window).mean().pow(0.5)
++    if annualize:
++        vol = vol * np.sqrt(periods_per_year)
++    df[out_col] = vol
++    return df
++
++
++def add_rolling_garman_klass(
++    df: pd.DataFrame,
++    *,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++    window: int = 20,
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    out_col: str | None = None,
++) -> pd.DataFrame:
++    if out_col is None:
++        out_col = f"vol_gk_roll_{window}"
++    term1 = 0.5 * (np.log(df[high_col] / df[low_col])) ** 2
++    term2 = (2 * np.log(2) - 1) * (np.log(df[close_col] / df[open_col])) ** 2
++    inner = term1 - term2
++    mean_inner = inner.rolling(window, min_periods=window).mean()
++    vol = (mean_inner.clip(lower=0)).pow(0.5)
++    if annualize:
++        vol = vol * np.sqrt(periods_per_year)
++    df[out_col] = vol
++    return df
++
++
++def add_rolling_realized_batch(
++    df: pd.DataFrame,
++    *,
++    windows: Sequence[int] = (20, 63, 126),
++    which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++) -> pd.DataFrame:
++    """
++    Batch helper for rolling realized-vol estimators across many windows.
++    """
++    for w in windows:
++        if "parkinson" in which:
++            add_rolling_parkinson(
++                df, high_col=high_col, low_col=low_col,
++                window=w, annualize=annualize, periods_per_year=periods_per_year,
++            )
++        if "rs" in which:
++            add_rolling_rogers_satchell(
++                df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
++                window=w, annualize=annualize, periods_per_year=periods_per_year,
++            )
++        if "gk" in which:
++            add_rolling_garman_klass(
++                df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
++                window=w, annualize=annualize, periods_per_year=periods_per_year,
++            )
++    return df
++
++
++# =============================================================================
++# One-call orchestrator (optional convenience)
++# =============================================================================
++
++def add_volatility_features(
++    df: pd.DataFrame,
++    *,
++    # single-bar toggles
++    do_atr: bool = True,
++    do_parkinson: bool = True,
++    do_rs: bool = True,
++    do_gk: bool = True,
++    atr_period: int = 14,
++
++    # rolling returns vol
++    ret_windows: Sequence[int] = (20, 63, 126),
++    ret_types: Literal["log", "pct", "both"] = "both",
++    ret_annualize: bool = True,
++    ret_periods_per_year: int = 252,
++    ret_ddof: int = 0,
++    ret_prefix: str = "vol",
++
++    # rolling realized vol
++    rv_windows: Sequence[int] = (20, 63, 126),
++    rv_which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
++    rv_annualize: bool = True,
++    rv_periods_per_year: int = 252,
++
++    # column names
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++) -> pd.DataFrame:
++    """
++    Add single-bar and rolling volatility features in one call.
++    """
++    if do_parkinson:
++        add_parkinson_vol(df, high_col=high_col, low_col=low_col)
++    if do_rs:
++        add_rogers_satchell_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col)
++    if do_gk:
++        add_garman_klass_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col)
++    if do_atr:
++        add_atr(df, period=atr_period, high_col=high_col, low_col=low_col, close_col=close_col)
++
++    add_rolling_vol_from_returns_batch(
++        df,
++        close_col=close_col,
++        windows=ret_windows,
++        types=ret_types,
++        annualize=ret_annualize,
++        periods_per_year=ret_periods_per_year,
++        ddof=ret_ddof,
++        prefix=ret_prefix,
++    )
++
++    add_rolling_realized_batch(
++        df,
++        windows=rv_windows,
++        which=rv_which,
++        annualize=rv_annualize,
++        periods_per_year=rv_periods_per_year,
++        open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
++    )
++
+     return df
+diff --git a/src/ta_lab2/regimes/run_btc_pipeline.py b/src/ta_lab2/regimes/run_btc_pipeline.py
+index e620e67..dceb8d2 100644
+--- a/src/ta_lab2/regimes/run_btc_pipeline.py
++++ b/src/ta_lab2/regimes/run_btc_pipeline.py
+@@ -1,56 +1,36 @@
+-@@
+--# ---- load your CSV ---------------------------------------------------------
+--csv_path = r"C:/Users/asafi/Downloads/ta_lab2/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
+--df2 = pd.read_csv(csv_path)
+--# Normalize headers to stable names
+--df2.columns = _clean_headers(df2.columns)
+--...   # (rest of pipeline at import time)
+-+from pathlib import Path
+-+import pandas as pd
+-+import logging
+-+
+-+log = logging.getLogger(__name__)
+-+
+-+def run_btc_pipeline(csv_path: str | Path, out_dir: str | Path, **kwargs) -> dict:
+-+    """
+-+    Run the BTC pipeline.
+-+    Parameters
+-+    ----------
+-+    csv_path : path to source CSV
+-+    out_dir  : output directory for artifacts (parquet/csv)
+-+    kwargs   : optional tuning params (ema windows, resample rules, etc.)
+-+    Returns
+-+    -------
+-+    dict with key outputs, e.g. file paths or small result stats
+-+    """
+-+    csv_path = Path(csv_path)
+-+    out_dir = Path(out_dir)
+-+    out_dir.mkdir(parents=True, exist_ok=True)
+-+
+-+    if not csv_path.exists():
+-+        raise FileNotFoundError(f"Input CSV not found: {csv_path}")
+-+
+-+    log.info("Loading data from %s", csv_path)
+-+    df2 = pd.read_csv(csv_path)
+-+    df2.columns = _clean_headers(df2.columns)  # your existing helper
+-+
+-+    # ... your existing transforms/features/resampling/regimes here ...
+-+    # write outputs to out_dir
+-+    # e.g., (keep your current filenames, just write relative to out_dir)
+-+    # df_daily.to_parquet(out_dir / "daily_en.parquet")
+-+    # df_weekly.to_parquet(out_dir / "weekly_en.parquet")
+-+    # stats.to_csv(out_dir / "regime_stats.csv", index=False)
+-+
+-+    return {
+-+        "input": str(csv_path),
+-+        "out_dir": str(out_dir),
+-+        # "n_rows": len(df2),
+-+        # "artifacts": [str(out_dir / "daily_en.parquet"), ...]
+-+    }
+-+
+-+if __name__ == "__main__":
+-+    # Local manual run (kept for convenience)
+-+    DEFAULT_ROOT = Path(__file__).resolve().parents[3]
+-+    csv = DEFAULT_ROOT / "data" / "Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
+-+    out_ = DEFAULT_ROOT / "out"
+-+    run_btc_pipeline(csv_path=csv, out_dir=out_)
++from __future__ import annotations
++from pathlib import Path
++import pandas as pd
++
++def run_btc_pipeline(
++    csv_path: str | Path,
++    out_dir: str | Path,
++    ema_windows: list[int] | None = None,
++    resample: dict | None = None,
++):
++    """
++    Orchestrate the BTC pipeline:
++      1) load CSV (from csv_path)
++      2) compute features / regimes (call your existing helpers)
++      3) write outputs to out_dir
++    """
++    csv_path = Path(csv_path)
++    out_dir = Path(out_dir)
++    out_dir.mkdir(parents=True, exist_ok=True)
++
++    # ---- 1) Load data (NO hard-coded paths) ----
++    df = pd.read_csv(csv_path)
++
++    # TODO: call your existing feature/resample/regime functions here, e.g.:
++    # df = add_base_features(df, ema_windows=ema_windows, resample=resample)
++    # regimes = compute_regimes(df)
++    # Save outputs:
++    # df.to_parquet(out_dir / "daily_en.parquet")
++    # regimes.to_parquet(out_dir / "daily_regimes.parquet")
++
++    # For now just return a tiny status so CLI works:
++    return {"rows": len(df), "out_dir": str(out_dir)}
++
++if __name__ == "__main__":
++    # Optional: ad-hoc local test; never runs during import.
++    raise SystemExit("Use the CLI or call run_btc_pipeline() from code.")
diff --git a/full_diff.patch b/full_diff.patch
new file mode 100644
index 0000000..bcc3b5d
--- /dev/null
+++ b/full_diff.patch
@@ -0,0 +1,2612 @@
+diff --git a/.github/.release-please-manifest.json b/.github/.release-please-manifest.json
+new file mode 100644
+index 0000000..466df71
+--- /dev/null
++++ b/.github/.release-please-manifest.json
+@@ -0,0 +1,3 @@
++{
++  ".": "0.1.0"
++}
+diff --git a/.github/release-please-config.json b/.github/release-please-config.json
+new file mode 100644
+index 0000000..5e20aea
+--- /dev/null
++++ b/.github/release-please-config.json
+@@ -0,0 +1,12 @@
++{
++  "release-type": "python",
++  "package-name": "ta_lab2",
++  "changelog-path": "CHANGELOG.md",
++  "skip-github-release": true,
++  "include-v-in-tag": true,
++  "bump-minor-pre-major": true,
++  "extra-files": [
++    "pyproject.toml",
++    "src/ta_lab2/__init__.py"
++  ]
++}
+diff --git a/.github/workflows/publish-release.yml b/.github/workflows/publish-release.yml
+new file mode 100644
+index 0000000..877728c
+--- /dev/null
++++ b/.github/workflows/publish-release.yml
+@@ -0,0 +1,32 @@
++      - name: Generate release notes
++        id: notes
++        run: |
++          VERSION="${GITHUB_REF_NAME}"   # e.g., v0.1.0
++          DATE="$(date +'%B %e, %Y')"
++
++          cat > notes.md <<'EOF'
++## ðŸš€ **ta_lab2 v0.1.0 â€” First Major Release**
++
++### ðŸ§­ Overview
++This release marks the first full, modular version of **ta_lab2**, a Python toolkit for technical analysis and regime detection.
++It introduces a unified configuration system, expanded feature library, and an advanced volatility engine designed for large-scale analytics.
++
++---
++
++### âš™ï¸ Core Refactor
++- Moved configuration logic from `src/ta_lab2/config.py` â†’ root-level `config.py`.
++- Added `project_root()` to auto-detect the repo root for path normalization.
++- Centralized settings in `config/default.yaml` for portable project setup.
++
++---
++
++### ðŸ“¦ Packaging & CLI
++... (all your Markdown body above) ...
++
++---
++
++**Tag:** ${{ github.ref_name }}
++**Release Date:** ${DATE}
++EOF
++
++          echo "notes_file=notes.md" >> $GITHUB_OUTPUT
+diff --git a/.github/workflows/release-please.yml b/.github/workflows/release-please.yml
+new file mode 100644
+index 0000000..474c5c5
+--- /dev/null
++++ b/.github/workflows/release-please.yml
+@@ -0,0 +1,21 @@
++name: release-please
++
++on:
++  push:
++    branches: [ main ]
++  workflow_dispatch:
++
++permissions:
++  contents: write
++  pull-requests: write
++
++jobs:
++  release-please:
++    runs-on: ubuntu-latest
++    steps:
++      - name: Run release-please
++        uses: google-github-actions/release-please-action@v4
++        with:
++          command: manifest
++          config-file: .github/release-please-config.json
++          manifest-file: .github/.release-please-manifest.json
+diff --git a/changelog.md b/changelog.md
+new file mode 100644
+index 0000000..64a2fe2
+--- /dev/null
++++ b/changelog.md
+@@ -0,0 +1,48 @@
++# ðŸ§¾ Changelog
++
++All notable changes to **ta_lab2** will be documented here.
++
++---
++
++## [0.1.0] - 2025-11-01
++### ðŸŽ¯ Overview
++First major update of `ta_lab2`: introduces a modular configuration system, full volatility suite, and technical indicator + correlation modules.
++
++---
++
++### âš™ï¸ Core Refactor
++- Moved configuration logic from `src/ta_lab2/config.py` to top-level `config.py`.
++- Added path resolution via `project_root()` for robust portability.
++- Introduced root-level YAML file (`config/default.yaml`) for user settings.
++
++### ðŸ“¦ Packaging & CLI
++- Added proper `pyproject.toml` build system (setuptools â‰¥ 68).
++- Added `ta-lab2` command-line entry point via `[project.scripts]`.
++- CLI now loads settings from root-level config and runs the BTC pipeline modularly.
++
++### ðŸ“ˆ Features
++- Introduced **technical indicators** (`rsi`, `macd`, `stoch_kd`, `bollinger`, `adx`, `obv`, `mfi`).
++- Added **correlation utilities** (`acf`, `pacf_yw`, `rolling_autocorr`, `xcorr`).
++
++### ðŸ“Š Volatility Module Overhaul
++- Rewrote `vol.py` to include:
++  - Parkinson, Rogersâ€“Satchell, and Garmanâ€“Klass volatility estimators.
++  - Rolling realized volatility (annualized and multi-window).
++  - Rolling historical volatility from log or percent returns.
++  - Unified `add_volatility_features()` orchestrator for one-call analysis.
++
++### ðŸ§  Pipeline Improvements
++- Simplified `run_btc_pipeline()` â€” removed hardcoded paths, made fully callable.
++- Prepares project for composable feature + regime detection pipeline.
++
++### ðŸ§ª Developer Experience
++- Added dev dependencies: `pytest`, `mypy`, `ruff`, `hypothesis`, `pytest-benchmark`.
++- Normalized project structure for testing and CI/CD compatibility.
++
++---
++
++## [Unreleased]
++- Add rolling correlation matrices
++- Implement feature-store export
++- Integrate regime clustering and labeling
++- Add unit tests for volatility and indicator modules
+diff --git a/config.py b/config.py
+new file mode 100644
+index 0000000..d511080
+--- /dev/null
++++ b/config.py
+@@ -0,0 +1,41 @@
++# config.py (at repo root)
++from __future__ import annotations
++from dataclasses import dataclass, field
++from pathlib import Path
++from typing import Any
++import yaml
++
++@dataclass
++class Settings:
++    # required
++    data_csv: str
++    # optional
++    out_dir: str = "out"
++    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100])
++    resample: dict[str, Any] = field(default_factory=lambda: {"weekly": "W-SUN", "monthly": "MS"})
++    indicators: dict[str, Any] | None = None
++    correlations: dict[str, Any] | None = None
++
++def project_root(start: str | Path | None = None) -> Path:
++    """Walk up from 'start' (or this file) until we find a folder containing pyproject.toml."""
++    cur = Path(start or __file__).resolve()
++    for p in [cur, *cur.parents]:
++        if (p / "pyproject.toml").exists():
++            return p
++    # fallback: repo root is parent of this file
++    return Path(__file__).resolve().parent
++
++def load_settings(yaml_path: str | Path) -> Settings:
++    """Load YAML into Settings, then normalize relative paths against the project root."""
++    root = project_root()
++    p = (root / yaml_path).resolve() if not Path(yaml_path).is_absolute() else Path(yaml_path)
++    data = yaml.safe_load(p.read_text(encoding="utf-8")) or {}
++
++    # Build Settings
++    s = Settings(**data)
++
++    # Normalize paths (make absolute, anchored to repo root)
++    s.data_csv = str((root / s.data_csv).resolve()) if not Path(s.data_csv).is_absolute() else s.data_csv
++    s.out_dir  = str((root / s.out_dir).resolve())  if not Path(s.out_dir).is_absolute()  else s.out_dir
++
++    return s
+diff --git a/config/default.yaml b/config/default.yaml
+new file mode 100644
+index 0000000..ea337c4
+--- /dev/null
++++ b/config/default.yaml
+@@ -0,0 +1,23 @@
++data_csv: data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv
++out_dir: out
++ema_windows: [21, 50, 100]
++resample:
++  weekly: "W-SUN"
++  monthly: "MS"
++
++indicators:
++  rsi: [14, 28]
++  macd: {fast: 12, slow: 26, signal: 9}
++  stoch: {k: 14, d: 3}
++  bollinger: {window: 20, n_sigma: 2}
++  atr: [14]
++  adx: [14]
++  obv: true
++  mfi: [14]
++
++correlations:
++  acf: {nlags: 40, on: "returns"}   # "returns" or "close"
++  pacf: {nlags: 20, on: "returns"}
++  rolling_autocorr:
++    - {lag: 1, window: 100, on: "returns"}
++    - {lag: 5, window: 100, on: "returns"}
+diff --git a/diff.txt b/diff.txt
+new file mode 100644
+index 0000000..91280df
+--- /dev/null
++++ b/diff.txt
+@@ -0,0 +1,863 @@
++diff --git a/config.py b/config.py
++new file mode 100644
++index 0000000..d511080
++--- /dev/null
+++++ b/config.py
++@@ -0,0 +1,41 @@
+++# config.py (at repo root)
+++from __future__ import annotations
+++from dataclasses import dataclass, field
+++from pathlib import Path
+++from typing import Any
+++import yaml
+++
+++@dataclass
+++class Settings:
+++    # required
+++    data_csv: str
+++    # optional
+++    out_dir: str = "out"
+++    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100])
+++    resample: dict[str, Any] = field(default_factory=lambda: {"weekly": "W-SUN", "monthly": "MS"})
+++    indicators: dict[str, Any] | None = None
+++    correlations: dict[str, Any] | None = None
+++
+++def project_root(start: str | Path | None = None) -> Path:
+++    """Walk up from 'start' (or this file) until we find a folder containing pyproject.toml."""
+++    cur = Path(start or __file__).resolve()
+++    for p in [cur, *cur.parents]:
+++        if (p / "pyproject.toml").exists():
+++            return p
+++    # fallback: repo root is parent of this file
+++    return Path(__file__).resolve().parent
+++
+++def load_settings(yaml_path: str | Path) -> Settings:
+++    """Load YAML into Settings, then normalize relative paths against the project root."""
+++    root = project_root()
+++    p = (root / yaml_path).resolve() if not Path(yaml_path).is_absolute() else Path(yaml_path)
+++    data = yaml.safe_load(p.read_text(encoding="utf-8")) or {}
+++
+++    # Build Settings
+++    s = Settings(**data)
+++
+++    # Normalize paths (make absolute, anchored to repo root)
+++    s.data_csv = str((root / s.data_csv).resolve()) if not Path(s.data_csv).is_absolute() else s.data_csv
+++    s.out_dir  = str((root / s.out_dir).resolve())  if not Path(s.out_dir).is_absolute()  else s.out_dir
+++
+++    return s
++diff --git a/config/default.yaml b/config/default.yaml
++new file mode 100644
++index 0000000..ea337c4
++--- /dev/null
+++++ b/config/default.yaml
++@@ -0,0 +1,23 @@
+++data_csv: data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv
+++out_dir: out
+++ema_windows: [21, 50, 100]
+++resample:
+++  weekly: "W-SUN"
+++  monthly: "MS"
+++
+++indicators:
+++  rsi: [14, 28]
+++  macd: {fast: 12, slow: 26, signal: 9}
+++  stoch: {k: 14, d: 3}
+++  bollinger: {window: 20, n_sigma: 2}
+++  atr: [14]
+++  adx: [14]
+++  obv: true
+++  mfi: [14]
+++
+++correlations:
+++  acf: {nlags: 40, on: "returns"}   # "returns" or "close"
+++  pacf: {nlags: 20, on: "returns"}
+++  rolling_autocorr:
+++    - {lag: 1, window: 100, on: "returns"}
+++    - {lag: 5, window: 100, on: "returns"}
++diff --git a/pyproject.toml b/pyproject.toml
++index 9a6a43d..96032a0 100644
++--- a/pyproject.toml
+++++ b/pyproject.toml
++@@ -1,21 +1,34 @@
++- [project]
++- name = "ta_lab2"
++- version = "0.1.0"
++- requires-python = ">=3.10"
++- dependencies = [
++--    # your runtime deps here
++-+    "pandas",
++-+    "pyyaml",
++- ]
++-
++-+[project.optional-dependencies]
++-+dev = [
++-+    "pytest",
++-+    "mypy",
++-+    "ruff",
++-+    "pytest-benchmark",
++-+    "hypothesis",
++-+]
++-+
++-+[project.scripts]
++-+ta-lab2 = "ta_lab2.cli:main"
+++[build-system]
+++requires = ["setuptools>=68", "wheel"]
+++build-backend = "setuptools.build_meta"
+++
+++[project]
+++name = "ta_lab2"
+++version = "0.1.0"
+++description = "Technical analysis & regime-detection toolkit"
+++readme = "README.md"
+++requires-python = ">=3.10"
+++dependencies = [
+++  "pandas",
+++  "pyyaml",
+++]
+++
+++[project.optional-dependencies]
+++dev = [
+++  "pytest",
+++  "mypy",
+++  "ruff",
+++  "pytest-benchmark",
+++  "hypothesis",
+++]
+++
+++[project.scripts]
+++ta-lab2 = "ta_lab2.cli:main"
+++
+++# Tell setuptools to find packages under src/
+++[tool.setuptools.packages.find]
+++where = ["src"]
+++
+++# Also install the top-level config.py module (so `from config import ...` works)
+++[tool.setuptools]
+++py-modules = ["config"]
++diff --git a/src/ta_lab2/__init__.py b/src/ta_lab2/__init__.py
++index 7840e43..1bdc623 100644
++--- a/src/ta_lab2/__init__.py
+++++ b/src/ta_lab2/__init__.py
++@@ -1,5 +1,4 @@
++--# current content
++-+from .regimes.run_btc_pipeline import run_btc_pipeline
++-+
++-+__all__ = ["run_btc_pipeline"]
++-+__version__ = "0.1.0"
+++from .regimes.run_btc_pipeline import run_btc_pipeline
+++
+++__all__ = ["run_btc_pipeline"]
+++__version__ = "0.1.0"
++diff --git a/src/ta_lab2/cli.py b/src/ta_lab2/cli.py
++index 3131e8d..1b8350c 100644
++--- a/src/ta_lab2/cli.py
+++++ b/src/ta_lab2/cli.py
++@@ -1,27 +1,39 @@
++ from __future__ import annotations
++ import argparse
++ from pathlib import Path
++-from .config import load_settings, project_root
++-from .regimes.run_btc_pipeline import run_btc_pipeline
+++
+++# Import from root-level config.py, not from ta_lab2.config
+++from config import load_settings, project_root
+++from ta_lab2.regimes.run_btc_pipeline import run_btc_pipeline
+++
++
++ def main(argv: list[str] | None = None) -> int:
++     ap = argparse.ArgumentParser(prog="ta-lab2", description="ta_lab2 CLI")
++-    ap.add_argument("--config", "-c", default="configs/default.yaml",
++-                    help="Path to YAML config relative to project root")
+++    ap.add_argument(
+++        "--config", "-c",
+++        default="config/default.yaml",
+++        help="Path to YAML config relative to project root (default: config/default.yaml)"
+++    )
++     args = ap.parse_args(argv)
++
++-    root = project_root()
++-    cfg_path = (root / args.config).resolve()
++-    settings = load_settings(cfg_path)
+++    # Load settings from YAML via the root-level config.py
+++    settings = load_settings(args.config)
++
++-    csv = (root / settings.data_csv).resolve()
++-    out_dir = (root / settings.out_dir).resolve()
+++    # Resolve absolute paths for input and output
+++    csv = Path(settings.data_csv)
+++    out_dir = Path(settings.out_dir)
+++
+++    # Run main pipeline
+++    result = run_btc_pipeline(
+++        csv_path=csv,
+++        out_dir=out_dir,
+++        ema_windows=settings.ema_windows,
+++        resample=settings.resample
+++    )
++
++-    result = run_btc_pipeline(csv_path=csv, out_dir=out_dir,
++-                              ema_windows=settings.ema_windows,
++-                              resample=settings.resample)
++     print("Pipeline complete:", result)
++     return 0
++
+++
++ if __name__ == "__main__":
++     raise SystemExit(main())
++diff --git a/src/ta_lab2/config.py b/src/ta_lab2/config.py
++deleted file mode 100644
++index b1797bd..0000000
++--- a/src/ta_lab2/config.py
+++++ /dev/null
++@@ -1,24 +0,0 @@
++-from __future__ import annotations
++-from dataclasses import dataclass, field
++-from pathlib import Path
++-import yaml
++-
++-@dataclass
++-class Settings:
++-    data_csv: str
++-    out_dir: str = "out"
++-    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100])
++-    resample: dict = field(default_factory=lambda: {"weekly": "W-SUN", "monthly": "MS"})
++-
++-def load_settings(path: str | Path) -> Settings:
++-    p = Path(path)
++-    data = yaml.safe_load(p.read_text(encoding="utf-8"))
++-    return Settings(**data)
++-
++-def project_root(start: str | Path | None = None) -> Path:
++-    # walk up until we find pyproject.toml
++-    cur = Path(start or __file__).resolve()
++-    for ancestor in [cur, *cur.parents]:
++-        if (ancestor / "pyproject.toml").exists():
++-            return ancestor
++-    return cur  # fallback
++diff --git a/src/ta_lab2/config/default.yaml b/src/ta_lab2/config/default.yaml
++deleted file mode 100644
++index 4da5e13..0000000
++--- a/src/ta_lab2/config/default.yaml
+++++ /dev/null
++@@ -1,9 +0,0 @@
++-# Paths are relative to the project root (where pyproject.toml lives)
++-data_csv: data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv
++-out_dir: out
++-
++-# Pipeline parameters (exampleâ€”extend as your code supports)
++-ema_windows: [21, 50, 100]
++-resample:
++-  weekly: "W-SUN"
++-  monthly: "MS"
++\ No newline at end of file
++diff --git a/src/ta_lab2/features/__init__.py b/src/ta_lab2/features/__init__.py
++index 9fa317e..b169b79 100644
++--- a/src/ta_lab2/features/__init__.py
+++++ b/src/ta_lab2/features/__init__.py
++@@ -2,3 +2,23 @@ from .calendar import expand_datetime_features_inplace
++ from .ema import add_ema_columns, add_ema_d1, add_ema_d2
++ from .returns import add_returns
++ from .vol import add_atr
+++
+++# New imports for technical indicators
+++from .indicators import rsi, macd, stoch_kd, bollinger, atr, adx, obv, mfi
+++
+++# New imports for correlation-based features
+++from .correlation import acf, pacf_yw, rolling_autocorr, xcorr
+++
+++
+++__all__ = [
+++    # Core features
+++    "expand_datetime_features_inplace",
+++    "add_ema_columns", "add_ema_d1", "add_ema_d2",
+++    "add_returns", "add_atr",
+++
+++    # Technical indicators
+++    "rsi", "macd", "stoch_kd", "bollinger", "atr", "adx", "obv", "mfi",
+++
+++    # Correlation utilities
+++    "acf", "pacf_yw", "rolling_autocorr", "xcorr",
+++]
++diff --git a/src/ta_lab2/features/correlation.py b/src/ta_lab2/features/correlation.py
++new file mode 100644
++index 0000000..bd96500
++--- /dev/null
+++++ b/src/ta_lab2/features/correlation.py
++@@ -0,0 +1,63 @@
+++from __future__ import annotations
+++import numpy as np
+++import pandas as pd
+++
+++def acf(x: pd.Series, nlags: int = 40, demean: bool = True) -> pd.Series:
+++    s = pd.Series(x).dropna().astype(float)
+++    if len(s) == 0:
+++        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="acf")
+++    if demean:
+++        s = s - s.mean()
+++    var = (s**2).sum()
+++    ac = [1.0]
+++    for k in range(1, nlags + 1):
+++        cov = (s.iloc[k:] * s.iloc[:-k]).sum()
+++        ac.append(float(cov / var) if var != 0 else np.nan)
+++    return pd.Series(ac, index=range(0, nlags + 1), name="acf")
+++
+++def pacf_yw(x: pd.Series, nlags: int = 20) -> pd.Series:
+++    s = pd.Series(x).dropna().astype(float)
+++    if len(s) == 0:
+++        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="pacf")
+++    s = s - s.mean()
+++    # autocov sequence
+++    gamma = np.array([
+++        (s[:len(s)-k] @ s[k:]) / len(s) if k > 0 else (s @ s) / len(s)
+++        for k in range(0, nlags+1)
+++    ])
+++    pac = np.zeros(nlags+1)
+++    pac[0] = 1.0
+++    phi = np.zeros((nlags+1, nlags+1))
+++    var = gamma[0]
+++    for k in range(1, nlags+1):
+++        num = gamma[k] - np.sum(phi[k-1,1:k] * gamma[1:k][::-1])
+++        den = var - np.sum(phi[k-1,1:k] * gamma[1:k])
+++        phi[k,k] = num / den if den != 0 else np.nan
+++        for j in range(1, k):
+++            phi[k,j] = phi[k-1,j] - phi[k,k]*phi[k-1,k-j]
+++        pac[k] = phi[k,k]
+++    return pd.Series(pac, index=range(0, nlags+1), name="pacf")
+++
+++def rolling_autocorr(s: pd.Series, lag: int = 1, window: int = 100) -> pd.Series:
+++    return s.rolling(window).corr(s.shift(lag)).rename(f"roll_ac_{lag}_{window}")
+++
+++def xcorr(a: pd.Series, b: pd.Series, max_lag: int = 20, demean: bool = True) -> pd.Series:
+++    A = pd.Series(a).astype(float)
+++    B = pd.Series(b).astype(float)
+++    A, B = A.align(B, join="inner")
+++    if len(A) == 0:
+++        return pd.Series([np.nan]*(2*max_lag+1), index=range(-max_lag, max_lag+1), name="xcorr")
+++    if demean:
+++        A, B = A - A.mean(), B - B.mean()
+++    var = np.sqrt((A**2).sum() * (B**2).sum())
+++    vals = []
+++    lags = range(-max_lag, max_lag + 1)
+++    for k in lags:
+++        if k < 0:
+++            cov = (A[:k] * B[-k:]).sum()
+++        elif k > 0:
+++            cov = (A[k:] * B[:-k]).sum()
+++        else:
+++            cov = (A * B).sum()
+++        vals.append(float(cov / var) if var != 0 else np.nan)
+++    return pd.Series(vals, index=list(lags), name="xcorr")
++diff --git a/src/ta_lab2/features/indicators.py b/src/ta_lab2/features/indicators.py
++new file mode 100644
++index 0000000..a71a0a4
++--- /dev/null
+++++ b/src/ta_lab2/features/indicators.py
++@@ -0,0 +1,94 @@
+++from __future__ import annotations
+++import numpy as np
+++import pandas as pd
+++
+++# ---- helpers ----
+++def _ema(s: pd.Series, span: int) -> pd.Series:
+++    return s.ewm(span=span, adjust=False).mean()
+++
+++def _sma(s: pd.Series, window: int) -> pd.Series:
+++    return s.rolling(window, min_periods=window).mean()
+++
+++def _tr(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:
+++    prev_close = close.shift(1)
+++    return pd.concat([
+++        (high - low).abs(),
+++        (high - prev_close).abs(),
+++        (low - prev_close).abs()
+++    ], axis=1).max(axis=1)
+++
+++# ---- indicators ----
+++def rsi(close: pd.Series, window: int = 14) -> pd.Series:
+++    delta = close.diff()
+++    gain = delta.clip(lower=0)
+++    loss = -delta.clip(upper=0)
+++    avg_gain = gain.ewm(alpha=1/window, adjust=False).mean()
+++    avg_loss = loss.ewm(alpha=1/window, adjust=False).mean()
+++    rs = avg_gain / (avg_loss.replace(0, np.nan))
+++    out = 100 - (100 / (1 + rs))
+++    return out.rename(f"rsi_{window}")
+++
+++def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:
+++    ema_fast = _ema(close, fast)
+++    ema_slow = _ema(close, slow)
+++    macd_line = ema_fast - ema_slow
+++    signal_line = _ema(macd_line, signal)
+++    hist = macd_line - signal_line
+++    return pd.DataFrame({
+++        f"macd_{fast}_{slow}": macd_line,
+++        f"macd_signal_{signal}": signal_line,
+++        f"macd_hist_{fast}_{slow}_{signal}": hist
+++    })
+++
+++def stoch_kd(high: pd.Series, low: pd.Series, close: pd.Series, k: int = 14, d: int = 3) -> pd.DataFrame:
+++    lowest = low.rolling(k, min_periods=k).min()
+++    highest = high.rolling(k, min_periods=k).max()
+++    k_line = 100 * (close - lowest) / (highest - lowest)
+++    d_line = k_line.rolling(d, min_periods=d).mean()
+++    return pd.DataFrame({f"stoch_k_{k}": k_line, f"stoch_d_{d}": d_line})
+++
+++def bollinger(close: pd.Series, window: int = 20, n_sigma: float = 2.0) -> pd.DataFrame:
+++    ma = _sma(close, window)
+++    std = close.rolling(window, min_periods=window).std()
+++    upper = ma + n_sigma * std
+++    lower = ma - n_sigma * std
+++    bw = (upper - lower) / ma
+++    return pd.DataFrame({
+++        f"bb_ma_{window}": ma,
+++        f"bb_up_{window}_{n_sigma}": upper,
+++        f"bb_lo_{window}_{n_sigma}": lower,
+++        f"bb_width_{window}": bw
+++    })
+++
+++def atr(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
+++    tr = _tr(high, low, close)
+++    out = tr.rolling(window, min_periods=window).mean()
+++    return out.rename(f"atr_{window}")
+++
+++def adx(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
+++    up = high.diff()
+++    dn = -low.diff()
+++    plus_dm  = np.where((up > dn) and isinstance(up, pd.Series) and (up > 0), up, 0.0)
+++    minus_dm = np.where((dn > up) and isinstance(dn, pd.Series) and (dn > 0), dn, 0.0)
+++    tr = _tr(high, low, close)
+++    atr_ = tr.rolling(window, min_periods=window).mean()
+++    plus_di  = 100 * pd.Series(plus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
+++    minus_di = 100 * pd.Series(minus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
+++    dx = ((plus_di - minus_di).abs() / (plus_di + minus_di)) * 100
+++    adx_ = dx.rolling(window, min_periods=window).mean()
+++    return adx_.rename(f"adx_{window}")
+++
+++def obv(close: pd.Series, volume: pd.Series) -> pd.Series:
+++    direction = np.sign(close.diff().fillna(0))
+++    return (direction * volume).fillna(0).cumsum().rename("obv")
+++
+++def mfi(high: pd.Series, low: pd.Series, close: pd.Series, volume: pd.Series, window: int = 14) -> pd.Series:
+++    tp = (high + low + close) / 3.0
+++    raw = tp * volume
+++    pos = raw.where(tp.diff() > 0, 0.0)
+++    neg = raw.where(tp.diff() < 0, 0.0)
+++    mr = pos.rolling(window, min_periods=window).sum() / (
+++        neg.rolling(window, min_periods=window).sum().replace(0, np.nan)
+++    )
+++    out = 100 - (100 / (1 + mr))
+++    return out.rename(f"mfi_{window}")
++diff --git a/src/ta_lab2/features/vol.py b/src/ta_lab2/features/vol.py
++index 64a9858..50a0575 100644
++--- a/src/ta_lab2/features/vol.py
+++++ b/src/ta_lab2/features/vol.py
++@@ -1,15 +1,306 @@
++-
++-import pandas as pd
+++# src/ta_lab2/features/vol.py
++ import numpy as np
+++import pandas as pd
+++from typing import Iterable, Literal, Sequence
++
++-def add_atr(df: pd.DataFrame, period: int = 14,
++-            high_col="high", low_col="low", close_col="close"):
+++
+++# =============================================================================
+++# Single-bar realized volatility estimators
+++# =============================================================================
+++
+++def add_atr(
+++    df: pd.DataFrame,
+++    period: int = 14,
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    close_col: str = "close",
+++) -> pd.DataFrame:
+++    """
+++    Average True Range (Wilder EMA smoothing).
+++    """
++     high = df[high_col].astype(float)
++-    low  = df[low_col].astype(float)
+++    low = df[low_col].astype(float)
++     close = df[close_col].astype(float)
++     prev_close = close.shift(1)
+++
++     tr = (high - low).abs()
++     tr = np.maximum(tr, (high - prev_close).abs())
++     tr = np.maximum(tr, (low - prev_close).abs())
++-    df[f"atr_{period}"] = tr.ewm(alpha=1/period, adjust=False).mean()
+++
+++    df[f"atr_{period}"] = tr.ewm(alpha=1 / period, adjust=False).mean()
+++    return df
+++
+++
+++def add_parkinson_vol(
+++    df: pd.DataFrame,
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    out_col: str = "vol_parkinson",
+++) -> pd.DataFrame:
+++    """
+++    Ïƒ_P = sqrt( (1 / (4 * ln(2))) * (ln(H/L))^2 )
+++    """
+++    hl2 = np.log(df[high_col] / df[low_col]) ** 2
+++    df[out_col] = np.sqrt((1.0 / (4.0 * np.log(2.0))) * hl2)
+++    return df
+++
+++
+++def add_rogers_satchell_vol(
+++    df: pd.DataFrame,
+++    open_col: str = "open",
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    close_col: str = "close",
+++    out_col: str = "vol_rs",
+++) -> pd.DataFrame:
+++    """
+++    Ïƒ_RS = sqrt( ln(H/C)ln(H/O) + ln(L/C)ln(L/O) )
+++    """
+++    term = (
+++        np.log(df[high_col] / df[close_col]) * np.log(df[high_col] / df[open_col])
+++        + np.log(df[low_col] / df[close_col]) * np.log(df[low_col] / df[open_col])
+++    ).clip(lower=0)
+++    df[out_col] = np.sqrt(term)
+++    return df
+++
+++
+++def add_garman_klass_vol(
+++    df: pd.DataFrame,
+++    open_col: str = "open",
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    close_col: str = "close",
+++    out_col: str = "vol_gk",
+++) -> pd.DataFrame:
+++    """
+++    Ïƒ_GK = sqrt( 0.5(ln(H/L))^2 - (2ln2 - 1)(ln(C/O))^2 )
+++    """
+++    term1 = 0.5 * (np.log(df[high_col] / df[low_col])) ** 2
+++    term2 = (2 * np.log(2) - 1) * (np.log(df[close_col] / df[open_col])) ** 2
+++    inner = term1 - term2
+++    df[out_col] = np.sqrt(np.abs(inner))
+++    return df
+++
+++
+++# =============================================================================
+++# Rolling volatility from returns (log / percent / both) â€” batch
+++# =============================================================================
+++
+++def add_rolling_vol_from_returns_batch(
+++    df: pd.DataFrame,
+++    *,
+++    close_col: str = "close",
+++    windows: Sequence[int] = (20, 63, 126),
+++    types: Literal["log", "pct", "both"] = "log",
+++    annualize: bool = True,
+++    periods_per_year: int = 252,
+++    ddof: int = 0,
+++    prefix: str = "vol",
+++) -> pd.DataFrame:
+++    """
+++    Compute rolling historical volatility from (log|pct) returns
+++    for multiple windows and (optionally) both return types.
+++
+++    Adds columns:
+++      - f"{prefix}_log_roll_{W}" for log returns (if types includes "log")
+++      - f"{prefix}_pct_roll_{W}" for pct returns (if types includes "pct")
+++    """
+++    px = df[close_col].astype(float)
+++    r_log = np.log(px / px.shift(1))
+++    r_pct = px.pct_change()
+++
+++    need_log = types in ("log", "both")
+++    need_pct = types in ("pct", "both")
+++
+++    for w in windows:
+++        if need_log:
+++            vol = r_log.rolling(w, min_periods=w).std(ddof=ddof)
+++            if annualize:
+++                vol = vol * np.sqrt(periods_per_year)
+++            df[f"{prefix}_log_roll_{w}"] = vol
+++
+++        if need_pct:
+++            vol = r_pct.rolling(w, min_periods=w).std(ddof=ddof)
+++            if annualize:
+++                vol = vol * np.sqrt(periods_per_year)
+++            df[f"{prefix}_pct_roll_{w}"] = vol
+++
+++    return df
+++
+++
+++# =============================================================================
+++# Rolling realized volatility (Parkinson / RS / GK) â€” batch
+++# =============================================================================
+++
+++def add_rolling_parkinson(
+++    df: pd.DataFrame,
+++    *,
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    window: int = 20,
+++    annualize: bool = True,
+++    periods_per_year: int = 252,
+++    out_col: str | None = None,
+++) -> pd.DataFrame:
+++    if out_col is None:
+++        out_col = f"vol_parkinson_roll_{window}"
+++    hl2 = (np.log(df[high_col] / df[low_col])) ** 2
+++    base = (1.0 / (4.0 * np.log(2.0))) * hl2
+++    vol = base.rolling(window, min_periods=window).mean().pow(0.5)
+++    if annualize:
+++        vol = vol * np.sqrt(periods_per_year)
+++    df[out_col] = vol
+++    return df
+++
+++
+++def add_rolling_rogers_satchell(
+++    df: pd.DataFrame,
+++    *,
+++    open_col: str = "open",
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    close_col: str = "close",
+++    window: int = 20,
+++    annualize: bool = True,
+++    periods_per_year: int = 252,
+++    out_col: str | None = None,
+++) -> pd.DataFrame:
+++    if out_col is None:
+++        out_col = f"vol_rs_roll_{window}"
+++    term = (
+++        np.log(df[high_col] / df[close_col]) * np.log(df[high_col] / df[open_col])
+++        + np.log(df[low_col] / df[close_col]) * np.log(df[low_col] / df[open_col])
+++    ).clip(lower=0)
+++    vol = term.rolling(window, min_periods=window).mean().pow(0.5)
+++    if annualize:
+++        vol = vol * np.sqrt(periods_per_year)
+++    df[out_col] = vol
+++    return df
+++
+++
+++def add_rolling_garman_klass(
+++    df: pd.DataFrame,
+++    *,
+++    open_col: str = "open",
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    close_col: str = "close",
+++    window: int = 20,
+++    annualize: bool = True,
+++    periods_per_year: int = 252,
+++    out_col: str | None = None,
+++) -> pd.DataFrame:
+++    if out_col is None:
+++        out_col = f"vol_gk_roll_{window}"
+++    term1 = 0.5 * (np.log(df[high_col] / df[low_col])) ** 2
+++    term2 = (2 * np.log(2) - 1) * (np.log(df[close_col] / df[open_col])) ** 2
+++    inner = term1 - term2
+++    mean_inner = inner.rolling(window, min_periods=window).mean()
+++    vol = (mean_inner.clip(lower=0)).pow(0.5)
+++    if annualize:
+++        vol = vol * np.sqrt(periods_per_year)
+++    df[out_col] = vol
+++    return df
+++
+++
+++def add_rolling_realized_batch(
+++    df: pd.DataFrame,
+++    *,
+++    windows: Sequence[int] = (20, 63, 126),
+++    which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
+++    annualize: bool = True,
+++    periods_per_year: int = 252,
+++    open_col: str = "open",
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    close_col: str = "close",
+++) -> pd.DataFrame:
+++    """
+++    Batch helper for rolling realized-vol estimators across many windows.
+++    """
+++    for w in windows:
+++        if "parkinson" in which:
+++            add_rolling_parkinson(
+++                df, high_col=high_col, low_col=low_col,
+++                window=w, annualize=annualize, periods_per_year=periods_per_year,
+++            )
+++        if "rs" in which:
+++            add_rolling_rogers_satchell(
+++                df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
+++                window=w, annualize=annualize, periods_per_year=periods_per_year,
+++            )
+++        if "gk" in which:
+++            add_rolling_garman_klass(
+++                df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
+++                window=w, annualize=annualize, periods_per_year=periods_per_year,
+++            )
+++    return df
+++
+++
+++# =============================================================================
+++# One-call orchestrator (optional convenience)
+++# =============================================================================
+++
+++def add_volatility_features(
+++    df: pd.DataFrame,
+++    *,
+++    # single-bar toggles
+++    do_atr: bool = True,
+++    do_parkinson: bool = True,
+++    do_rs: bool = True,
+++    do_gk: bool = True,
+++    atr_period: int = 14,
+++
+++    # rolling returns vol
+++    ret_windows: Sequence[int] = (20, 63, 126),
+++    ret_types: Literal["log", "pct", "both"] = "both",
+++    ret_annualize: bool = True,
+++    ret_periods_per_year: int = 252,
+++    ret_ddof: int = 0,
+++    ret_prefix: str = "vol",
+++
+++    # rolling realized vol
+++    rv_windows: Sequence[int] = (20, 63, 126),
+++    rv_which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
+++    rv_annualize: bool = True,
+++    rv_periods_per_year: int = 252,
+++
+++    # column names
+++    open_col: str = "open",
+++    high_col: str = "high",
+++    low_col: str = "low",
+++    close_col: str = "close",
+++) -> pd.DataFrame:
+++    """
+++    Add single-bar and rolling volatility features in one call.
+++    """
+++    if do_parkinson:
+++        add_parkinson_vol(df, high_col=high_col, low_col=low_col)
+++    if do_rs:
+++        add_rogers_satchell_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col)
+++    if do_gk:
+++        add_garman_klass_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col)
+++    if do_atr:
+++        add_atr(df, period=atr_period, high_col=high_col, low_col=low_col, close_col=close_col)
+++
+++    add_rolling_vol_from_returns_batch(
+++        df,
+++        close_col=close_col,
+++        windows=ret_windows,
+++        types=ret_types,
+++        annualize=ret_annualize,
+++        periods_per_year=ret_periods_per_year,
+++        ddof=ret_ddof,
+++        prefix=ret_prefix,
+++    )
+++
+++    add_rolling_realized_batch(
+++        df,
+++        windows=rv_windows,
+++        which=rv_which,
+++        annualize=rv_annualize,
+++        periods_per_year=rv_periods_per_year,
+++        open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
+++    )
+++
++     return df
++diff --git a/src/ta_lab2/regimes/run_btc_pipeline.py b/src/ta_lab2/regimes/run_btc_pipeline.py
++index e620e67..dceb8d2 100644
++--- a/src/ta_lab2/regimes/run_btc_pipeline.py
+++++ b/src/ta_lab2/regimes/run_btc_pipeline.py
++@@ -1,56 +1,36 @@
++-@@
++--# ---- load your CSV ---------------------------------------------------------
++--csv_path = r"C:/Users/asafi/Downloads/ta_lab2/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
++--df2 = pd.read_csv(csv_path)
++--# Normalize headers to stable names
++--df2.columns = _clean_headers(df2.columns)
++--...   # (rest of pipeline at import time)
++-+from pathlib import Path
++-+import pandas as pd
++-+import logging
++-+
++-+log = logging.getLogger(__name__)
++-+
++-+def run_btc_pipeline(csv_path: str | Path, out_dir: str | Path, **kwargs) -> dict:
++-+    """
++-+    Run the BTC pipeline.
++-+    Parameters
++-+    ----------
++-+    csv_path : path to source CSV
++-+    out_dir  : output directory for artifacts (parquet/csv)
++-+    kwargs   : optional tuning params (ema windows, resample rules, etc.)
++-+    Returns
++-+    -------
++-+    dict with key outputs, e.g. file paths or small result stats
++-+    """
++-+    csv_path = Path(csv_path)
++-+    out_dir = Path(out_dir)
++-+    out_dir.mkdir(parents=True, exist_ok=True)
++-+
++-+    if not csv_path.exists():
++-+        raise FileNotFoundError(f"Input CSV not found: {csv_path}")
++-+
++-+    log.info("Loading data from %s", csv_path)
++-+    df2 = pd.read_csv(csv_path)
++-+    df2.columns = _clean_headers(df2.columns)  # your existing helper
++-+
++-+    # ... your existing transforms/features/resampling/regimes here ...
++-+    # write outputs to out_dir
++-+    # e.g., (keep your current filenames, just write relative to out_dir)
++-+    # df_daily.to_parquet(out_dir / "daily_en.parquet")
++-+    # df_weekly.to_parquet(out_dir / "weekly_en.parquet")
++-+    # stats.to_csv(out_dir / "regime_stats.csv", index=False)
++-+
++-+    return {
++-+        "input": str(csv_path),
++-+        "out_dir": str(out_dir),
++-+        # "n_rows": len(df2),
++-+        # "artifacts": [str(out_dir / "daily_en.parquet"), ...]
++-+    }
++-+
++-+if __name__ == "__main__":
++-+    # Local manual run (kept for convenience)
++-+    DEFAULT_ROOT = Path(__file__).resolve().parents[3]
++-+    csv = DEFAULT_ROOT / "data" / "Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
++-+    out_ = DEFAULT_ROOT / "out"
++-+    run_btc_pipeline(csv_path=csv, out_dir=out_)
+++from __future__ import annotations
+++from pathlib import Path
+++import pandas as pd
+++
+++def run_btc_pipeline(
+++    csv_path: str | Path,
+++    out_dir: str | Path,
+++    ema_windows: list[int] | None = None,
+++    resample: dict | None = None,
+++):
+++    """
+++    Orchestrate the BTC pipeline:
+++      1) load CSV (from csv_path)
+++      2) compute features / regimes (call your existing helpers)
+++      3) write outputs to out_dir
+++    """
+++    csv_path = Path(csv_path)
+++    out_dir = Path(out_dir)
+++    out_dir.mkdir(parents=True, exist_ok=True)
+++
+++    # ---- 1) Load data (NO hard-coded paths) ----
+++    df = pd.read_csv(csv_path)
+++
+++    # TODO: call your existing feature/resample/regime functions here, e.g.:
+++    # df = add_base_features(df, ema_windows=ema_windows, resample=resample)
+++    # regimes = compute_regimes(df)
+++    # Save outputs:
+++    # df.to_parquet(out_dir / "daily_en.parquet")
+++    # regimes.to_parquet(out_dir / "daily_regimes.parquet")
+++
+++    # For now just return a tiny status so CLI works:
+++    return {"rows": len(df), "out_dir": str(out_dir)}
+++
+++if __name__ == "__main__":
+++    # Optional: ad-hoc local test; never runs during import.
+++    raise SystemExit("Use the CLI or call run_btc_pipeline() from code.")
+diff --git a/pyproject.toml b/pyproject.toml
+index 9a6a43d..80c8849 100644
+--- a/pyproject.toml
++++ b/pyproject.toml
+@@ -1,21 +1,37 @@
+- [project]
+- name = "ta_lab2"
+- version = "0.1.0"
+- requires-python = ">=3.10"
+- dependencies = [
+--    # your runtime deps here
+-+    "pandas",
+-+    "pyyaml",
+- ]
+-
+-+[project.optional-dependencies]
+-+dev = [
+-+    "pytest",
+-+    "mypy",
+-+    "ruff",
+-+    "pytest-benchmark",
+-+    "hypothesis",
+-+]
+-+
+-+[project.scripts]
+-+ta-lab2 = "ta_lab2.cli:main"
++[build-system]
++requires = ["setuptools>=68", "wheel"]
++build-backend = "setuptools.build_meta"
++
++[project]
++name = "ta_lab2"
++version = "0.1.0"
++description = "Technical analysis & regime-detection toolkit"
++readme = "README.md"
++requires-python = ">=3.10"
++dependencies = [
++  "pandas",
++  "pyyaml",
++]
++
++[project.optional-dependencies]
++dev = [
++  "pytest",
++  "mypy",
++  "ruff",
++  "pytest-benchmark",
++  "hypothesis",
++]
++
++[project.scripts]
++ta-lab2 = "ta_lab2.cli:main"
++
++# Tell setuptools to find packages under src/
++[tool.setuptools.packages.find]
++where = ["src"]
++
++# Also install the top-level config.py module (so `from config import ...` works)
++[tool.setuptools]
++py-modules = ["config"]
++
++[project.optional-dependencies]
++viz = ["matplotlib>=3.6"]
+\ No newline at end of file
+diff --git a/src/ta_lab2/__init__.py b/src/ta_lab2/__init__.py
+index 7840e43..b09a473 100644
+--- a/src/ta_lab2/__init__.py
++++ b/src/ta_lab2/__init__.py
+@@ -1,5 +1,43 @@
+--# current content
+-+from .regimes.run_btc_pipeline import run_btc_pipeline
+-+
+-+__all__ = ["run_btc_pipeline"]
+-+__version__ = "0.1.0"
++# src/ta_lab2/__init__.py
++"""
++ta_lab2
++--------
++
++Technical Analysis and Regime Detection Lab
++Modular feature extraction, volatility analytics, and visualization toolkit.
++"""
++
++from .regimes.run_btc_pipeline import run_btc_pipeline
++
++# === Feature Modules ===
++from .features.calendar import (
++    expand_datetime_features_inplace,
++    expand_multiple_timestamps,
++)
++from .features.trend import compute_trend_labels
++from .features.segments import build_flip_segments
++
++# === Visualization ===
++from .viz.all_plots import (
++    plot_ema_with_trend,
++    plot_consolidated_emas_like,
++    plot_realized_vol,
++)
++
++__version__ = "0.1.0"
++
++__all__ = [
++    # Core pipeline
++    "run_btc_pipeline",
++
++    # Features
++    "expand_datetime_features_inplace",
++    "expand_multiple_timestamps",
++    "compute_trend_labels",
++    "build_flip_segments",
++
++    # Visualization
++    "plot_ema_with_trend",
++    "plot_consolidated_emas_like",
++    "plot_realized_vol",
++]
+diff --git a/src/ta_lab2/cli.py b/src/ta_lab2/cli.py
+index 3131e8d..1b8350c 100644
+--- a/src/ta_lab2/cli.py
++++ b/src/ta_lab2/cli.py
+@@ -1,27 +1,39 @@
+ from __future__ import annotations
+ import argparse
+ from pathlib import Path
+-from .config import load_settings, project_root
+-from .regimes.run_btc_pipeline import run_btc_pipeline
++
++# Import from root-level config.py, not from ta_lab2.config
++from config import load_settings, project_root
++from ta_lab2.regimes.run_btc_pipeline import run_btc_pipeline
++
+
+ def main(argv: list[str] | None = None) -> int:
+     ap = argparse.ArgumentParser(prog="ta-lab2", description="ta_lab2 CLI")
+-    ap.add_argument("--config", "-c", default="configs/default.yaml",
+-                    help="Path to YAML config relative to project root")
++    ap.add_argument(
++        "--config", "-c",
++        default="config/default.yaml",
++        help="Path to YAML config relative to project root (default: config/default.yaml)"
++    )
+     args = ap.parse_args(argv)
+
+-    root = project_root()
+-    cfg_path = (root / args.config).resolve()
+-    settings = load_settings(cfg_path)
++    # Load settings from YAML via the root-level config.py
++    settings = load_settings(args.config)
+
+-    csv = (root / settings.data_csv).resolve()
+-    out_dir = (root / settings.out_dir).resolve()
++    # Resolve absolute paths for input and output
++    csv = Path(settings.data_csv)
++    out_dir = Path(settings.out_dir)
++
++    # Run main pipeline
++    result = run_btc_pipeline(
++        csv_path=csv,
++        out_dir=out_dir,
++        ema_windows=settings.ema_windows,
++        resample=settings.resample
++    )
+
+-    result = run_btc_pipeline(csv_path=csv, out_dir=out_dir,
+-                              ema_windows=settings.ema_windows,
+-                              resample=settings.resample)
+     print("Pipeline complete:", result)
+     return 0
+
++
+ if __name__ == "__main__":
+     raise SystemExit(main())
+diff --git a/src/ta_lab2/config.py b/src/ta_lab2/config.py
+deleted file mode 100644
+index b1797bd..0000000
+--- a/src/ta_lab2/config.py
++++ /dev/null
+@@ -1,24 +0,0 @@
+-from __future__ import annotations
+-from dataclasses import dataclass, field
+-from pathlib import Path
+-import yaml
+-
+-@dataclass
+-class Settings:
+-    data_csv: str
+-    out_dir: str = "out"
+-    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100])
+-    resample: dict = field(default_factory=lambda: {"weekly": "W-SUN", "monthly": "MS"})
+-
+-def load_settings(path: str | Path) -> Settings:
+-    p = Path(path)
+-    data = yaml.safe_load(p.read_text(encoding="utf-8"))
+-    return Settings(**data)
+-
+-def project_root(start: str | Path | None = None) -> Path:
+-    # walk up until we find pyproject.toml
+-    cur = Path(start or __file__).resolve()
+-    for ancestor in [cur, *cur.parents]:
+-        if (ancestor / "pyproject.toml").exists():
+-            return ancestor
+-    return cur  # fallback
+diff --git a/src/ta_lab2/config/default.yaml b/src/ta_lab2/config/default.yaml
+deleted file mode 100644
+index 4da5e13..0000000
+--- a/src/ta_lab2/config/default.yaml
++++ /dev/null
+@@ -1,9 +0,0 @@
+-# Paths are relative to the project root (where pyproject.toml lives)
+-data_csv: data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv
+-out_dir: out
+-
+-# Pipeline parameters (exampleâ€”extend as your code supports)
+-ema_windows: [21, 50, 100]
+-resample:
+-  weekly: "W-SUN"
+-  monthly: "MS"
+\ No newline at end of file
+diff --git a/src/ta_lab2/features/__init__.py b/src/ta_lab2/features/__init__.py
+index 9fa317e..b169b79 100644
+--- a/src/ta_lab2/features/__init__.py
++++ b/src/ta_lab2/features/__init__.py
+@@ -2,3 +2,23 @@ from .calendar import expand_datetime_features_inplace
+ from .ema import add_ema_columns, add_ema_d1, add_ema_d2
+ from .returns import add_returns
+ from .vol import add_atr
++
++# New imports for technical indicators
++from .indicators import rsi, macd, stoch_kd, bollinger, atr, adx, obv, mfi
++
++# New imports for correlation-based features
++from .correlation import acf, pacf_yw, rolling_autocorr, xcorr
++
++
++__all__ = [
++    # Core features
++    "expand_datetime_features_inplace",
++    "add_ema_columns", "add_ema_d1", "add_ema_d2",
++    "add_returns", "add_atr",
++
++    # Technical indicators
++    "rsi", "macd", "stoch_kd", "bollinger", "atr", "adx", "obv", "mfi",
++
++    # Correlation utilities
++    "acf", "pacf_yw", "rolling_autocorr", "xcorr",
++]
+diff --git a/src/ta_lab2/features/calendar.py b/src/ta_lab2/features/calendar.py
+index 350c794..6bdaf81 100644
+--- a/src/ta_lab2/features/calendar.py
++++ b/src/ta_lab2/features/calendar.py
+@@ -1,4 +1,5 @@
+-
++# src/ta_lab2/features/calendar.py
++from __future__ import annotations
+ import numpy as np
+ import pandas as pd
+
+@@ -8,6 +9,22 @@ try:
+ except Exception:
+     _HAS_ASTRONOMY = False
+
++
++def _session_bucket(hour: int) -> str:
++    """
++    Example bucketizer for trading-style sessions (UTC-based):
++    - 01-08: 'pre'
++    - 09-20: 'regular'
++    - 21-24/00: 'after'
++    Tweak to your venue/timezone as needed.
++    """
++    if 1 <= hour <= 8:
++        return "pre"
++    if 9 <= hour <= 20:
++        return "regular"
++    return "after"
++
++
+ def expand_datetime_features_inplace(
+     df: pd.DataFrame,
+     base_timestamp_col: str,
+@@ -20,7 +37,10 @@ def expand_datetime_features_inplace(
+     if base_timestamp_col not in df.columns:
+         print(f"Warning: Column '{base_timestamp_col}' not found. Skipping.")
+         return
++
+     dt = pd.to_datetime(df[base_timestamp_col], errors="coerce")
++
++    # Normalize to UTC for deterministic astronomy calcs
+     if getattr(dt.dt, "tz", None) is not None:
+         if to_utc:
+             dt = dt.dt.tz_convert("UTC")
+@@ -29,34 +49,83 @@ def expand_datetime_features_inplace(
+             dt = dt.dt.tz_localize("UTC", nonexistent="NaT", ambiguous="NaT")
+         except Exception:
+             dt = dt.dt.tz_localize("UTC")
++
+     if prefix is None:
+         prefix = base_timestamp_col
+     valid = dt.notna()
+
+-    # Day-of-week numbering
++    # US vs ISO weekday numbering
+     if us_week_start_sunday:
+-        dow_num = ((dt.dt.dayofweek + 1) % 7 + 1).astype("Int64")   # Sun=1..Sat=7
++        # Sun=1..Sat=7
++        dow_num = ((dt.dt.dayofweek + 1) % 7 + 1).astype("Int64")
++        week_of_year = dt.dt.isocalendar().week.astype("Int64")  # still ISO for comparability
++        iso_year = dt.dt.isocalendar().year.astype("Int64")
+     else:
+-        dow_num = dt.dt.isocalendar().day.astype("Int64")           # Mon=1..Sun=7
++        # Mon=1..Sun=7 (ISO)
++        dow_num = dt.dt.isocalendar().day.astype("Int64")
++        week_of_year = dt.dt.isocalendar().week.astype("Int64")
++        iso_year = dt.dt.isocalendar().year.astype("Int64")
+
++    # Unix seconds
+     unix_ns = dt.astype("int64")
+     unix_ns = pd.Series(unix_ns, index=df.index).where(valid)
+     unix_s  = (unix_ns // 10**9).astype("Int64")
+
++    # Days in month and nth day of month
++    # (via month boundaries difference)
++    month_start = dt.dt.to_period("M").dt.start_time
++    month_end   = dt.dt.to_period("M").dt.end_time
++    # careful: end_time is end-of-month at 23:59:59; use normalize for date arith
++    days_in_month = (month_end.dt.normalize() - month_start.dt.normalize()).dt.days.add(1).astype("Int64")
++    nth_day_of_month = dt.dt.day.astype("Int64")
++
++    # Week-of-month (1..5): 1st week = week number of first day baseline
++    wom = (
++        (dt.dt.day.add((dt.dt.to_period("M").dt.start_time.dt.dayofweek + 1) % 7) + 6) // 7
++    ).astype("Int64")
++
+     out = {
+         f"{prefix}_date": dt.dt.date,
+         f"{prefix}_time": dt.dt.time,
+-        f"{prefix}_year": dt.dt.year.astype("Int64"),
+-        f"{prefix}_month": dt.dt.month.astype("Int64"),
+-        f"{prefix}_day": dt.dt.day.astype("Int64"),
++
++        f"{prefix}_year":   dt.dt.year.astype("Int64"),
++        f"{prefix}_month":  dt.dt.month.astype("Int64"),
++        f"{prefix}_day":    dt.dt.day.astype("Int64"),
++
+         f"{prefix}_day_name": dt.dt.day_name(),
+-        f"{prefix}_day_of_week_num": dow_num,
+-        f"{prefix}_hour": dt.dt.hour.astype("Int64"),
++        f"{prefix}_day_of_week_num": dow_num,         # Sun=1..Sat=7 or Mon=1..Sun=7 (ISO)
++        f"{prefix}_iso_year": iso_year,               # ISO year (useful around New Year)
++        f"{prefix}_week_of_year": week_of_year,       # ISO weeks 1..53
++        f"{prefix}_week_of_month": wom,               # 1..5 (approx, aligns well in practice)
++
++        f"{prefix}_hour":   dt.dt.hour.astype("Int64"),
+         f"{prefix}_minute": dt.dt.minute.astype("Int64"),
+         f"{prefix}_second": dt.dt.second.astype("Int64"),
++
+         f"{prefix}_unix": unix_s,
+-        f"{prefix}_quarter": dt.dt.quarter.astype("Int64"),
++
++        f"{prefix}_quarter":   dt.dt.quarter.astype("Int64"),
+         f"{prefix}_year_half": ((dt.dt.quarter - 1) // 2 + 1).astype("Int64"),
++
++        # Boundary flags
++        f"{prefix}_is_month_start": dt.dt.is_month_start.astype("Int8"),
++        f"{prefix}_is_month_end":   dt.dt.is_month_end.astype("Int8"),
++        f"{prefix}_is_quarter_start": dt.dt.is_quarter_start.astype("Int8"),
++        f"{prefix}_is_quarter_end":   dt.dt.is_quarter_end.astype("Int8"),
++        f"{prefix}_is_year_start":    dt.dt.is_year_start.astype("Int8"),
++        f"{prefix}_is_year_end":      dt.dt.is_year_end.astype("Int8"),
++
++        # Day-of-year and business-day flag (Monâ€“Fri, not holiday-aware)
++        f"{prefix}_day_of_year": dt.dt.dayofyear.astype("Int64"),
++        f"{prefix}_is_business_day": pd.Series(
++            np.is_busday(dt.dt.date.astype("datetime64[D]"), weekmask='Mon Tue Wed Thu Fri'),
++            index=df.index
++        ).astype("Int8"),
++
++        # Session bucket (example; adjust to your venue)
++        f"{prefix}_session": dt.dt.hour.map(_session_bucket),
++        f"{prefix}_days_in_month": days_in_month,
++        f"{prefix}_nth_day_of_month": nth_day_of_month,
+     }
+
+     # Seasons (exact if astronomy present; else approx)
+@@ -72,13 +141,15 @@ def expand_datetime_features_inplace(
+         )
+
+     if _HAS_ASTRONOMY:
+-        cache = {}
++        cache: dict[int, dict[str, object]] = {}
+         def _season_exact(ts: pd.Timestamp):
+             if pd.isna(ts): return np.nan
+             y = ts.year
+-            if y not in cache:
+-                cache[y] = _season_boundaries(y)
+-            b = cache[y]; d = ts.date()
++            b = cache.get(y)
++            if b is None:
++                b = _season_boundaries(y)
++                cache[y] = b
++            d = ts.date()
+             if b["spring"] <= d < b["summer"]: return "Spring"
+             if b["summer"] <= d < b["fall"]:   return "Summer"
+             if b["fall"]   <= d < b["winter"]: return "Fall"
+@@ -127,3 +198,23 @@ def expand_datetime_features_inplace(
+         out[f"{prefix}_moon_illum_frac"] = moon_deg.apply(_illum)
+
+     df[list(out.keys())] = pd.DataFrame(out, index=df.index)
++
++
++def expand_multiple_timestamps(
++    df: pd.DataFrame,
++    cols: list[str],
++    *,
++    to_utc: bool = True,
++    add_moon: bool = True,
++    us_week_start_sunday: bool = True
++) -> None:
++    """
++    Convenience wrapper to expand several timestamp columns at once,
++    using each column name as its own prefix.
++    """
++    for c in cols:
++        expand_datetime_features_inplace(
++            df, base_timestamp_col=c, prefix=c,
++            to_utc=to_utc, add_moon=add_moon,
++            us_week_start_sunday=us_week_start_sunday
++        )
+diff --git a/src/ta_lab2/features/correlation.py b/src/ta_lab2/features/correlation.py
+new file mode 100644
+index 0000000..bd96500
+--- /dev/null
++++ b/src/ta_lab2/features/correlation.py
+@@ -0,0 +1,63 @@
++from __future__ import annotations
++import numpy as np
++import pandas as pd
++
++def acf(x: pd.Series, nlags: int = 40, demean: bool = True) -> pd.Series:
++    s = pd.Series(x).dropna().astype(float)
++    if len(s) == 0:
++        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="acf")
++    if demean:
++        s = s - s.mean()
++    var = (s**2).sum()
++    ac = [1.0]
++    for k in range(1, nlags + 1):
++        cov = (s.iloc[k:] * s.iloc[:-k]).sum()
++        ac.append(float(cov / var) if var != 0 else np.nan)
++    return pd.Series(ac, index=range(0, nlags + 1), name="acf")
++
++def pacf_yw(x: pd.Series, nlags: int = 20) -> pd.Series:
++    s = pd.Series(x).dropna().astype(float)
++    if len(s) == 0:
++        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="pacf")
++    s = s - s.mean()
++    # autocov sequence
++    gamma = np.array([
++        (s[:len(s)-k] @ s[k:]) / len(s) if k > 0 else (s @ s) / len(s)
++        for k in range(0, nlags+1)
++    ])
++    pac = np.zeros(nlags+1)
++    pac[0] = 1.0
++    phi = np.zeros((nlags+1, nlags+1))
++    var = gamma[0]
++    for k in range(1, nlags+1):
++        num = gamma[k] - np.sum(phi[k-1,1:k] * gamma[1:k][::-1])
++        den = var - np.sum(phi[k-1,1:k] * gamma[1:k])
++        phi[k,k] = num / den if den != 0 else np.nan
++        for j in range(1, k):
++            phi[k,j] = phi[k-1,j] - phi[k,k]*phi[k-1,k-j]
++        pac[k] = phi[k,k]
++    return pd.Series(pac, index=range(0, nlags+1), name="pacf")
++
++def rolling_autocorr(s: pd.Series, lag: int = 1, window: int = 100) -> pd.Series:
++    return s.rolling(window).corr(s.shift(lag)).rename(f"roll_ac_{lag}_{window}")
++
++def xcorr(a: pd.Series, b: pd.Series, max_lag: int = 20, demean: bool = True) -> pd.Series:
++    A = pd.Series(a).astype(float)
++    B = pd.Series(b).astype(float)
++    A, B = A.align(B, join="inner")
++    if len(A) == 0:
++        return pd.Series([np.nan]*(2*max_lag+1), index=range(-max_lag, max_lag+1), name="xcorr")
++    if demean:
++        A, B = A - A.mean(), B - B.mean()
++    var = np.sqrt((A**2).sum() * (B**2).sum())
++    vals = []
++    lags = range(-max_lag, max_lag + 1)
++    for k in lags:
++        if k < 0:
++            cov = (A[:k] * B[-k:]).sum()
++        elif k > 0:
++            cov = (A[k:] * B[:-k]).sum()
++        else:
++            cov = (A * B).sum()
++        vals.append(float(cov / var) if var != 0 else np.nan)
++    return pd.Series(vals, index=list(lags), name="xcorr")
+diff --git a/src/ta_lab2/features/indicators.py b/src/ta_lab2/features/indicators.py
+new file mode 100644
+index 0000000..a71a0a4
+--- /dev/null
++++ b/src/ta_lab2/features/indicators.py
+@@ -0,0 +1,94 @@
++from __future__ import annotations
++import numpy as np
++import pandas as pd
++
++# ---- helpers ----
++def _ema(s: pd.Series, span: int) -> pd.Series:
++    return s.ewm(span=span, adjust=False).mean()
++
++def _sma(s: pd.Series, window: int) -> pd.Series:
++    return s.rolling(window, min_periods=window).mean()
++
++def _tr(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:
++    prev_close = close.shift(1)
++    return pd.concat([
++        (high - low).abs(),
++        (high - prev_close).abs(),
++        (low - prev_close).abs()
++    ], axis=1).max(axis=1)
++
++# ---- indicators ----
++def rsi(close: pd.Series, window: int = 14) -> pd.Series:
++    delta = close.diff()
++    gain = delta.clip(lower=0)
++    loss = -delta.clip(upper=0)
++    avg_gain = gain.ewm(alpha=1/window, adjust=False).mean()
++    avg_loss = loss.ewm(alpha=1/window, adjust=False).mean()
++    rs = avg_gain / (avg_loss.replace(0, np.nan))
++    out = 100 - (100 / (1 + rs))
++    return out.rename(f"rsi_{window}")
++
++def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:
++    ema_fast = _ema(close, fast)
++    ema_slow = _ema(close, slow)
++    macd_line = ema_fast - ema_slow
++    signal_line = _ema(macd_line, signal)
++    hist = macd_line - signal_line
++    return pd.DataFrame({
++        f"macd_{fast}_{slow}": macd_line,
++        f"macd_signal_{signal}": signal_line,
++        f"macd_hist_{fast}_{slow}_{signal}": hist
++    })
++
++def stoch_kd(high: pd.Series, low: pd.Series, close: pd.Series, k: int = 14, d: int = 3) -> pd.DataFrame:
++    lowest = low.rolling(k, min_periods=k).min()
++    highest = high.rolling(k, min_periods=k).max()
++    k_line = 100 * (close - lowest) / (highest - lowest)
++    d_line = k_line.rolling(d, min_periods=d).mean()
++    return pd.DataFrame({f"stoch_k_{k}": k_line, f"stoch_d_{d}": d_line})
++
++def bollinger(close: pd.Series, window: int = 20, n_sigma: float = 2.0) -> pd.DataFrame:
++    ma = _sma(close, window)
++    std = close.rolling(window, min_periods=window).std()
++    upper = ma + n_sigma * std
++    lower = ma - n_sigma * std
++    bw = (upper - lower) / ma
++    return pd.DataFrame({
++        f"bb_ma_{window}": ma,
++        f"bb_up_{window}_{n_sigma}": upper,
++        f"bb_lo_{window}_{n_sigma}": lower,
++        f"bb_width_{window}": bw
++    })
++
++def atr(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
++    tr = _tr(high, low, close)
++    out = tr.rolling(window, min_periods=window).mean()
++    return out.rename(f"atr_{window}")
++
++def adx(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
++    up = high.diff()
++    dn = -low.diff()
++    plus_dm  = np.where((up > dn) and isinstance(up, pd.Series) and (up > 0), up, 0.0)
++    minus_dm = np.where((dn > up) and isinstance(dn, pd.Series) and (dn > 0), dn, 0.0)
++    tr = _tr(high, low, close)
++    atr_ = tr.rolling(window, min_periods=window).mean()
++    plus_di  = 100 * pd.Series(plus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
++    minus_di = 100 * pd.Series(minus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
++    dx = ((plus_di - minus_di).abs() / (plus_di + minus_di)) * 100
++    adx_ = dx.rolling(window, min_periods=window).mean()
++    return adx_.rename(f"adx_{window}")
++
++def obv(close: pd.Series, volume: pd.Series) -> pd.Series:
++    direction = np.sign(close.diff().fillna(0))
++    return (direction * volume).fillna(0).cumsum().rename("obv")
++
++def mfi(high: pd.Series, low: pd.Series, close: pd.Series, volume: pd.Series, window: int = 14) -> pd.Series:
++    tp = (high + low + close) / 3.0
++    raw = tp * volume
++    pos = raw.where(tp.diff() > 0, 0.0)
++    neg = raw.where(tp.diff() < 0, 0.0)
++    mr = pos.rolling(window, min_periods=window).sum() / (
++        neg.rolling(window, min_periods=window).sum().replace(0, np.nan)
++    )
++    out = 100 - (100 / (1 + mr))
++    return out.rename(f"mfi_{window}")
+diff --git a/src/ta_lab2/features/vol.py b/src/ta_lab2/features/vol.py
+index 64a9858..945ce28 100644
+--- a/src/ta_lab2/features/vol.py
++++ b/src/ta_lab2/features/vol.py
+@@ -1,15 +1,264 @@
+-
+-import pandas as pd
++from __future__ import annotations
+ import numpy as np
++import pandas as pd
++from typing import Sequence, Iterable, Literal
++
++# =========================================================
++# ---- Core Volatility Estimators (single-bar + rolling) ---
++# =========================================================
++
++def add_parkinson_vol(
++    df: pd.DataFrame,
++    high_col: str = "high",
++    low_col: str = "low",
++    windows: Sequence[int] = (20, 63, 126),
++    annualize: bool = True,
++    periods_per_year: int = 252,
++) -> pd.DataFrame:
++    """Parkinson (1980) range-based volatility estimator."""
++    high, low = df[high_col].astype(float), df[low_col].astype(float)
++    coef = 1.0 / (4.0 * np.log(2.0))
++    hl = (np.log(high / low)) ** 2
++    for w in windows:
++        vol = np.sqrt(coef * hl.rolling(w, min_periods=w).mean())
++        if annualize:
++            vol *= np.sqrt(periods_per_year)
++        df[f"vol_parkinson_{w}"] = vol
++    return df
++
++
++def add_garman_klass_vol(
++    df: pd.DataFrame,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++    windows: Sequence[int] = (20, 63, 126),
++    annualize: bool = True,
++    periods_per_year: int = 252,
++) -> pd.DataFrame:
++    """Garmanâ€“Klass (1980) volatility estimator."""
++    o, h, l, c = [df[k].astype(float) for k in (open_col, high_col, low_col, close_col)]
++    rs = 0.5 * (np.log(h/l))**2 - (2*np.log(2)-1) * (np.log(c/o))**2
++    for w in windows:
++        vol = np.sqrt(rs.rolling(w, min_periods=w).mean())
++        if annualize:
++            vol *= np.sqrt(periods_per_year)
++        df[f"vol_gk_{w}"] = vol
++    return df
+
+-def add_atr(df: pd.DataFrame, period: int = 14,
+-            high_col="high", low_col="low", close_col="close"):
+-    high = df[high_col].astype(float)
+-    low  = df[low_col].astype(float)
+-    close = df[close_col].astype(float)
+-    prev_close = close.shift(1)
+-    tr = (high - low).abs()
+-    tr = np.maximum(tr, (high - prev_close).abs())
+-    tr = np.maximum(tr, (low - prev_close).abs())
++
++def add_rogers_satchell_vol(
++    df: pd.DataFrame,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++    windows: Sequence[int] = (20, 63, 126),
++    annualize: bool = True,
++    periods_per_year: int = 252,
++) -> pd.DataFrame:
++    """Rogersâ€“Satchell (1991) volatility estimator."""
++    o, h, l, c = [df[k].astype(float) for k in (open_col, high_col, low_col, close_col)]
++    rs = (np.log(h/c) * np.log(h/o) + np.log(l/c) * np.log(l/o))
++    for w in windows:
++        vol = np.sqrt(rs.rolling(w, min_periods=w).mean())
++        if annualize:
++            vol *= np.sqrt(periods_per_year)
++        df[f"vol_rs_{w}"] = vol
++    return df
++
++
++def add_atr(
++    df: pd.DataFrame,
++    period: int = 14,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++) -> pd.DataFrame:
++    """Average True Range (Wilder)."""
++    h, l, c = df[high_col].astype(float), df[low_col].astype(float), df[close_col].astype(float)
++    prev_close = c.shift(1)
++    tr = (h - l).abs()
++    tr = np.maximum(tr, (h - prev_close).abs())
++    tr = np.maximum(tr, (l - prev_close).abs())
+     df[f"atr_{period}"] = tr.ewm(alpha=1/period, adjust=False).mean()
+     return df
++
++
++def add_logret_stdev_vol(
++    df: pd.DataFrame,
++    logret_cols: Sequence[str] = ("close_log_delta",),
++    windows: Sequence[int] = (20, 63, 126),
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    ddof: int = 0,
++    prefix: str = "vol",
++) -> pd.DataFrame:
++    """Rolling std of log returns."""
++    for name in logret_cols:
++        if name not in df.columns:
++            continue
++        r = df[name].astype(float)
++        for w in windows:
++            vol = r.rolling(w, min_periods=w).std(ddof=ddof)
++            if annualize:
++                vol *= np.sqrt(periods_per_year)
++            df[f"{prefix}_{name}_stdev_{w}"] = vol
++    return df
++
++
++def add_rolling_realized_batch(
++    df: pd.DataFrame,
++    windows: Sequence[int] = (20, 63, 126),
++    which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++) -> pd.DataFrame:
++    """Compute realized vol (Parkinson, RS, GK) across windows."""
++    if "parkinson" in which:
++        add_parkinson_vol(df, high_col=high_col, low_col=low_col, windows=windows,
++                          annualize=annualize, periods_per_year=periods_per_year)
++    if "rs" in which:
++        add_rogers_satchell_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
++                                windows=windows, annualize=annualize, periods_per_year=periods_per_year)
++    if "gk" in which:
++        add_garman_klass_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
++                             windows=windows, annualize=annualize, periods_per_year=periods_per_year)
++    return df
++
++
++# =========================================================
++# -------------- Compatibility Shims ----------------------
++# =========================================================
++
++def add_rolling_vol_from_returns_batch(
++    df: pd.DataFrame,
++    *,
++    # New API
++    close_col: str = "close",
++    windows: Sequence[int] = (20, 63, 126),
++    types: Literal["log", "pct", "both"] = "log",
++    annualize: bool = True,
++    periods_per_year: int = 252,
++    ddof: int = 0,
++    prefix: str = "vol",
++    # Legacy API
++    price_col: str | None = None,
++    modes: Iterable[str] | None = None,
++    direction: str | None = None,
++) -> pd.DataFrame:
++    """Rolling historical volatility (new + legacy API)."""
++    # --- Backward compat mapping ---
++    if price_col is not None:
++        close_col = price_col
++    if modes is not None:
++        modes = tuple(str(m).lower() for m in modes)
++        if "log" in modes and "pct" in modes:
++            types = "both"
++        elif "pct" in modes:
++            types = "pct"
++        else:
++            types = "log"
++
++    px = df[close_col].astype(float)
++    r_log = np.log(px / px.shift(1))
++    r_pct = px.pct_change()
++
++    if types in ("log", "both"):
++        for w in windows:
++            vol = r_log.rolling(w, min_periods=w).std(ddof=ddof)
++            if annualize:
++                vol *= np.sqrt(periods_per_year)
++            df[f"{prefix}_log_roll_{w}"] = vol
++
++    if types in ("pct", "both"):
++        for w in windows:
++            vol = r_pct.rolling(w, min_periods=w).std(ddof=ddof)
++            if annualize:
++                vol *= np.sqrt(periods_per_year)
++            df[f"{prefix}_pct_roll_{w}"] = vol
++
++    return df
++
++
++def add_volatility_features(
++    df: pd.DataFrame,
++    *,
++    # single-bar
++    do_atr: bool = True,
++    do_parkinson: bool = True,
++    do_rs: bool = True,
++    do_gk: bool = True,
++    atr_period: int = 14,
++    # rolling returns vol
++    ret_windows: Sequence[int] = (20, 63, 126),
++    ret_types: Literal["log", "pct", "both"] = "both",
++    ret_annualize: bool = True,
++    ret_periods_per_year: int = 252,
++    ret_ddof: int = 0,
++    ret_prefix: str = "vol",
++    # rolling realized vol
++    rv_windows: Sequence[int] = (20, 63, 126),
++    rv_which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
++    rv_annualize: bool = True,
++    rv_periods_per_year: int = 252,
++    # column names
++    open_col: str = "open",
++    high_col: str = "high",
++    low_col: str = "low",
++    close_col: str = "close",
++    # Legacy API
++    rolling_windows: Sequence[int] | None = None,
++    direction: str | None = None,
++) -> pd.DataFrame:
++    """Unified volatility orchestrator with legacy support."""
++    # ---- Backward compatibility ----
++    if rolling_windows is not None:
++        ret_windows = tuple(rolling_windows)
++        rv_windows = tuple(rolling_windows)
++    # (direction accepted but unused; kept for API continuity)
++
++    # ---- Single-bar ----
++    if do_parkinson:
++        add_parkinson_vol(df, high_col=high_col, low_col=low_col, windows=(1,))
++    if do_rs:
++        add_rogers_satchell_vol(df, open_col=open_col, high_col=high_col, low_col=low_col,
++                                close_col=close_col, windows=(1,))
++    if do_gk:
++        add_garman_klass_vol(df, open_col=open_col, high_col=high_col, low_col=low_col,
++                             close_col=close_col, windows=(1,))
++    if do_atr:
++        add_atr(df, period=atr_period, high_col=high_col, low_col=low_col, close_col=close_col)
++
++    # ---- Rolling from returns ----
++    add_rolling_vol_from_returns_batch(
++        df,
++        close_col=close_col,
++        windows=ret_windows,
++        types=ret_types,
++        annualize=ret_annualize,
++        periods_per_year=ret_periods_per_year,
++        ddof=ret_ddof,
++        prefix=ret_prefix,
++    )
++
++    # ---- Rolling realized batch ----
++    add_rolling_realized_batch(
++        df,
++        windows=rv_windows,
++        which=rv_which,
++        annualize=rv_annualize,
++        periods_per_year=rv_periods_per_year,
++        open_col=open_col,
++        high_col=high_col,
++        low_col=low_col,
++        close_col=close_col,
++    )
++
++    return df
+diff --git a/src/ta_lab2/pipelines/btc_pipeline.py b/src/ta_lab2/pipelines/btc_pipeline.py
+index 26e2182..2876637 100644
+--- a/src/ta_lab2/pipelines/btc_pipeline.py
++++ b/src/ta_lab2/pipelines/btc_pipeline.py
+@@ -1,188 +1,161 @@
+-# -*- coding: utf-8 -*-
+-"""
+-Created on Fri Oct 31 16:05:09 2025
+-
+-@author: asafi
+-"""
+-
+-import os, re, argparse
++from __future__ import annotations
+ import pandas as pd
+-import numpy as np
+
+-from ta_lab2.resample import bin_by_calendar
+ from ta_lab2.features.calendar import expand_datetime_features_inplace
+-from ta_lab2.features.ema import add_ema_columns, add_ema_d1, add_ema_d2
+-from ta_lab2.features.returns import add_returns
+-from ta_lab2.features.vol import add_atr
+-from ta_lab2.regimes.comovement import build_alignment_frame, sign_agreement, rolling_agreement
+-from ta_lab2.regimes.flips import (
+-    sign_from_series, detect_flips, label_regimes_from_flips,
+-    attach_regimes, regime_stats
++from ta_lab2.features.ema import add_ema_columns, add_ema_d1, add_ema_d2, prepare_ema_helpers
++from ta_lab2.features.returns import b2t_pct_delta, b2t_log_delta
++from ta_lab2.features.vol import (
++    add_volatility_features,            # shim (see vol.py update)
++    add_rolling_vol_from_returns_batch, # shim (see vol.py update)
+ )
+-
+-# -------- utils --------
+-
+-def _clean_headers(cols):
+-    return [re.sub(r"\s+", " ", c.strip().lower()).replace(" ", "_") for c in cols]
+-
+-def _to_num(s):
+-    return pd.to_numeric(
+-        pd.Series(s).astype(str).str.replace(",", "", regex=False).replace({"-": None, "": None}),
+-        errors="coerce"
+-    )
+-
+-def _parse_epoch_series(x: pd.Series) -> pd.Series:
+-    x = pd.to_numeric(x, errors="coerce")
+-    if x.dropna().median() > 10_000_000_000:
+-        return pd.to_datetime(x, unit="ms", utc=True, errors="coerce")
+-    return pd.to_datetime(x, unit="s", utc=True, errors="coerce")
+-
+-def _scal(s):
+-    return s.iloc[0] if hasattr(s, "iloc") else s
+-
+-# -------- IO + cleaning --------
+-
+-def load_clean_csv(csv_path: str) -> pd.DataFrame:
++from ta_lab2.features.indicators import rsi, macd, bollinger  # lightweight stubs
++from ta_lab2.regimes.comovement import (
++    compute_ema_comovement_stats,
++    compute_ema_comovement_hierarchy,
++)
++from ta_lab2.regimes.segments import build_flip_segments  # thin wrapper
++
++
++def _infer_timestamp_col(df: pd.DataFrame, fallback: str = "timestamp") -> str:
++    if fallback in df.columns:
++        return fallback
++    for c in df.columns:
++        if "time" in str(c).lower():
++            return c
++    return fallback
++
++
++def run_btc_pipeline(
++    csv_path: str,
++    price_cols=("open", "high", "low", "close"),
++    timestamp_col="timestamp",
++    ema_windows=(21, 50, 100, 200),
++    resample: str | None = None,   # e.g., "1H", "1D"
++    returns_modes=("log", "pct"),
++    returns_windows=(30, 60, 90),
++) -> dict:
++    """
++    End-to-end, testable pipeline aligned to the modular ta_lab2 layout.
++    Returns a dict of key tables for downstream use.
++    """
+     df = pd.read_csv(csv_path)
+-    df.columns = _clean_headers(df.columns)
+-
+-    # Build timeopen (prefer timeopen; fallback to epoch timestamp)
+-    if "timeopen" in df.columns:
+-        dt = pd.to_datetime(df["timeopen"], errors="coerce", utc=True)
+-    else:
+-        dt = pd.NaT
+-
+-    if dt.isna().mean() > 0.5 and "timestamp" in df.columns:
+-        ts_dt = _parse_epoch_series(df["timestamp"])
+-        if ts_dt.notna().sum() > dt.notna().sum():
+-            dt = ts_dt
+-
+-    if pd.isna(dt).all():
+-        raise KeyError("Could not parse timestamps from 'timeOpen' or 'timestamp'.")
+-
+-    df["timeopen"] = dt
+-    for col in ["open", "high", "low", "close", "volume", "marketcap"]:
+-        if col in df.columns:
+-            df[col] = _to_num(df[col])
+-
+-    df = df.dropna(subset=["timeopen"]).sort_values("timeopen").reset_index(drop=True)
+-
+-    print("Loaded rows:", len(df))
+-    print("Date range:", df["timeopen"].min(), "â†’", df["timeopen"].max())
+-    print("Columns now:", list(df.columns))
+-    return df
+-
+-# -------- timeframes --------
+-
+-def build_timeframes(df: pd.DataFrame):
+-    expand_datetime_features_inplace(df, "timeopen", prefix="timeopen")
+-
+-    weekly = bin_by_calendar(df, "timeopen", "W-SUN").rename(columns={"period_end": "date"})
+-    weekly["timeframe"] = "1W"
+-
+-    monthly = bin_by_calendar(df, "timeopen", "MS").rename(columns={"period_end": "date"})
+-    monthly["timeframe"] = "1M"
+-
+-    daily = df.rename(columns={"timeopen": "date"})[["date","open","high","low","close","volume"]].copy()
+-    daily["timeframe"] = "1D"
+-
+-    for d in (daily, weekly, monthly):
+-        d["symbol"] = "BTC-USD"
+-
+-    return daily, weekly, monthly
+-
+-# -------- enrichment --------
+-
+-def enrich(bars: pd.DataFrame) -> pd.DataFrame:
+-    add_returns(bars, close_col="close")  # local impl: creates close_ret_1
+-    add_ema_columns(bars, ["close"], [21,50,100,200])
+-    add_ema_d1(bars, ["close"], [21,50,100,200])
+-    add_ema_d2(bars, ["close"], [21,50,100,200])
+-    add_atr(bars, period=14, high_col="high", low_col="low", close_col="close")
+-    return bars
+-
+-def enrich_all(daily, weekly, monthly):
+-    return enrich(daily.copy()), enrich(weekly.copy()), enrich(monthly.copy())
+-
+-# -------- diagnostics --------
+-
+-def print_ema21_agreement(daily_en: pd.DataFrame, weekly_en: pd.DataFrame):
+-    d = daily_en[["date","close_ema_21_d1"]].sort_values("date")
+-    w = weekly_en[["date","close_ema_21_d1"]].sort_values("date").rename(columns={"close_ema_21_d1":"close_ema_21_d1_w"})
+-    cmp = pd.merge_asof(d, w, on="date", direction="backward")
+-    cmp["ema21_d1_agree"] = (cmp["close_ema_21_d1"] * cmp["close_ema_21_d1_w"]) > 0
+-    print("Daily vs Weekly EMA21 slope agreement:", f"{cmp['ema21_d1_agree'].mean():.2%}")
+-
+-def boundary_check(daily, weekly, monthly, dates_utc):
+-    for dt_str in dates_utc:
+-        dt = pd.Timestamp(dt_str, tz="UTC")
+-        drow = daily.loc[daily["date"] == dt]
+-        wrow = weekly.loc[weekly["date"] == dt]
+-        mrow = monthly.loc[monthly["date"] == dt]
+-        if not drow.empty and not wrow.empty:
+-            print("WEEK check:", dt_str, "daily open:", float(_scal(drow["open"])), "weekly open:", float(_scal(wrow["open"])))
+-        if not drow.empty and not mrow.empty:
+-            print("MONTH check:", dt_str, "daily open:", float(_scal(drow["open"])), "monthly open:", float(_scal(mrow["open"])))
+-
+-# -------- regimes --------
+-
+-def compute_regimes(daily_en: pd.DataFrame):
+-    daily_sig = sign_from_series(daily_en.copy(), "close_ema_21_d1", out_col="d_slope_sign")
+-
+-    if "close_ret_1" not in daily_sig.columns:
+-        add_returns(daily_sig, close_col="close")
+-
+-    flips = detect_flips(daily_sig, "d_slope_sign", min_separation=2)
+-    regime_ids = label_regimes_from_flips(len(daily_sig), flips["idx"].tolist())
+-    daily_reg = attach_regimes(daily_sig, regime_ids, col="regime_id")
+-
+-    if "close_ret_1" not in daily_reg.columns:
+-        # fallback: compute forward simple return
+-        daily_reg["close_ret_1"] = (daily_reg["close"].shift(-1) / daily_reg["close"]) - 1
+-
+-    stats = regime_stats(daily_reg, regime_col="regime_id", ret_col="close_ret_1")
+-    return daily_reg, stats
+-
+-# -------- comovement --------
+-
+-def compute_comovement(daily_en: pd.DataFrame, weekly_en: pd.DataFrame):
+-    al = build_alignment_frame(
+-        daily_en, weekly_en,
+-        on="date", low_cols=["close_ema_21_d1"], high_cols=["close_ema_21_d1"]
+-    ).rename(columns={"close_ema_21_d1": "d_slope", "close_ema_21_d1_w": "w_slope"})
+-    al, pct = sign_agreement(al, "d_slope", "w_slope", out_col="agree")
+-    al = rolling_agreement(al, "d_slope", "w_slope", window=63)
+-    return al, pct
+-
+-# -------- main --------
+-
+-def main(argv=None):
+-    ap = argparse.ArgumentParser()
+-    ap.add_argument("--csv", required=True, help="Path to BTC CSV (CoinMarketCap export).")
+-    ap.add_argument("--outdir", default="", help="Optional directory to save artifacts.")
+-    ap.add_argument("--check", nargs="*", help="Optional UTC dates to boundary-check, e.g. 2015-01-01 2015-02-01")
+-    args = ap.parse_args(argv)
+-
+-    df = load_clean_csv(args.csv)
+-    daily, weekly, monthly = build_timeframes(df)
+-    daily_en, weekly_en, monthly_en = enrich_all(daily, weekly, monthly)
++    df.columns = [str(c).strip().lower() for c in df.columns]
++    timestamp_col = _infer_timestamp_col(df, timestamp_col)
++    df = df.rename(columns={timestamp_col: "timestamp"})
++
++    # NOTE: new API name is base_timestamp_col (not ts_col)
++    expand_datetime_features_inplace(df, base_timestamp_col="timestamp")
++
++    # Optional resample (OHLCV)
++    if resample:
++        agg = {"open": "first", "high": "max", "low": "min", "close": "last", "volume": "sum"}
++        have = {k: v for k, v in agg.items() if k in df.columns}
++        if have:
++            df = (
++                df.set_index("timestamp")
++                  .resample(resample)
++                  .agg(have)
++                  .dropna()
++                  .reset_index()
++            )
++            expand_datetime_features_inplace(df, base_timestamp_col="timestamp")
++
++    # Indicators (simple stubs to keep imports working)
++    if "close" in df.columns:
++        out = rsi(df, period=14, price_col="close")
++        df[out.name] = out
++        df = df.join(macd(df, price_col="close"))
++        df = df.join(bollinger(df, price_col="close"))
++
++    # Quick engineered columns
++    if all(k in df.columns for k in ("high", "low", "close", "open")):
++        df["close-open"] = df["close"].astype(float) - df["open"].astype(float)
++        df["range"] = df["high"].astype(float) - df["low"].astype(float)
++
++    # Bar-to-bar deltas (percent + log)
++    b2t_pct_delta(
++        df,
++        cols=list(price_cols) + ["close-open"],
++        extra_cols=["range"],
++        round_places=6,
++        direction="newest_top",
++        open_col="open",
++        close_col="close",
++    )
++    b2t_log_delta(
++        df,
++        cols=list(price_cols) + ["close-open"],
++        extra_cols=["range"],
++        prefix="_log_delta",
++        round_places=6,
++        add_intraday=True,
++        open_col="open",
++        close_col="close",
++    )
+
+-    print_ema21_agreement(daily_en, weekly_en)
++    # Volatility (single-bar + rolling realized) via shims
++    df = add_volatility_features(
++        df,
++        do_atr=True, do_parkinson=True, do_rs=True, do_gk=True,
++        rolling_windows=tuple(returns_windows),
++        direction="newest_top",
++    )
++    df = add_rolling_vol_from_returns_batch(
++        df,
++        price_col="close",
++        modes=returns_modes,
++        windows=tuple(returns_windows),
++        annualize=True,
++        direction="newest_top",
++    )
+
+-    if args.check:
+-        boundary_check(daily, weekly, monthly, args.check)
++    # EMAs + slopes
++    base_cols = list(price_cols)
++    add_ema_columns(df, base_cols, list(ema_windows))
++    add_ema_d1(df, base_cols, list(ema_windows), direction="newest_top", overwrite=False, round_places=6)
++    add_ema_d2(df, base_cols, list(ema_windows), direction="newest_top", overwrite=False, round_places=6)
++    prepare_ema_helpers(df, base_cols, list(ema_windows), direction="newest_top", scale="bps")
++
++    # Regime labels (close) and segments between EMA-slope sign flips
++    _, labeled = compute_ema_comovement_stats(
++        df.copy(),
++        periods=list(ema_windows),
++        direction="newest_top",
++        close_col="close",
++        return_col="close_pct_delta",
++    )
++    df["trend_state"] = labeled["regime_label"]
++
++    segments, seg_summary, seg_by_year = build_flip_segments(
++        df,
++        base_cols=("close",),
++        periods=list(ema_windows),
++        direction="newest_top",
++        scale="bps",
++        date_col="timestamp",
++        ema_name_fmt="{field}_ema_{period}",
++    )
+
+-    daily_reg, stats = compute_regimes(daily_en)
+-    print(stats.head())
+-
+-    al, pct = compute_comovement(daily_en, weekly_en)
++    major_stats, sub_stats, sub_stats_mixsum = compute_ema_comovement_hierarchy(
++        df,
++        periods=list(ema_windows),
++        close_col="close",
++        direction="newest_top",
++        return_col="close_pct_delta",
++    )
+
+-    if args.outdir:
+-        os.makedirs(args.outdir, exist_ok=True)
+-        daily_en.to_parquet(os.path.join(args.outdir, "daily_en.parquet"), index=False)
+-        weekly_en.to_parquet(os.path.join(args.outdir, "weekly_en.parquet"), index=False)
+-        monthly_en.to_parquet(os.path.join(args.outdir, "monthly_en.parquet"), index=False)
+-        daily_reg.to_parquet(os.path.join(args.outdir, "daily_regimes.parquet"), index=False)
+-        stats.to_csv(os.path.join(args.outdir, "regime_stats.csv"), index=False)
+-        al.to_parquet(os.path.join(args.outdir, "alignment.parquet"), index=False)
+-        print(f"Saved outputs to: {args.outdir}")
++    summary = {
++        "n_rows": int(len(df)),
++        "n_segments": int(len(segments)),
++        "mean_seg_return": float(segments["ret_close_to_close"].mean()) if len(segments) else 0.0,
++        "mean_seg_len": float(segments["bars"].mean()) if len(segments) else 0.0,
++    }
++    return {
++        "data": df,
++        "segments": segments,
++        "segment_summary": seg_summary,
++        "segment_by_year": seg_by_year,
++        "regime_major": major_stats,
++        "regime_sub": sub_stats_mixsum,
++        "summary": summary,
++    }
+diff --git a/src/ta_lab2/regimes/run_btc_pipeline.py b/src/ta_lab2/regimes/run_btc_pipeline.py
+index e620e67..dceb8d2 100644
+--- a/src/ta_lab2/regimes/run_btc_pipeline.py
++++ b/src/ta_lab2/regimes/run_btc_pipeline.py
+@@ -1,56 +1,36 @@
+-@@
+--# ---- load your CSV ---------------------------------------------------------
+--csv_path = r"C:/Users/asafi/Downloads/ta_lab2/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
+--df2 = pd.read_csv(csv_path)
+--# Normalize headers to stable names
+--df2.columns = _clean_headers(df2.columns)
+--...   # (rest of pipeline at import time)
+-+from pathlib import Path
+-+import pandas as pd
+-+import logging
+-+
+-+log = logging.getLogger(__name__)
+-+
+-+def run_btc_pipeline(csv_path: str | Path, out_dir: str | Path, **kwargs) -> dict:
+-+    """
+-+    Run the BTC pipeline.
+-+    Parameters
+-+    ----------
+-+    csv_path : path to source CSV
+-+    out_dir  : output directory for artifacts (parquet/csv)
+-+    kwargs   : optional tuning params (ema windows, resample rules, etc.)
+-+    Returns
+-+    -------
+-+    dict with key outputs, e.g. file paths or small result stats
+-+    """
+-+    csv_path = Path(csv_path)
+-+    out_dir = Path(out_dir)
+-+    out_dir.mkdir(parents=True, exist_ok=True)
+-+
+-+    if not csv_path.exists():
+-+        raise FileNotFoundError(f"Input CSV not found: {csv_path}")
+-+
+-+    log.info("Loading data from %s", csv_path)
+-+    df2 = pd.read_csv(csv_path)
+-+    df2.columns = _clean_headers(df2.columns)  # your existing helper
+-+
+-+    # ... your existing transforms/features/resampling/regimes here ...
+-+    # write outputs to out_dir
+-+    # e.g., (keep your current filenames, just write relative to out_dir)
+-+    # df_daily.to_parquet(out_dir / "daily_en.parquet")
+-+    # df_weekly.to_parquet(out_dir / "weekly_en.parquet")
+-+    # stats.to_csv(out_dir / "regime_stats.csv", index=False)
+-+
+-+    return {
+-+        "input": str(csv_path),
+-+        "out_dir": str(out_dir),
+-+        # "n_rows": len(df2),
+-+        # "artifacts": [str(out_dir / "daily_en.parquet"), ...]
+-+    }
+-+
+-+if __name__ == "__main__":
+-+    # Local manual run (kept for convenience)
+-+    DEFAULT_ROOT = Path(__file__).resolve().parents[3]
+-+    csv = DEFAULT_ROOT / "data" / "Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
+-+    out_ = DEFAULT_ROOT / "out"
+-+    run_btc_pipeline(csv_path=csv, out_dir=out_)
++from __future__ import annotations
++from pathlib import Path
++import pandas as pd
++
++def run_btc_pipeline(
++    csv_path: str | Path,
++    out_dir: str | Path,
++    ema_windows: list[int] | None = None,
++    resample: dict | None = None,
++):
++    """
++    Orchestrate the BTC pipeline:
++      1) load CSV (from csv_path)
++      2) compute features / regimes (call your existing helpers)
++      3) write outputs to out_dir
++    """
++    csv_path = Path(csv_path)
++    out_dir = Path(out_dir)
++    out_dir.mkdir(parents=True, exist_ok=True)
++
++    # ---- 1) Load data (NO hard-coded paths) ----
++    df = pd.read_csv(csv_path)
++
++    # TODO: call your existing feature/resample/regime functions here, e.g.:
++    # df = add_base_features(df, ema_windows=ema_windows, resample=resample)
++    # regimes = compute_regimes(df)
++    # Save outputs:
++    # df.to_parquet(out_dir / "daily_en.parquet")
++    # regimes.to_parquet(out_dir / "daily_regimes.parquet")
++
++    # For now just return a tiny status so CLI works:
++    return {"rows": len(df), "out_dir": str(out_dir)}
++
++if __name__ == "__main__":
++    # Optional: ad-hoc local test; never runs during import.
++    raise SystemExit("Use the CLI or call run_btc_pipeline() from code.")
+diff --git a/src/ta_lab2/viz/all_plots.py b/src/ta_lab2/viz/all_plots.py
+new file mode 100644
+index 0000000..667df9a
+--- /dev/null
++++ b/src/ta_lab2/viz/all_plots.py
+@@ -0,0 +1,195 @@
++from __future__ import annotations
++import pandas as pd
++import numpy as np
++import matplotlib.pyplot as plt
++
++# --- small utility: choose a time column if present ---
++def _pick_time_index(d: pd.DataFrame) -> pd.Index:
++    for c in ("timestamp", "timeclose", "date", "timeopen"):
++        if c in d.columns:
++            return pd.to_datetime(d[c], errors="coerce")
++    return d.index
++
++# --- Price + EMAs (+ optional slopes & flips), newest bar on the right ---
++def plot_ema_with_trend(
++    df: pd.DataFrame,
++    price_col: str = "close",
++    ema_cols=None,
++    trend_col: str = "trend_state",
++    *,
++    include_slopes: bool = True,
++    include_flips: bool = True,
++    n: int = 1000
++):
++    d = df.tail(n).copy()
++    # If caller didnâ€™t pass explicit EMA cols, auto-detect like <base>_ema_<p>
++    if ema_cols is None:
++        ema_cols = [c for c in d.columns if c.lower().startswith(("open_ema_","high_ema_","low_ema_","close_ema_"))]
++        if not ema_cols:  # fall back to any column starting with "ema_"
++            ema_cols = [c for c in d.columns if c.lower().startswith("ema_")]
++
++    x = np.arange(len(d))  # newest-on-top visual: invert x later
++    t = _pick_time_index(d)
++
++    fig, ax = plt.subplots(figsize=(12, 6))
++    ax.plot(x, d[price_col].to_numpy(), lw=1.3, label=price_col)
++
++    # left axis: EMAs
++    for c in ema_cols:
++        if c in d:
++            ax.plot(x, d[c].to_numpy(), lw=1.0, label=c)
++
++    ax2 = None
++    if include_slopes:
++        # try to find slope columns that match attached helpers: *_d1_bps / *_d1_norm
++        slope_cols = [c for c in d.columns if c.endswith("_d1_bps") or c.endswith("_d1_norm")]
++        if slope_cols:
++            ax2 = ax.twinx()
++            for sc in slope_cols:
++                ax2.plot(x, d[sc].to_numpy(), lw=0.8, alpha=0.8, label=sc)
++            ax2.axhline(0, ls="--", lw=1, alpha=0.8)
++
++            # match attached â€œsensible y-lims from all drawn slope seriesâ€
++            right_vals = np.concatenate([d[c].to_numpy()[~np.isnan(d[c].to_numpy())] for c in slope_cols if c in d])
++            if right_vals.size:
++                qlo, qhi = np.percentile(right_vals, [1, 99])
++                span = qhi - qlo
++                pad = (span * 0.25) if np.isfinite(span) and span > 0 else 10
++                ax2.set_ylim(qlo - pad, qhi + pad)
++
++    # optional flip markers (columns named like <base>_ema_<p>_flip), as in your attached utils
++    if include_flips:
++        flip_cols = [c for c in d.columns if c.endswith("_ema_21_flip") or c.endswith("_flip")]
++        # de-dup to avoid plotting tons of labels
++        plotted = False
++        for fc in flip_cols:
++            if fc in d:
++                idx = np.where(d[fc].to_numpy())[0]
++                if idx.size:
++                    # mark flips on the shortest EMA series available for better alignment
++                    base_for_mark = ema_cols[0] if ema_cols else price_col
++                    ax.scatter(idx, d[base_for_mark].to_numpy()[idx], c="k", marker="x", s=40,
++                               label=("flip" if not plotted else None))
++                    plotted = True
++
++    # optional trend track (your custom column)
++    if trend_col in d.columns:
++        ax3 = ax.twinx()
++        ax3.spines.right.set_position(("axes", 1.08))
++        ax3.plot(x, d[trend_col].to_numpy(), lw=0.8, alpha=0.25)
++        ax3.set_yticks([-1, 0, 1])
++        ax3.set_ylabel("trend")
++
++    # newest bar on the RIGHT to match your figures
++    ax.invert_xaxis()
++    ax.set_xticks(np.linspace(0, len(d)-1, 6, dtype=int))
++    ax.set_xticklabels(pd.to_datetime(t).astype("datetime64[ns]").to_series().iloc[ax.get_xticks().astype(int)].dt.date.astype(str), rotation=0)
++
++    ax.set_title("Price + EMAs + Slopes/Flips (newest on right)")
++    ax.set_xlabel("bars")
++    ax.legend(loc="upper left")
++    if include_slopes and ax2:
++        ax2.legend(loc="upper right")
++    plt.tight_layout()
++    return ax
++
++# --- Consolidated EMAs view (mirrors daf.plot_consolidated_emas) ---
++def plot_consolidated_emas_like(
++    df: pd.DataFrame,
++    base_col: str = "close",
++    periods=(21, 50, 100, 200),
++    *,
++    include_slopes: bool = True,
++    include_flips: bool = True,
++    n: int = 1000
++):
++    d = df.tail(n).copy()
++    x = np.arange(len(d))
++    t = _pick_time_index(d)
++
++    fig, ax = plt.subplots(figsize=(12, 6))
++
++    # all EMAs for this base on left axis
++    for p in periods:
++        ema = f"{base_col}_ema_{p}"
++        if ema not in d:
++            continue
++        ax.plot(x, d[ema].to_numpy(), lw=1.2, label=ema)
++
++    ax.invert_xaxis()
++    ax.set_title(f"{base_col.upper()} EMAs {', '.join(map(str, periods))}")
++    ax.set_xlabel("bars (newest on right)")
++    ax.legend(loc="upper left")
++
++    if include_slopes:
++        ax2 = ax.twinx()
++        right_series = []
++        for p in periods:
++            bps = f"{base_col}_ema_{p}_d1_bps"
++            pct = f"{base_col}_ema_{p}_d1_norm"
++            if bps in d:
++                ax2.plot(x, d[bps].to_numpy(), alpha=0.5, lw=0.9, label=f"slope bps (p={p})")
++                right_series.append(d[bps].to_numpy())
++            if pct in d:
++                ax2.plot(x, d[pct].to_numpy(), alpha=0.5, lw=0.9, label=f"slope % (p={p})")
++                right_series.append(d[pct].to_numpy())
++
++            if include_flips:
++                flip = f"{base_col}_ema_{p}_flip"
++                if flip in d:
++                    idx = np.where(d[flip].to_numpy())[0]
++                    if idx.size:
++                        ax.scatter(idx, d[f"{base_col}_ema_{p}"].to_numpy()[idx],
++                                   c="k", marker="x", s=40, label=f"flip {p}")
++        ax2.axhline(0, ls="--", lw=1, alpha=0.8)
++        ax2.legend(loc="upper right")
++
++        if right_series:
++            rs = np.concatenate([r[~np.isnan(r)] for r in right_series if r.size])
++            if rs.size:
++                qlo, qhi = np.percentile(rs, [1, 99])
++                span = qhi - qlo
++                pad = (span * 0.25) if np.isfinite(span) and span > 0 else 10
++                ax2.set_ylim(qlo - pad, qhi + pad)
++
++    plt.tight_layout()
++    return ax
++
++# --- Realized volatility panel: Parkinson, GK, RS (+ optional stdev of log returns) ---
++def plot_realized_vol(
++    df: pd.DataFrame,
++    *,
++    windows=(30, 60, 90),
++    include_logret_stdev: bool = True,
++    n: int = 1000
++):
++    d = df.tail(n).copy()
++    x = np.arange(len(d))
++    t = _pick_time_index(d)
++
++    fig, ax = plt.subplots(figsize=(12, 4))
++    plotted = False
++
++    # match generated names: parkinson_vol_<w>, gk_vol_<w> (or gk_vol_<w>), rs_vol_<w>
++    for w in windows:
++        for name in (f"parkinson_vol_{w}", f"gk_vol_{w}", f"rs_vol_{w}"):
++            if name in d.columns:
++                ax.plot(x, d[name].to_numpy(), lw=1.0, label=name)
++                plotted = True
++
++    # optional: rolling stdev of log returns (add_logret_stdev_vol)
++    if include_logret_stdev:
++        stdev_cols = [c for c in d.columns if c.endswith(tuple(f"_vol_stdev_{w}" for w in windows))]
++        for c in stdev_cols:
++            ax.plot(x, d[c].to_numpy(), lw=0.9, alpha=0.8, label=c)
++
++    if not plotted and not [c for c in d.columns if c.endswith("_vol_stdev_")]:
++        print("[plot skipped] No realized-vol columns found.")
++        return ax
++
++    ax.invert_xaxis()
++    ax.set_title("Realized Volatility (rolling)")
++    ax.set_xlabel("bars (newest on right)")
++    ax.legend(loc="upper left", ncol=2)
++    plt.tight_layout()
++    return ax
diff --git a/pyproject.toml b/pyproject.toml
index 9a6a43d..3c95784 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,21 +1,49 @@
- [project]
- name = "ta_lab2"
- version = "0.1.0"
- requires-python = ">=3.10"
- dependencies = [
--    # your runtime deps here
-+    "pandas",
-+    "pyyaml",
- ]
-
-+[project.optional-dependencies]
-+dev = [
-+    "pytest",
-+    "mypy",
-+    "ruff",
-+    "pytest-benchmark",
-+    "hypothesis",
-+]
-+
-+[project.scripts]
-+ta-lab2 = "ta_lab2.cli:main"
+[build-system]
+requires = ["setuptools>=68", "wheel"]
+build-backend = "setuptools.build_meta"
+
+[project]
+name = "ta_lab2"
+version = "0.1.0"
+description = "Technical analysis & regime-detection toolkit"
+readme = "README.md"
+requires-python = ">=3.10"
+
+# Core runtime deps used across the package
+dependencies = [
+  "pandas",
+  "pyyaml",
+  "numpy",
+]
+
+[project.scripts]
+ta-lab2 = "ta_lab2.cli:main"
+
+# ---------- Optional dependency groups (ALL IN ONE BLOCK) ----------
+[project.optional-dependencies]
+# Dev / CI convenience
+dev = [
+  "pytest>=8.0",
+  "pytest-benchmark",
+  "hypothesis",
+  "ruff>=0.1.5",
+  "mypy>=1.8",
+]
+
+# Plotting (used by viz/all_plots.py and CLI optional plots)
+viz = [
+  "matplotlib>=3.6",
+]
+
+# Astronomy extras for exact seasons/moon in calendar features
+astro = [
+  "astronomy-engine>=2.2.0",
+]
+
+# ---------- Setuptools (src/ layout + root module) ----------
+[tool.setuptools.packages.find]
+where = ["src"]
+
+# Also install the top-level config.py so `from config import load_settings` works
+[tool.setuptools]
+py-modules = ["config"]
diff --git a/pytest.ini b/pytest.ini
new file mode 100644
index 0000000..b04e1a7
--- /dev/null
+++ b/pytest.ini
@@ -0,0 +1,4 @@
+# pytest.ini
+[pytest]
+testpaths = tests
+pythonpath = src
\ No newline at end of file
diff --git a/src/ta_lab2/__init__.py b/src/ta_lab2/__init__.py
index 7840e43..29e17eb 100644
--- a/src/ta_lab2/__init__.py
+++ b/src/ta_lab2/__init__.py
@@ -1,5 +1,126 @@
--# current content
-+from .regimes.run_btc_pipeline import run_btc_pipeline
-+
-+__all__ = ["run_btc_pipeline"]
-+__version__ = "0.1.0"
+# src/ta_lab2/__init__.py
+from __future__ import annotations
+import importlib, sys
+
+# --- Expose feature submodules at top level for backward compatibility ---
+# e.g., allow: from ta_lab2.calendar import expand_datetime_features_inplace
+for _name in ("calendar", "ema", "returns", "indicators", "segments", "vol", "trend", "correlation"):
+    try:
+        _mod = importlib.import_module(f".features.{_name}", __name__)
+        sys.modules[f"{__name__}.{_name}"] = _mod
+    except Exception:
+        # Some projects may not include all submodules; ignore missing ones
+        pass
+
+# -------- Calendar / datetime features --------
+from .features.calendar import (
+    expand_datetime_features_inplace,
+    expand_multiple_timestamps,
+)
+
+# -------- EMA family --------
+from .features.ema import (
+    compute_ema,
+    add_ema_columns,
+    add_ema_d1,
+    add_ema_d2,
+    add_ema,  # legacy wrapper shim
+)
+
+# -------- Returns / deltas --------
+from .features.returns import (
+    add_returns,
+    b2t_pct_delta,
+    b2t_log_delta,
+)
+
+# -------- Rolling realized vol (robust import with shim) --------
+_add_rv_from_returns = None
+try:
+    from .features.returns import add_rolling_vol_from_returns_batch as _add_rv_from_returns  # type: ignore
+except Exception:
+    try:
+        from .features.vol import add_rolling_vol_from_returns_batch as _add_rv_from_returns  # type: ignore
+    except Exception:
+        _add_rv_from_returns = None
+
+def add_rolling_vol_from_returns_batch(
+    df,
+    *,
+    price_col: str = "close",
+    modes=("log", "pct"),
+    windows=(30, 60, 90),
+    annualize: bool = True,
+    direction: str = "oldest_top",
+):
+    """
+    Fallback shim: delegates to the project implementation if present,
+    otherwise computes rolling std on b2t returns and (optionally) annualizes.
+    """
+    import numpy as np
+    if _add_rv_from_returns is not None:
+        return _add_rv_from_returns(
+            df, price_col=price_col, modes=tuple(modes),
+            windows=tuple(windows), annualize=annualize, direction=direction
+        )
+
+    # Ensure needed return columns exist
+    if "log" in modes and f"{price_col}_b2t_log" not in df.columns:
+        b2t_log_delta(df, cols=[price_col], direction=direction)
+    if "pct" in modes and f"{price_col}_b2t_pct" not in df.columns:
+        b2t_pct_delta(df, cols=[price_col], direction=direction)
+
+    for mode in modes:
+        base = f"{price_col}_b2t_{mode}"
+        if base not in df.columns:
+            continue
+        for w in windows:
+            out = f"rv_{mode}_{int(w)}"
+            s = df[base].astype(float).rolling(int(w), min_periods=int(w)).std()
+            df[out] = s * (np.sqrt(252.0) if annualize else 1.0)
+    return df
+
+# -------- Single-bar vol --------
+try:
+    from .features.vol import add_atr
+except Exception:
+    # Optional: if vol module isn't present
+    def add_atr(*args, **kwargs):
+        raise ImportError("vol.add_atr not available in this build")
+
+# -------- Indicators --------
+try:
+    from .features.indicators import (
+        rsi, macd, stoch_kd, bollinger, atr, adx, obv, mfi
+    )
+except Exception:
+    # make missing optional
+    rsi = macd = stoch_kd = bollinger = atr = adx = obv = mfi = None
+
+# -------- Correlation --------
+try:
+    from .features.correlation import (
+        acf, pacf_yw, rolling_autocorr, xcorr
+    )
+except Exception:
+    acf = pacf_yw = rolling_autocorr = xcorr = None
+
+__all__ = [
+    # Calendar/date features
+    "expand_datetime_features_inplace", "expand_multiple_timestamps",
+
+    # EMA family
+    "compute_ema", "add_ema_columns", "add_ema_d1", "add_ema_d2", "add_ema",
+
+    # Returns / deltas / rolling vol
+    "add_returns", "b2t_pct_delta", "b2t_log_delta", "add_rolling_vol_from_returns_batch",
+
+    # Single-bar vol
+    "add_atr",
+
+    # Indicators (if present)
+    "rsi", "macd", "stoch_kd", "bollinger", "atr", "adx", "obv", "mfi",
+
+    # Correlation (if present)
+    "acf", "pacf_yw", "rolling_autocorr", "xcorr",
+]
diff --git a/src/ta_lab2/cli.py b/src/ta_lab2/cli.py
index 3131e8d..1b8350c 100644
--- a/src/ta_lab2/cli.py
+++ b/src/ta_lab2/cli.py
@@ -1,27 +1,39 @@
 from __future__ import annotations
 import argparse
 from pathlib import Path
-from .config import load_settings, project_root
-from .regimes.run_btc_pipeline import run_btc_pipeline
+
+# Import from root-level config.py, not from ta_lab2.config
+from config import load_settings, project_root
+from ta_lab2.regimes.run_btc_pipeline import run_btc_pipeline
+

 def main(argv: list[str] | None = None) -> int:
     ap = argparse.ArgumentParser(prog="ta-lab2", description="ta_lab2 CLI")
-    ap.add_argument("--config", "-c", default="configs/default.yaml",
-                    help="Path to YAML config relative to project root")
+    ap.add_argument(
+        "--config", "-c",
+        default="config/default.yaml",
+        help="Path to YAML config relative to project root (default: config/default.yaml)"
+    )
     args = ap.parse_args(argv)

-    root = project_root()
-    cfg_path = (root / args.config).resolve()
-    settings = load_settings(cfg_path)
+    # Load settings from YAML via the root-level config.py
+    settings = load_settings(args.config)

-    csv = (root / settings.data_csv).resolve()
-    out_dir = (root / settings.out_dir).resolve()
+    # Resolve absolute paths for input and output
+    csv = Path(settings.data_csv)
+    out_dir = Path(settings.out_dir)
+
+    # Run main pipeline
+    result = run_btc_pipeline(
+        csv_path=csv,
+        out_dir=out_dir,
+        ema_windows=settings.ema_windows,
+        resample=settings.resample
+    )

-    result = run_btc_pipeline(csv_path=csv, out_dir=out_dir,
-                              ema_windows=settings.ema_windows,
-                              resample=settings.resample)
     print("Pipeline complete:", result)
     return 0

+
 if __name__ == "__main__":
     raise SystemExit(main())
diff --git a/src/ta_lab2/config.py b/src/ta_lab2/config.py
index b1797bd..8ea1cb1 100644
--- a/src/ta_lab2/config.py
+++ b/src/ta_lab2/config.py
@@ -1,24 +1,30 @@
+# src/ta_lab2/config.py
+"""
+Shim so callers can do:
+    from ta_lab2.config import load_settings, project_root, Settings
+while the real loader lives at the project root (./config.py).
+
+We explicitly add the project root to sys.path so that importing this module
+works even when Python resolves from inside the installed package path.
+"""
+
 from __future__ import annotations
-from dataclasses import dataclass, field
+import sys
 from pathlib import Path
-import yaml
+from importlib import import_module as _imp
+
+# This file lives at <repo>/src/ta_lab2/config.py
+# -> project root is two parents above: <repo>
+_PROJECT_ROOT = Path(__file__).resolve().parents[2]
+if str(_PROJECT_ROOT) not in sys.path:
+    sys.path.insert(0, str(_PROJECT_ROOT))

-@dataclass
-class Settings:
-    data_csv: str
-    out_dir: str = "out"
-    ema_windows: list[int] = field(default_factory=lambda: [21, 50, 100])
-    resample: dict = field(default_factory=lambda: {"weekly": "W-SUN", "monthly": "MS"})
+# Import the real root-level config.py
+_cfg = _imp("config")

-def load_settings(path: str | Path) -> Settings:
-    p = Path(path)
-    data = yaml.safe_load(p.read_text(encoding="utf-8"))
-    return Settings(**data)
+# Re-export key symbols
+load_settings = _cfg.load_settings
+project_root = _cfg.project_root
+Settings = _cfg.Settings  # type: ignore[attr-defined]

-def project_root(start: str | Path | None = None) -> Path:
-    # walk up until we find pyproject.toml
-    cur = Path(start or __file__).resolve()
-    for ancestor in [cur, *cur.parents]:
-        if (ancestor / "pyproject.toml").exists():
-            return ancestor
-    return cur  # fallback
+__all__ = ["load_settings", "project_root", "Settings"]
\ No newline at end of file
diff --git a/src/ta_lab2/config/default.yaml b/src/ta_lab2/config/default.yaml
deleted file mode 100644
index 4da5e13..0000000
--- a/src/ta_lab2/config/default.yaml
+++ /dev/null
@@ -1,9 +0,0 @@
-# Paths are relative to the project root (where pyproject.toml lives)
-data_csv: data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv
-out_dir: out
-
-# Pipeline parameters (exampleâ€”extend as your code supports)
-ema_windows: [21, 50, 100]
-resample:
-  weekly: "W-SUN"
-  monthly: "MS"
\ No newline at end of file
diff --git a/src/ta_lab2/features/__init__.py b/src/ta_lab2/features/__init__.py
index 9fa317e..5309d9d 100644
--- a/src/ta_lab2/features/__init__.py
+++ b/src/ta_lab2/features/__init__.py
@@ -1,4 +1,66 @@
-from .calendar import expand_datetime_features_inplace
-from .ema import add_ema_columns, add_ema_d1, add_ema_d2
-from .returns import add_returns
-from .vol import add_atr
+from .calendar import (
+    expand_datetime_features_inplace,
+    expand_multiple_timestamps,
+)
+
+from .ema import (
+    compute_ema,
+    add_ema_columns,
+    add_ema_d1,
+    add_ema_d2,
+    add_ema,                # legacy wrapper shim
+    prepare_ema_helpers,    # NEW: helper scalers/normalizers used by pipeline/tests
+)
+
+from .returns import (
+    add_returns,
+    b2t_pct_delta,
+    b2t_log_delta,
+)
+
+# Volatility helpers live in vol.py (realized-vol + single-bar)
+from .vol import (
+    add_volatility_features,
+    add_rolling_vol_from_returns_batch,  # FIX: import from vol, not returns
+    add_atr,
+)
+
+# Technical indicators
+from .indicators import (
+    rsi, macd, stoch_kd, bollinger, atr, adx, obv, mfi
+)
+
+# Correlation utilities
+from .correlation import (
+    acf, pacf_yw, rolling_autocorr, xcorr
+)
+
+__all__ = [
+    # Calendar/date features
+    "expand_datetime_features_inplace",
+    "expand_multiple_timestamps",
+
+    # EMA family
+    "compute_ema",
+    "add_ema_columns",
+    "add_ema_d1",
+    "add_ema_d2",
+    "add_ema",               # legacy
+    "prepare_ema_helpers",   # NEW
+
+    # Returns / deltas
+    "add_returns",
+    "b2t_pct_delta",
+    "b2t_log_delta",
+
+    # Volatility
+    "add_volatility_features",
+    "add_rolling_vol_from_returns_batch",
+    "add_atr",
+
+    # Indicators
+    "rsi", "macd", "stoch_kd", "bollinger", "atr", "adx", "obv", "mfi",
+
+    # Correlation helpers
+    "acf", "pacf_yw", "rolling_autocorr", "xcorr",
+]
diff --git a/src/ta_lab2/features/calendar.py b/src/ta_lab2/features/calendar.py
index 350c794..74f7d6b 100644
--- a/src/ta_lab2/features/calendar.py
+++ b/src/ta_lab2/features/calendar.py
@@ -1,129 +1,254 @@
+# src/ta_lab2/features/calendar.py
+"""
+Calendar/date-time feature expansion utilities.
+
+`expand_datetime_features_inplace(df, base_timestamp_col, prefix=None, *, to_utc=True, add_moon=True)`
+- Parses timestamps (NaT-safe), normalizes to UTC (for deterministic astronomy).
+- Adds a rich set of date/time parts, ISO week, day-of-year, business-day flag, etc.
+- Optionally adds season and moon features (if `astronomy` package available).
+
+`expand_multiple_timestamps(df, cols, *, to_utc=True, add_moon=False)`
+- Convenience wrapper that expands several timestamp columns in one call.
+"""
+
+from __future__ import annotations
+
+from typing import Iterable, Sequence

 import numpy as np
 import pandas as pd

-try:
-    import astronomy as astro   # from astronomy-engine
+# Optional astronomy support (exact seasonal bounds + moon phase)
+_HAS_ASTRONOMY = False
+try:  # pragma: no cover - optional dependency
+    import astronomy as astro  # type: ignore
     _HAS_ASTRONOMY = True
-except Exception:
+except Exception:  # pragma: no cover - optional
     _HAS_ASTRONOMY = False

+
 def expand_datetime_features_inplace(
     df: pd.DataFrame,
     base_timestamp_col: str,
-    prefix: str = None,
+    prefix: str | None = None,
     *,
     to_utc: bool = True,
     add_moon: bool = True,
-    us_week_start_sunday: bool = True
 ) -> None:
+    """
+    One-call datetime feature expansion.
+
+    Parameters
+    ----------
+    df : pd.DataFrame
+    base_timestamp_col : str
+        Column name of the timestamp to expand.
+    prefix : str | None
+        Prefix for generated columns. Defaults to `base_timestamp_col`.
+    to_utc : bool
+        If True, normalize timezone-aware timestamps to UTC and localize naive
+        timestamps to UTC. Astronomy/season boundaries are computed in UTC.
+    add_moon : bool
+        If True and `astronomy` is available, adds moon phase features.
+
+    Notes
+    -----
+    - NaT-safe: rows with unparseable timestamps will yield NA features.
+    - Restores legacy fields:
+        * `<prefix>_week_of_year` (ISO week)
+        * `<prefix>_day_of_year`
+    """
     if base_timestamp_col not in df.columns:
         print(f"Warning: Column '{base_timestamp_col}' not found. Skipping.")
         return
+
+    # Parse
     dt = pd.to_datetime(df[base_timestamp_col], errors="coerce")
+
+    # Normalize to UTC for deterministic season/moon
     if getattr(dt.dt, "tz", None) is not None:
         if to_utc:
             dt = dt.dt.tz_convert("UTC")
     else:
+        # localize naive as UTC (NaT-safe)
         try:
             dt = dt.dt.tz_localize("UTC", nonexistent="NaT", ambiguous="NaT")
-        except Exception:
+        except Exception:  # pandas < 2.2 fallback
             dt = dt.dt.tz_localize("UTC")
+
     if prefix is None:
         prefix = base_timestamp_col
+
     valid = dt.notna()

-    # Day-of-week numbering
-    if us_week_start_sunday:
-        dow_num = ((dt.dt.dayofweek + 1) % 7 + 1).astype("Int64")   # Sun=1..Sat=7
-    else:
-        dow_num = dt.dt.isocalendar().day.astype("Int64")           # Mon=1..Sun=7
+    # --- Base parts ---
+    us_dow = ((dt.dt.dayofweek + 1) % 7 + 1).astype("Int64")  # Sun=1..Sat=7

-    unix_ns = dt.astype("int64")
+    # unix seconds (preserve NaT -> <NA>)
+    unix_ns = dt.view("int64")
     unix_ns = pd.Series(unix_ns, index=df.index).where(valid)
-    unix_s  = (unix_ns // 10**9).astype("Int64")
+    unix_s = (unix_ns // 10**9).astype("Int64")
+
+    # Month boundaries (tz drop warnings are harmless for derived features)
+    month_start = dt.dt.to_period("M").dt.start_time
+    month_end = dt.dt.to_period("M").dt.end_time
+
+    # Business-day flag
+    bd_array = np.full(len(df), np.nan, dtype="float64")
+    if len(df) > 0:
+        norm_days = dt.dt.normalize().values.astype("datetime64[D]")
+        bd = np.is_busday(norm_days, weekmask="Mon Tue Wed Thu Fri")
+        bd_array = bd.astype("float64")
+    is_bus = pd.Series(bd_array, index=df.index).where(valid).astype("Int64")
+
+    # ISO calendar parts for week-of-year
+    iso = dt.dt.isocalendar()
+    iso_week = iso.week.astype("Int64")

     out = {
         f"{prefix}_date": dt.dt.date,
         f"{prefix}_time": dt.dt.time,
-        f"{prefix}_year": dt.dt.year.astype("Int64"),
-        f"{prefix}_month": dt.dt.month.astype("Int64"),
-        f"{prefix}_day": dt.dt.day.astype("Int64"),
+
+        f"{prefix}_year":   dt.dt.year.astype("Int64"),
+        f"{prefix}_month":  dt.dt.month.astype("Int64"),
+        f"{prefix}_day":    dt.dt.day.astype("Int64"),
+
         f"{prefix}_day_name": dt.dt.day_name(),
-        f"{prefix}_day_of_week_num": dow_num,
-        f"{prefix}_hour": dt.dt.hour.astype("Int64"),
+        f"{prefix}_day_of_week_num": us_dow,  # Sun=1..Sat=7
+
+        f"{prefix}_hour":   dt.dt.hour.astype("Int64"),
         f"{prefix}_minute": dt.dt.minute.astype("Int64"),
         f"{prefix}_second": dt.dt.second.astype("Int64"),
+
         f"{prefix}_unix": unix_s,
-        f"{prefix}_quarter": dt.dt.quarter.astype("Int64"),
+
+        f"{prefix}_quarter":   dt.dt.quarter.astype("Int64"),
         f"{prefix}_year_half": ((dt.dt.quarter - 1) // 2 + 1).astype("Int64"),
-    }

-    # Seasons (exact if astronomy present; else approx)
-    def _season_boundaries(year: int):
-        s = astro.Seasons(year)
-        s_prev = astro.Seasons(year - 1)
-        return dict(
-            spring=s.mar_equinox.Utc().date(),
-            summer=s.jun_solstice.Utc().date(),
-            fall=s.sep_equinox.Utc().date(),
-            winter=s.dec_solstice.Utc().date(),
-            winter_prev=s_prev.dec_solstice.Utc().date(),
-        )
+        # Legacy fields expected downstream/tests
+        f"{prefix}_day_of_year": dt.dt.day_of_year.astype("Int64"),
+        f"{prefix}_week_of_year": iso_week,
+
+        # Convenience flags
+        f"{prefix}_is_month_start": (dt == month_start).astype("Int64").where(valid),
+        f"{prefix}_is_month_end":   (dt == month_end).astype("Int64").where(valid),
+        f"{prefix}_is_business_day": is_bus,
+    }

+    # --- Seasons ---
     if _HAS_ASTRONOMY:
-        cache = {}
+        _season_cache: dict[int, dict[str, pd.Timestamp]] = {}
+
+        def _bounds(year: int):
+            s = _season_cache.get(year)
+            if s is None:
+                sy = astro.Seasons(year)
+                sy1 = astro.Seasons(year - 1)
+                s = {
+                    "spring":      sy.mar_equinox.Utc().date(),
+                    "summer":      sy.jun_solstice.Utc().date(),
+                    "fall":        sy.sep_equinox.Utc().date(),
+                    "winter":      sy.dec_solstice.Utc().date(),
+                    "winter_prev": sy1.dec_solstice.Utc().date(),
+                }
+                _season_cache[year] = s
+            return s
+
         def _season_exact(ts: pd.Timestamp):
-            if pd.isna(ts): return np.nan
+            if pd.isna(ts):
+                return np.nan
             y = ts.year
-            if y not in cache:
-                cache[y] = _season_boundaries(y)
-            b = cache[y]; d = ts.date()
-            if b["spring"] <= d < b["summer"]: return "Spring"
-            if b["summer"] <= d < b["fall"]:   return "Summer"
-            if b["fall"]   <= d < b["winter"]: return "Fall"
+            b = _bounds(y)
+            d = ts.date()
+            if b["spring"] <= d < b["summer"]:
+                return "Spring"
+            if b["summer"] <= d < b["fall"]:
+                return "Summer"
+            if b["fall"] <= d < b["winter"]:
+                return "Fall"
             return "Winter"
-        season_exact = dt.apply(_season_exact)
-        out[f"{prefix}_season_exact"] = season_exact
+
+        out[f"{prefix}_season_exact"] = dt.apply(_season_exact)
     else:
-        m = dt.dt.month; d = dt.dt.day
+        # Approximate Northern Hemisphere rule
+        m = dt.dt.month
+        d = dt.dt.day
         conds = [
             ((m == 3) & (d >= 20)) | m.between(4, 5) | ((m == 6) & (d < 21)),
             ((m == 6) & (d >= 21)) | m.between(7, 8) | ((m == 9) & (d < 22)),
             ((m == 9) & (d >= 22)) | m.between(10, 11) | ((m == 12) & (d < 21)),
         ]
         out[f"{prefix}_season"] = pd.Series(
-            np.select(conds, ["Spring","Summer","Fall"], default="Winter"),
-            index=df.index
+            np.select(conds, ["Spring", "Summer", "Fall"], default="Winter"),
+            index=df.index,
         ).where(valid)

-    # Moon (noon UTC, via Time.Make)
+    # --- Moon (snap to noon UTC) ---
     if add_moon and _HAS_ASTRONOMY:
         noon_utc = dt.dt.normalize() + pd.Timedelta(hours=12)
+
         def _moon_deg(ts_noon: pd.Timestamp):
-            if pd.isna(ts_noon): return np.nan
+            if pd.isna(ts_noon):
+                return np.nan
             sec = ts_noon.second + ts_noon.microsecond / 1_000_000.0
-            t = astro.Time.Make(int(ts_noon.year), int(ts_noon.month), int(ts_noon.day),
-                                int(ts_noon.hour), int(ts_noon.minute), float(sec))
+            t = astro.Time.Make(
+                int(ts_noon.year), int(ts_noon.month), int(ts_noon.day),
+                int(ts_noon.hour), int(ts_noon.minute), float(sec),
+            )
             return float(astro.MoonPhase(t))
+
         def _phase_name(a):
-            if not np.isfinite(a): return np.nan
+            if not np.isfinite(a):
+                return np.nan
             a = a % 360.0
-            def near(x): return abs((a - x + 180) % 360 - 180) <= 5
+
+            def near(x):  # within Â±5Â°
+                return abs((a - x + 180) % 360 - 180) <= 5
+
             if near(0):   return "New Moon"
             if near(90):  return "First Quarter"
             if near(180): return "Full Moon"
             if near(270): return "Last Quarter"
-            if 0 < a < 90:    return "Waxing Crescent"
-            if 90 < a < 180:  return "Waxing Gibbous"
-            if 180 < a < 270: return "Waning Gibbous"
+            if 0   < a < 90:   return "Waxing Crescent"
+            if 90  < a < 180:  return "Waxing Gibbous"
+            if 180 < a < 270:  return "Waning Gibbous"
             return "Waning Crescent"
+
         def _illum(a):
-            if not np.isfinite(a): return np.nan
+            if not np.isfinite(a):
+                return np.nan
+            # (1 - cos(theta)) / 2 maps 0->0 (new) and 180->1 (full)
             return (1.0 - np.cos(np.deg2rad(a))) / 2.0
+
         moon_deg = noon_utc.apply(_moon_deg)
         out[f"{prefix}_moon_phase_deg"]  = moon_deg
         out[f"{prefix}_moon_phase_name"] = moon_deg.apply(_phase_name)
         out[f"{prefix}_moon_illum_frac"] = moon_deg.apply(_illum)

+    # --- Assign back ---
     df[list(out.keys())] = pd.DataFrame(out, index=df.index)
+
+
+def expand_multiple_timestamps(
+    df: pd.DataFrame,
+    cols: Iterable[str] | Sequence[str],
+    *,
+    to_utc: bool = True,
+    add_moon: bool = False,
+) -> None:
+    """
+    Expand several timestamp columns in one call (legacy test helper).
+    """
+    for c in cols:
+        if c in df.columns:
+            expand_datetime_features_inplace(
+                df, base_timestamp_col=c, prefix=c, to_utc=to_utc, add_moon=add_moon
+            )
+        else:
+            print(f"Warning: Column '{c}' not found. Skipping.")
+
+
+__all__ = [
+    "expand_datetime_features_inplace",
+    "expand_multiple_timestamps",
+]
diff --git a/src/ta_lab2/features/correlation.py b/src/ta_lab2/features/correlation.py
new file mode 100644
index 0000000..bd96500
--- /dev/null
+++ b/src/ta_lab2/features/correlation.py
@@ -0,0 +1,63 @@
+from __future__ import annotations
+import numpy as np
+import pandas as pd
+
+def acf(x: pd.Series, nlags: int = 40, demean: bool = True) -> pd.Series:
+    s = pd.Series(x).dropna().astype(float)
+    if len(s) == 0:
+        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="acf")
+    if demean:
+        s = s - s.mean()
+    var = (s**2).sum()
+    ac = [1.0]
+    for k in range(1, nlags + 1):
+        cov = (s.iloc[k:] * s.iloc[:-k]).sum()
+        ac.append(float(cov / var) if var != 0 else np.nan)
+    return pd.Series(ac, index=range(0, nlags + 1), name="acf")
+
+def pacf_yw(x: pd.Series, nlags: int = 20) -> pd.Series:
+    s = pd.Series(x).dropna().astype(float)
+    if len(s) == 0:
+        return pd.Series([np.nan]*(nlags+1), index=range(nlags+1), name="pacf")
+    s = s - s.mean()
+    # autocov sequence
+    gamma = np.array([
+        (s[:len(s)-k] @ s[k:]) / len(s) if k > 0 else (s @ s) / len(s)
+        for k in range(0, nlags+1)
+    ])
+    pac = np.zeros(nlags+1)
+    pac[0] = 1.0
+    phi = np.zeros((nlags+1, nlags+1))
+    var = gamma[0]
+    for k in range(1, nlags+1):
+        num = gamma[k] - np.sum(phi[k-1,1:k] * gamma[1:k][::-1])
+        den = var - np.sum(phi[k-1,1:k] * gamma[1:k])
+        phi[k,k] = num / den if den != 0 else np.nan
+        for j in range(1, k):
+            phi[k,j] = phi[k-1,j] - phi[k,k]*phi[k-1,k-j]
+        pac[k] = phi[k,k]
+    return pd.Series(pac, index=range(0, nlags+1), name="pacf")
+
+def rolling_autocorr(s: pd.Series, lag: int = 1, window: int = 100) -> pd.Series:
+    return s.rolling(window).corr(s.shift(lag)).rename(f"roll_ac_{lag}_{window}")
+
+def xcorr(a: pd.Series, b: pd.Series, max_lag: int = 20, demean: bool = True) -> pd.Series:
+    A = pd.Series(a).astype(float)
+    B = pd.Series(b).astype(float)
+    A, B = A.align(B, join="inner")
+    if len(A) == 0:
+        return pd.Series([np.nan]*(2*max_lag+1), index=range(-max_lag, max_lag+1), name="xcorr")
+    if demean:
+        A, B = A - A.mean(), B - B.mean()
+    var = np.sqrt((A**2).sum() * (B**2).sum())
+    vals = []
+    lags = range(-max_lag, max_lag + 1)
+    for k in lags:
+        if k < 0:
+            cov = (A[:k] * B[-k:]).sum()
+        elif k > 0:
+            cov = (A[k:] * B[:-k]).sum()
+        else:
+            cov = (A * B).sum()
+        vals.append(float(cov / var) if var != 0 else np.nan)
+    return pd.Series(vals, index=list(lags), name="xcorr")
diff --git a/src/ta_lab2/features/ema.py b/src/ta_lab2/features/ema.py
index 7757bed..b5e43a4 100644
--- a/src/ta_lab2/features/ema.py
+++ b/src/ta_lab2/features/ema.py
@@ -1,30 +1,337 @@
+# src/ta_lab2/features/ema.py
+from __future__ import annotations

-import pandas as pd
+from typing import Iterable, Optional, Sequence
 import numpy as np
+import pandas as pd
+
+__all__ = [
+    "compute_ema",
+    "add_ema_columns",
+    "add_ema_d1",
+    "add_ema_d2",
+]
+
+# ---------------------------------------------------------------------------
+# Core EMA helper
+# ---------------------------------------------------------------------------
+
+def compute_ema(
+    s: pd.Series,
+    window: int,
+    *,
+    adjust: bool = False,
+    min_periods: Optional[int] = None,
+    name: Optional[str] = None,
+    **kwargs,  # swallow legacy extras
+) -> pd.Series:
+    """
+    Series EMA with a Pandas-backed implementation.
+    Accepts extra kwargs for backward-compatibility (ignored).
+    """
+    out = (
+        s.astype(float)
+         .ewm(span=int(window), adjust=adjust, min_periods=min_periods)
+         .mean()
+    )
+    if name is not None:
+        out = out.rename(name)
+    return out
+
+
+# ---------------------------------------------------------------------------
+# Utilities
+# ---------------------------------------------------------------------------
+
+def _flip_for_direction(obj: pd.DataFrame | pd.Series, direction: str):
+    """
+    If data are newest-first, flip to chronological for diff/EMA, and tell caller
+    to flip back afterwards.
+    """
+    if direction not in ("oldest_top", "newest_top"):
+        # be forgiving; treat unknown as oldest_top
+        return obj, False
+    if direction == "newest_top":
+        return obj.iloc[::-1], True
+    return obj, False
+
+
+def _maybe_round(s: pd.Series, round_places: Optional[int]) -> pd.Series:
+    return s.round(round_places) if round_places is not None else s
+
+
+def _ensure_list(x: Sequence[str] | Iterable[str]) -> list[str]:
+    return list(x) if not isinstance(x, list) else x
+
+
+# ---------------------------------------------------------------------------
+# Column builders (in-place, return df) â€” tolerant to extra kwargs
+# ---------------------------------------------------------------------------

-def add_ema_columns(df: pd.DataFrame, fields, periods, suffix_fmt="{field}_ema_{period}"):
-    for field in fields:
-        x = df[field].astype(float)
-        for p in periods:
-            df[suffix_fmt.format(field=field, period=p)] = x.ewm(span=p, adjust=False).mean()
+def add_ema_columns(
+    df: pd.DataFrame,
+    base_price_cols: Sequence[str] | None,
+    ema_windows: Sequence[int] | None,
+    *,
+    direction: str = "oldest_top",
+    overwrite: bool = False,
+    round_places: Optional[int] = None,
+    adjust: bool = False,
+    min_periods: Optional[int] = None,
+    # Back-compat knobs we ignore but accept
+    price_cols: Sequence[str] | None = None,
+    ema_periods: Sequence[int] | None = None,
+    **kwargs,
+) -> pd.DataFrame:
+    """
+    For each `col` in base_price_cols and each `w` in ema_windows, add:
+      `{col}_ema_{w}`
+
+    Accepts legacy kwargs and aliases:
+      - price_cols (alias of base_price_cols)
+      - ema_periods (alias of ema_windows)
+      - arbitrary **kwargs (ignored)
+    """
+    if base_price_cols is None:
+        base_price_cols = price_cols or []
+    if ema_windows is None:
+        ema_windows = ema_periods or []
+
+    base_price_cols = _ensure_list(base_price_cols)
+    ema_windows = [int(w) for w in ema_windows]
+
+    work, flipped = _flip_for_direction(df, direction)
+
+    new_cols: dict[str, pd.Series] = {}
+    for col in base_price_cols:
+        if col not in work.columns:
+            continue
+        s = work[col].astype(float)
+        for w in ema_windows:
+            out_name = f"{col}_ema_{w}"
+            if not overwrite and out_name in df.columns:
+                continue
+            ema = compute_ema(s, w, adjust=adjust, min_periods=min_periods, name=out_name)
+            if flipped:
+                ema = ema.iloc[::-1]
+            ema = _maybe_round(ema, round_places)
+            new_cols[out_name] = ema
+
+    if new_cols:
+        df[list(new_cols.keys())] = pd.DataFrame(new_cols, index=df.index)
     return df

-def add_ema_d1(df: pd.DataFrame, fields, periods, round_places=None, suffix_fmt="{field}_ema_{period}"):
-    for field in fields:
-        for p in periods:
-            col = suffix_fmt.format(field=field, period=p)
-            d1 = df[col].diff()
-            if round_places is not None:
-                d1 = d1.round(round_places)
-            df[f"{col}_d1"] = d1
+
+def add_ema_d1(
+    df: pd.DataFrame,
+    base_price_cols: Sequence[str] | None,
+    ema_windows: Sequence[int] | None,
+    *,
+    direction: str = "oldest_top",
+    overwrite: bool = False,
+    round_places: Optional[int] = None,
+    # legacy aliases/kwargs tolerated
+    price_cols: Sequence[str] | None = None,
+    ema_periods: Sequence[int] | None = None,
+    **kwargs,
+) -> pd.DataFrame:
+    """
+    First difference of EMA:
+      `{col}_ema_{w}_d1 = diff({col}_ema_{w})`
+
+    Accepts and ignores unknown kwargs; supports direction flipping.
+    """
+    if base_price_cols is None:
+        base_price_cols = price_cols or []
+    if ema_windows is None:
+        ema_windows = ema_periods or []
+
+    base_price_cols = _ensure_list(base_price_cols)
+    ema_windows = [int(w) for w in ema_windows]
+
+    work, flipped = _flip_for_direction(df, direction)
+
+    new_cols: dict[str, pd.Series] = {}
+    for col in base_price_cols:
+        for w in ema_windows:
+            ema_col = f"{col}_ema_{w}"
+            if ema_col not in work.columns:
+                if col in work.columns:
+                    work[ema_col] = compute_ema(work[col].astype(float), w)
+                else:
+                    continue
+            d1_name = f"{ema_col}_d1"
+            if not overwrite and d1_name in df.columns:
+                continue
+            d1 = work[ema_col].astype(float).diff()
+            if flipped:
+                d1 = d1.iloc[::-1]
+            d1 = _maybe_round(d1.rename(d1_name), round_places)
+            new_cols[d1_name] = d1
+
+    if new_cols:
+        df[list(new_cols.keys())] = pd.DataFrame(new_cols, index=df.index)
     return df

-def add_ema_d2(df: pd.DataFrame, fields, periods, round_places=None, suffix_fmt="{field}_ema_{period}"):
-    for field in fields:
-        for p in periods:
-            col = suffix_fmt.format(field=field, period=p)
-            d2 = df[col].diff().diff()
-            if round_places is not None:
-                d2 = d2.round(round_places)
-            df[f"{col}_d2"] = d2
+
+def add_ema_d2(
+    df: pd.DataFrame,
+    base_price_cols: Sequence[str] | None,
+    ema_windows: Sequence[int] | None,
+    *,
+    direction: str = "oldest_top",
+    overwrite: bool = False,
+    round_places: Optional[int] = None,
+    # legacy aliases/kwargs tolerated
+    price_cols: Sequence[str] | None = None,
+    ema_periods: Sequence[int] | None = None,
+    **kwargs,
+) -> pd.DataFrame:
+    """
+    Second difference of EMA:
+      `{col}_ema_{w}_d2 = diff(diff({col}_ema_{w}))`
+
+    Accepts and ignores unknown kwargs; supports direction flipping.
+    """
+    if base_price_cols is None:
+        base_price_cols = price_cols or []
+    if ema_windows is None:
+        ema_windows = ema_periods or []
+
+    base_price_cols = _ensure_list(base_price_cols)
+    ema_windows = [int(w) for w in ema_windows]
+
+    work, flipped = _flip_for_direction(df, direction)
+
+    new_cols: dict[str, pd.Series] = {}
+    for col in base_price_cols:
+        for w in ema_windows:
+            ema_col = f"{col}_ema_{w}"
+            if ema_col not in work.columns:
+                if col in work.columns:
+                    work[ema_col] = compute_ema(work[col].astype(float), w)
+                else:
+                    continue
+            d2_name = f"{ema_col}_d2"
+            if not overwrite and d2_name in df.columns:
+                continue
+            d2 = work[ema_col].astype(float).diff().diff()
+            if flipped:
+                d2 = d2.iloc[::-1]
+            d2 = _maybe_round(d2.rename(d2_name), round_places)
+            new_cols[d2_name] = d2
+
+    if new_cols:
+        df[list(new_cols.keys())] = pd.DataFrame(new_cols, index=df.index)
+    return df
+
+
+# ---- Legacy compatibility shims ----
+def add_ema(df, col: str = "close", windows=(21, 50, 100, 200), prefix: str = "ema"):
+    """
+    Legacy wrapper: adds EMA columns for one price column.
+    Mirrors old API but delegates to the new add_ema_columns.
+    """
+    cols = [col]
+    add_ema_columns(df, cols, list(windows))
+    return df
+
+# -----------------------------------------------------------------------------
+# EMA helper scalers/normalizers used downstream (e.g., pipeline/tests)
+# -----------------------------------------------------------------------------
+def prepare_ema_helpers(
+    df: pd.DataFrame,
+    base_price_cols: Sequence[str] | None,
+    ema_windows: Sequence[int] | None,
+    *,
+    direction: str = "oldest_top",
+    scale: str = "bps",              # {"raw","pct","bps"}
+    overwrite: bool = False,
+    round_places: Optional[int] = 6,
+    # legacy aliases tolerated
+    price_cols: Sequence[str] | None = None,
+    periods: Sequence[int] | None = None,
+    **kwargs,
+) -> pd.DataFrame:
+    """
+    Ensure first/second EMA diffs exist, then add scaled helper columns for each
+    <col, period> pair:
+
+      - {col}_ema_{w}_d1   (1st diff)       [ensured]
+      - {col}_ema_{w}_d2   (2nd diff)       [ensured]
+      - {col}_ema_{w}_slope    (scaled d1)
+      - {col}_ema_{w}_accel    (scaled d2)
+
+    Scaling:
+      raw  -> slope = d1,                 accel = d2
+      pct  -> slope = d1 / ema,           accel = d2 / ema
+      bps  -> slope = 1e4 * d1 / ema,     accel = 1e4 * d2 / ema
+
+    Function is safe to call multiple times and ignores unknown kwargs.
+    """
+    if base_price_cols is None:
+        base_price_cols = price_cols or []
+    if ema_windows is None:
+        ema_windows = periods or []
+
+    base_price_cols = _ensure_list(base_price_cols)
+    ema_windows = [int(w) for w in ema_windows]
+
+    # Make sure ema, d1, d2 exist (donâ€™t clobber unless overwrite=True)
+    add_ema_columns(df, base_price_cols, ema_windows, direction=direction, overwrite=overwrite)
+    add_ema_d1(df, base_price_cols, ema_windows, direction=direction, overwrite=overwrite)
+    add_ema_d2(df, base_price_cols, ema_windows, direction=direction, overwrite=overwrite)
+
+    scale = (scale or "raw").lower()
+    if scale not in {"raw", "pct", "bps"}:
+        scale = "bps"  # sensible default for TA
+
+    new_cols: dict[str, pd.Series] = {}
+
+    for col in base_price_cols:
+        for w in ema_windows:
+            ema_col = f"{col}_ema_{w}"
+            d1_col  = f"{ema_col}_d1"
+            d2_col  = f"{ema_col}_d2"
+
+            if ema_col not in df.columns:
+                # If caller passed a base price without EMA (unlikely after add_ema_columns),
+                # compute minimally to proceed.
+                if col in df.columns:
+                    df[ema_col] = compute_ema(df[col].astype(float), w)
+                else:
+                    continue
+
+            ema = df[ema_col].astype(float)
+            d1  = df[d1_col].astype(float) if d1_col in df.columns else ema.diff()
+            d2  = df[d2_col].astype(float) if d2_col in df.columns else ema.diff().diff()
+
+            if scale == "raw":
+                slope = d1
+                accel = d2
+            elif scale == "pct":
+                slope = d1 / ema.replace(0.0, np.nan)
+                accel = d2 / ema.replace(0.0, np.nan)
+            else:  # "bps"
+                slope = 1e4 * d1 / ema.replace(0.0, np.nan)
+                accel = 1e4 * d2 / ema.replace(0.0, np.nan)
+
+            slope_name = f"{col}_ema_{w}_slope"
+            accel_name = f"{col}_ema_{w}_accel"
+
+            if overwrite or slope_name not in df.columns:
+                new_cols[slope_name] = _maybe_round(slope.astype(float), round_places)
+            if overwrite or accel_name not in df.columns:
+                new_cols[accel_name] = _maybe_round(accel.astype(float), round_places)
+
+    if new_cols:
+        df[list(new_cols.keys())] = pd.DataFrame(new_cols, index=df.index)
+
     return df
+
+
+# make sure it's exported
+try:
+    __all__.append("add_ema")  # if __all__ exists
+except NameError:
+    __all__ = ["add_ema"]
diff --git a/src/ta_lab2/features/indicators.py b/src/ta_lab2/features/indicators.py
new file mode 100644
index 0000000..7e2ba66
--- /dev/null
+++ b/src/ta_lab2/features/indicators.py
@@ -0,0 +1,333 @@
+from __future__ import annotations
+import numpy as np
+import pandas as pd
+
+__all__ = [
+    "rsi",
+    "macd",
+    "stoch_kd",
+    "bollinger",
+    "atr",
+    "adx",
+    "obv",
+    "mfi",
+]
+
+# -------------------------
+# internal helpers
+# -------------------------
+def _ema(s: pd.Series, span: int) -> pd.Series:
+    return s.astype(float).ewm(span=span, adjust=False).mean()
+
+def _sma(s: pd.Series, window: int) -> pd.Series:
+    return s.astype(float).rolling(window, min_periods=window).mean()
+
+def _tr(high: pd.Series, low: pd.Series, close: pd.Series) -> pd.Series:
+    high = high.astype(float)
+    low = low.astype(float)
+    close = close.astype(float)
+    prev_close = close.shift(1)
+    return pd.concat(
+        [(high - low).abs(), (high - prev_close).abs(), (low - prev_close).abs()],
+        axis=1,
+    ).max(axis=1)
+
+def _ensure_series(obj, *, col: str | None = None) -> pd.Series:
+    """Return a Series from either a Series or DataFrame+col."""
+    if isinstance(obj, pd.Series):
+        return obj
+    if isinstance(obj, pd.DataFrame):
+        if col is None:
+            raise ValueError("Column name must be provided when passing a DataFrame.")
+        if col not in obj.columns:
+            raise KeyError(f"Column '{col}' not found in DataFrame.")
+        return obj[col]
+    raise TypeError("Expected a pandas Series or DataFrame.")
+
+def _return(obj, series: pd.Series, out_col: str, *, inplace: bool):
+    """
+    Default behavior: return a **Series** (named).
+    If inplace=True and obj is a DataFrame, assign column and return the df.
+    """
+    series = series.rename(out_col)
+    if inplace and isinstance(obj, pd.DataFrame):
+        obj[out_col] = series
+        return obj
+    return series
+
+# -------------------------
+# indicators
+# -------------------------
+def rsi(
+    obj,  # Series or DataFrame
+    window: int | None = 14,
+    *,
+    period: int | None = None,        # alias for window
+    price_col: str = "close",
+    out_col: str | None = None,
+    inplace: bool = False,
+):
+    """
+    RSI (Wilder). Back-compat:
+      - Accepts Series or DataFrame.
+      - `period` is an alias for `window`.
+      - By default returns a **Series**; set `inplace=True` to assign to df and return df.
+    """
+    if window is None and period is not None:
+        window = period
+    if window is None:
+        window = 14
+    if out_col is None:
+        out_col = f"rsi_{window}"
+
+    s = _ensure_series(obj, col=price_col)
+    delta = s.diff()
+    gain = delta.clip(lower=0.0)
+    loss = (-delta).clip(lower=0.0)
+    avg_gain = gain.ewm(alpha=1 / window, adjust=False).mean()
+    avg_loss = loss.ewm(alpha=1 / window, adjust=False).mean()
+    rs = avg_gain / avg_loss.replace(0.0, np.nan)
+    rsi_series = 100.0 - (100.0 / (1.0 + rs))
+    return _return(obj, rsi_series.astype(float), out_col, inplace=inplace)
+
+def macd(
+    obj,  # Series or DataFrame
+    *,
+    price_col: str = "close",
+    fast: int = 12,
+    slow: int = 26,
+    signal: int = 9,
+    out_cols: tuple[str, str, str] | None = None,
+    inplace: bool = False,
+):
+    """
+    MACD (12/26/9 by default).
+    Default: return DataFrame with 3 series (macd, signal, hist).
+    If `inplace=True` and obj is a DataFrame, assign all three cols and return df.
+    """
+    if out_cols is None:
+        out_cols = (f"macd_{fast}_{slow}", f"macd_signal_{signal}", f"macd_hist_{fast}_{slow}_{signal}")
+
+    s = _ensure_series(obj, col=price_col)
+    ema_fast = _ema(s, fast)
+    ema_slow = _ema(s, slow)
+    macd_line = ema_fast - ema_slow
+    signal_line = _ema(macd_line, signal)
+    hist = macd_line - signal_line
+    out = pd.DataFrame({out_cols[0]: macd_line, out_cols[1]: signal_line, out_cols[2]: hist})
+
+    if inplace and isinstance(obj, pd.DataFrame):
+        for c in out.columns:
+            obj[c] = out[c]
+        return obj
+    return out
+
+def stoch_kd(
+    obj,  # DataFrame
+    *,
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+    k: int = 14,
+    d: int = 3,
+    out_cols: tuple[str, str] | None = None,
+    inplace: bool = False,
+):
+    """
+    Stochastic %K/%D (df input expected).
+    Default: return DataFrame with K and D. If `inplace=True`, assign and return df.
+    """
+    if out_cols is None:
+        out_cols = (f"stoch_k_{k}", f"stoch_d_{d}")
+
+    if not isinstance(obj, pd.DataFrame):
+        raise TypeError("stoch_kd expects a DataFrame; pass high/low/close columns via high_col/low_col/close_col.")
+
+    high = _ensure_series(obj, col=high_col)
+    low = _ensure_series(obj, col=low_col)
+    close = _ensure_series(obj, col=close_col)
+
+    lowest = low.rolling(k, min_periods=k).min()
+    highest = high.rolling(k, min_periods=k).max()
+    k_line = 100.0 * (close - lowest) / (highest - lowest)
+    d_line = k_line.rolling(d, min_periods=d).mean()
+
+    out = pd.DataFrame({out_cols[0]: k_line.astype(float), out_cols[1]: d_line.astype(float)})
+    if inplace:
+        for c in out.columns:
+            obj[c] = out[c]
+        return obj
+    return out
+
+def bollinger(
+    obj,  # Series or DataFrame
+    window: int = 20,
+    *,
+    price_col: str = "close",
+    n_sigma: float = 2.0,
+    out_cols: tuple[str, str, str, str] | None = None,
+    inplace: bool = False,
+):
+    """
+    Bollinger Bands.
+    Default: return DataFrame with ma/up/lo/width.
+    If `inplace=True` and obj is a DataFrame, assign and return df.
+    """
+    if out_cols is None:
+        out_cols = (f"bb_ma_{window}", f"bb_up_{window}_{n_sigma}", f"bb_lo_{window}_{n_sigma}", f"bb_width_{window}")
+
+    s = _ensure_series(obj, col=price_col)
+    ma = _sma(s, window)
+    std = s.astype(float).rolling(window, min_periods=window).std()
+    upper = ma + n_sigma * std
+    lower = ma - n_sigma * std
+    bw = (upper - lower) / ma
+
+    out = pd.DataFrame({out_cols[0]: ma, out_cols[1]: upper, out_cols[2]: lower, out_cols[3]: bw})
+    if inplace and isinstance(obj, pd.DataFrame):
+        for c in out.columns:
+            obj[c] = out[c].astype(float)
+        return obj
+    return out
+
+def atr(
+    obj,  # DataFrame
+    window: int | None = 14,
+    *,
+    period: int | None = None,   # alias for window
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+    out_col: str | None = None,
+    inplace: bool = False,
+):
+    """
+    Average True Range (simple rolling mean of TR, matching your original).
+    Default: return Series; if `inplace=True`, assign to df and return df.
+    """
+    if window is None and period is not None:
+        window = period
+    if window is None:
+        window = 14
+    if out_col is None:
+        out_col = f"atr_{window}"
+
+    if not isinstance(obj, pd.DataFrame):
+        raise TypeError("atr expects a DataFrame; pass high/low/close columns via high_col/low_col/close_col.")
+
+    high = _ensure_series(obj, col=high_col)
+    low = _ensure_series(obj, col=low_col)
+    close = _ensure_series(obj, col=close_col)
+
+    tr = _tr(high, low, close)
+    out = tr.rolling(window, min_periods=window).mean().astype(float)
+    return _return(obj, out, out_col, inplace=inplace)
+
+def adx(
+    obj,  # DataFrame
+    window: int | None = 14,
+    *,
+    period: int | None = None,  # alias for window
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+    out_col: str | None = None,
+    inplace: bool = False,
+):
+    """
+    ADX (vectorized conditions, preserves original behavior).
+    Default: return Series; if `inplace=True`, assign and return df.
+    """
+    if window is None and period is not None:
+        window = period
+    if window is None:
+        window = 14
+    if out_col is None:
+        out_col = f"adx_{window}"
+
+    if not isinstance(obj, pd.DataFrame):
+        raise TypeError("adx expects a DataFrame; pass high/low/close columns via high_col/low_col/close_col.")
+
+    high = _ensure_series(obj, col=high_col)
+    low = _ensure_series(obj, col=low_col)
+    close = _ensure_series(obj, col=close_col)
+
+    up = high.diff()
+    dn = -low.diff()
+
+    plus_dm = np.where((up > dn) & (up > 0), up, 0.0)
+    minus_dm = np.where((dn > up) & (dn > 0), dn, 0.0)
+
+    tr = _tr(high, low, close)
+    atr_ = tr.rolling(window, min_periods=window).mean()
+
+    plus_di = 100.0 * pd.Series(plus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
+    minus_di = 100.0 * pd.Series(minus_dm, index=high.index).rolling(window, min_periods=window).sum() / atr_
+
+    dx = ((plus_di - minus_di).abs() / (plus_di + minus_di).replace(0.0, np.nan)) * 100.0
+    adx_series = dx.rolling(window, min_periods=window).mean().astype(float)
+    return _return(obj, adx_series, out_col, inplace=inplace)
+
+def obv(
+    obj,  # DataFrame
+    *,
+    price_col: str = "close",
+    volume_col: str = "volume",
+    out_col: str = "obv",
+    inplace: bool = False,
+):
+    """
+    On-Balance Volume.
+    Default: return Series; if `inplace=True`, assign and return df.
+    """
+    if not isinstance(obj, pd.DataFrame):
+        raise TypeError("obv requires a DataFrame with price_col and volume_col.")
+
+    close = _ensure_series(obj, col=price_col)
+    volume = _ensure_series(obj, col=volume_col).astype(float)
+
+    direction = np.sign(close.diff().fillna(0.0))
+    obv_series = (direction * volume).fillna(0.0).cumsum().astype(float)
+    return _return(obj, obv_series, out_col, inplace=inplace)
+
+def mfi(
+    obj,  # DataFrame
+    window: int | None = 14,
+    *,
+    period: int | None = None,   # alias for window
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+    volume_col: str = "volume",
+    out_col: str | None = None,
+    inplace: bool = False,
+):
+    """
+    Money Flow Index. Default: return Series; if `inplace=True`, assign and return df.
+    """
+    if window is None and period is not None:
+        window = period
+    if window is None:
+        window = 14
+    if out_col is None:
+        out_col = f"mfi_{window}"
+
+    if not isinstance(obj, pd.DataFrame):
+        raise TypeError("mfi expects a DataFrame; pass high/low/close/volume via *_col params.")
+
+    high = _ensure_series(obj, col=high_col)
+    low = _ensure_series(obj, col=low_col)
+    close = _ensure_series(obj, col=close_col)
+    volume = _ensure_series(obj, col=volume_col).astype(float)
+
+    tp = (high.astype(float) + low.astype(float) + close.astype(float)) / 3.0
+    raw = tp * volume
+    pos = raw.where(tp.diff() > 0, 0.0)
+    neg = raw.where(tp.diff() < 0, 0.0)
+
+    pmf = pos.rolling(window, min_periods=window).sum()
+    nmf = (-neg).rolling(window, min_periods=window).sum()
+    mr = pmf / nmf.replace(0.0, np.nan)
+
+    out = (100.0 - (100.0 / (1.0 + mr))).astype(float)
+    return _return(obj, out, out_col, inplace=inplace)
diff --git a/src/ta_lab2/features/returns.py b/src/ta_lab2/features/returns.py
index 53aeb7e..299cf6d 100644
--- a/src/ta_lab2/features/returns.py
+++ b/src/ta_lab2/features/returns.py
@@ -1,8 +1,211 @@
+# src/ta_lab2/features/returns.py
+from __future__ import annotations

-import pandas as pd
+from typing import Sequence, Optional, Union
 import numpy as np
+import pandas as pd
+
+__all__ = ["b2t_pct_delta", "b2t_log_delta", "add_returns"]
+
+Number = Union[int, float, np.number]
+
+
+def _coerce_cols(cols: Optional[Union[str, Sequence[str]]]) -> list[str]:
+    """Normalize None / str / sequence -> list[str]."""
+    if cols is None:
+        return []
+    if isinstance(cols, str):
+        return [cols]
+    return [str(c) for c in cols]
+
+
+def _as_float_series(df: pd.DataFrame, col: str) -> pd.Series:
+    if col not in df.columns:
+        raise KeyError(f"Column '{col}' not found in DataFrame.")
+    return df[col].astype(float)
+
+
+def _b2b_change(
+    s: pd.Series, *, mode: str = "pct", direction: str = "oldest_top"
+) -> pd.Series:
+    """
+    Compute bar-to-bar change for a single Series.
+
+    Parameters
+    ----------
+    s : Series
+        Numeric series.
+    mode : {"pct","log"}
+        Percent change or log change.
+    direction : {"oldest_top","newest_top"}
+        If the DataFrame is sorted newest row first, pass "newest_top" so we
+        compute changes in true chronological order and then restore order.
+    """
+    if direction not in ("oldest_top", "newest_top"):
+        raise ValueError("direction must be 'oldest_top' or 'newest_top'")
+
+    # Work in chronological order
+    if direction == "newest_top":
+        s_work = s.iloc[::-1]
+        flip_back = True
+    else:
+        s_work = s
+        flip_back = False
+
+    if mode == "pct":
+        out = s_work.pct_change()
+    elif mode == "log":
+        out = np.log(s_work / s_work.shift(1))
+    else:
+        raise ValueError("mode must be 'pct' or 'log'")
+
+    if flip_back:
+        out = out.iloc[::-1]
+
+    return out
+
+
+def _apply_b2b(
+    df: pd.DataFrame,
+    *,
+    cols: Sequence[str],
+    mode: str,
+    suffix: str,
+    extra_cols: Sequence[str] = (),
+    round_places: Optional[int] = None,
+    direction: str = "oldest_top",
+) -> pd.DataFrame:
+    all_cols = list(dict.fromkeys([*cols, *extra_cols]))  # dedupe keep order
+
+    for c in all_cols:
+        s = _as_float_series(df, c)
+        chg = _b2b_change(s, mode=mode, direction=direction)
+        if round_places is not None:
+            chg = chg.round(round_places)
+        df[f"{c}_{suffix}"] = chg
+
+    return df
+
+
+# --------------------------------------------------------------------------------------
+# Public API
+# --------------------------------------------------------------------------------------
+def b2t_pct_delta(
+    df: pd.DataFrame,
+    *,
+    cols: Optional[Sequence[str]] = None,
+    columns: Optional[Sequence[str]] = None,  # legacy alias
+    extra_cols: Optional[Sequence[str]] = None,
+    round_places: Optional[int] = 6,
+    direction: str = "oldest_top",  # or "newest_top"
+    open_col: str = "open",         # kept for compatibility; not required here
+    close_col: str = "close",       # kept for compatibility; not required here
+    **kwargs,                       # swallow legacy args like prefix, add_intraday
+) -> pd.DataFrame:
+    """
+    Add bar-to-bar **percent** change columns for each requested column.
+
+    Mutates `df` in place and returns `df`.
+
+    Notes
+    -----
+    Accepts/ignores legacy kwargs (e.g. `prefix`, `add_intraday`) for compatibility.
+    """
+    base = _coerce_cols(columns if columns is not None else cols)
+    extras = _coerce_cols(extra_cols)
+
+    if not base and not extras:
+        return df
+
+    return _apply_b2b(
+        df,
+        cols=base,
+        extra_cols=extras,
+        mode="pct",
+        suffix="b2t_pct",
+        round_places=round_places,
+        direction=direction,
+    )
+
+
+def b2t_log_delta(
+    df: pd.DataFrame,
+    *,
+    cols: Optional[Sequence[str]] = None,
+    columns: Optional[Sequence[str]] = None,  # legacy alias
+    extra_cols: Optional[Sequence[str]] = None,
+    round_places: Optional[int] = 6,
+    direction: str = "oldest_top",
+    open_col: str = "open",   # kept for compatibility; not required here
+    close_col: str = "close", # kept for compatibility; not required here
+    **kwargs,                 # swallow legacy args like prefix, add_intraday
+) -> pd.DataFrame:
+    """
+    Add bar-to-bar **log** change columns for each requested column.
+
+    Mutates `df` in place and returns `df`.
+
+    Notes
+    -----
+    Accepts/ignores legacy kwargs (e.g. `prefix`, `add_intraday`) for compatibility.
+    """
+    base = _coerce_cols(columns if columns is not None else cols)
+    extras = _coerce_cols(extra_cols)
+
+    if not base and not extras:
+        return df
+
+    return _apply_b2b(
+        df,
+        cols=base,
+        extra_cols=extras,
+        mode="log",
+        suffix="b2t_log",
+        round_places=round_places,
+        direction=direction,
+    )
+
+
+def add_returns(
+    df: pd.DataFrame,
+    *,
+    cols: Optional[Sequence[str]] = None,
+    columns: Optional[Sequence[str]] = None,   # legacy alias
+    extra_cols: Optional[Sequence[str]] = None,
+    round_places: Optional[int] = 6,
+    direction: str = "oldest_top",
+    open_col: str = "open",                    # preserved for old call sites
+    close_col: str = "close",                  # preserved for old call sites
+    **kwargs,                                   # swallow legacy extras
+) -> pd.DataFrame:
+    """
+    Backward-compatible wrapper that mirrors the original API and adds BOTH:
+      - `{col}_b2t_pct`
+      - `{col}_b2t_log`
+
+    Mutates `df` in place and returns it.
+    """
+    base = _coerce_cols(columns if columns is not None else cols)
+    extras = _coerce_cols(extra_cols)

-def add_returns(df: pd.DataFrame, close_col="close"):
-    df["ret"] = df[close_col].pct_change()
-    df["logret"] = np.log(df[close_col]).diff()
+    b2t_pct_delta(
+        df,
+        cols=base,
+        extra_cols=extras,
+        round_places=round_places,
+        direction=direction,
+        open_col=open_col,
+        close_col=close_col,
+        **kwargs,
+    )
+    b2t_log_delta(
+        df,
+        cols=base,
+        extra_cols=extras,
+        round_places=round_places,
+        direction=direction,
+        open_col=open_col,
+        close_col=close_col,
+        **kwargs,
+    )
     return df
diff --git a/src/ta_lab2/features/segments.py b/src/ta_lab2/features/segments.py
new file mode 100644
index 0000000..cf7acad
--- /dev/null
+++ b/src/ta_lab2/features/segments.py
@@ -0,0 +1,72 @@
+# src/ta_lab2/features/segments.py
+"""
+Flip-segment builder
+
+Turns per-bar trend state labels into contiguous segments with start/end metadata.
+"""
+
+from __future__ import annotations
+import numpy as np
+import pandas as pd
+
+
+def build_flip_segments(
+    df: pd.DataFrame,
+    price_col: str = "close",
+    state_col: str = "trend_state",
+    timestamp_col: str | None = None,
+) -> pd.DataFrame:
+    """
+    Build contiguous segments of identical trend states.
+
+    Parameters
+    ----------
+    df : pd.DataFrame
+        Must include state_col and price_col (and optionally timestamp_col).
+    price_col : str, default "close"
+        Column used to measure segment returns.
+    state_col : str, default "trend_state"
+        Column with integer or categorical trend labels.
+    timestamp_col : str or None
+        Optional timestamp column for segment start/end markers.
+
+    Returns
+    -------
+    segs : pd.DataFrame
+        Columns:
+        - seg_id, state, start_idx, end_idx
+        - start_price, end_price, seg_return, seg_len
+        - start_time, end_time (if timestamp_col provided)
+    """
+    if state_col not in df or price_col not in df:
+        raise KeyError(f"DataFrame must include '{state_col}' and '{price_col}'.")
+
+    states = df[state_col].to_numpy()
+    changes = np.concatenate([[0], np.nonzero(np.diff(states, prepend=states[0]))[0] + 1])
+    seg_ids = np.repeat(np.arange(len(changes)), np.diff(np.append(changes, len(df))))
+    seg_df = df.copy()
+    seg_df["seg_id"] = seg_ids
+
+    # Aggregate by segment id
+    gb = seg_df.groupby("seg_id", sort=False)
+    segs = gb.agg(
+        state=(state_col, "first"),
+        start_idx=(price_col, lambda x: x.index[0]),
+        end_idx=(price_col, lambda x: x.index[-1]),
+        start_price=(price_col, "first"),
+        end_price=(price_col, "last"),
+        seg_len=(price_col, "size"),
+    ).reset_index()
+
+    segs["seg_return"] = segs["end_price"] / segs["start_price"] - 1
+
+    if timestamp_col and timestamp_col in df:
+        gb_t = seg_df.groupby("seg_id", sort=False)[timestamp_col].agg(["first", "last"]).rename(
+            columns={"first": "start_time", "last": "end_time"}
+        )
+        segs = segs.join(gb_t, on="seg_id")
+
+    return segs
+
+
+__all__ = ["build_flip_segments"]
diff --git a/src/ta_lab2/features/trend.py b/src/ta_lab2/features/trend.py
new file mode 100644
index 0000000..e4756cd
--- /dev/null
+++ b/src/ta_lab2/features/trend.py
@@ -0,0 +1,76 @@
+# src/ta_lab2/features/trend.py
+"""
+Trend labeling utilities
+
+Provides slope-based or flat-zone trend classification on arbitrary numeric series.
+"""
+
+from __future__ import annotations
+import numpy as np
+import pandas as pd
+
+
+def compute_trend_labels(
+    df: pd.DataFrame,
+    price_col: str = "close",
+    window: int = 21,
+    mode: str = "flat_zone",
+    flat_thresh: float = 0.0,
+    label_col: str | None = None,
+) -> pd.DataFrame:
+    """
+    Compute trend labels for a given price series.
+
+    Parameters
+    ----------
+    df : pd.DataFrame
+        Input DataFrame containing at least one price column.
+    price_col : str, default "close"
+        Column used to compute rolling slope / trend.
+    window : int, default 21
+        Rolling lookback window for slope calculation.
+    mode : str, default "flat_zone"
+        Labeling strategy: "binary", "three_state", or "flat_zone".
+    flat_thresh : float, default 0.0
+        Flat-zone threshold (absolute slope). If 0, uses 20th percentile of |slope|.
+    label_col : str or None
+        If given, output labels are stored under this name.
+        If None, uses f"trend_{mode}_{window}".
+
+    Returns
+    -------
+    df : pd.DataFrame
+        Original DataFrame with an added label column.
+    """
+    s = df[price_col].astype(float)
+    if len(s) < window:
+        df[label_col or f"trend_{mode}_{window}"] = np.nan
+        return df
+
+    # Rolling slope via linear regression on index vs price
+    x = np.arange(window)
+    denom = (x - x.mean()).var() * window
+    cov = s.rolling(window).apply(lambda v: np.dot(v - v.mean(), x - x.mean()) / denom, raw=False)
+    slope = cov * window  # approximate slope per index unit
+    df[f"{price_col}_slope_{window}"] = slope
+
+    # Determine threshold if flat_zone and threshold=0
+    if mode == "flat_zone" and flat_thresh == 0:
+        flat_thresh = np.nanpercentile(np.abs(slope.dropna()), 20) or 0.0
+
+    if mode == "binary":
+        label = np.where(slope > 0, 1, -1)
+    elif mode == "three_state":
+        pct = np.nanpercentile(np.abs(slope.dropna()), [33, 67])
+        lo, hi = pct[0], pct[1]
+        label = np.where(
+            slope.abs() < lo, 0,
+            np.where(slope > 0, 1, -1)
+        )
+    elif mode == "flat_zone":
+        label = np.where(np.abs(slope) < flat_thresh, 0, np.sign(slope))
+    else:
+        raise ValueError(f"Unknown mode '{mode}'")
+
+    df[label_col or f"trend_{mode}_{window}"] = label.astype("Int8")
+    return df
diff --git a/src/ta_lab2/features/vol.py b/src/ta_lab2/features/vol.py
index 64a9858..945ce28 100644
--- a/src/ta_lab2/features/vol.py
+++ b/src/ta_lab2/features/vol.py
@@ -1,15 +1,264 @@
-
-import pandas as pd
+from __future__ import annotations
 import numpy as np
+import pandas as pd
+from typing import Sequence, Iterable, Literal
+
+# =========================================================
+# ---- Core Volatility Estimators (single-bar + rolling) ---
+# =========================================================
+
+def add_parkinson_vol(
+    df: pd.DataFrame,
+    high_col: str = "high",
+    low_col: str = "low",
+    windows: Sequence[int] = (20, 63, 126),
+    annualize: bool = True,
+    periods_per_year: int = 252,
+) -> pd.DataFrame:
+    """Parkinson (1980) range-based volatility estimator."""
+    high, low = df[high_col].astype(float), df[low_col].astype(float)
+    coef = 1.0 / (4.0 * np.log(2.0))
+    hl = (np.log(high / low)) ** 2
+    for w in windows:
+        vol = np.sqrt(coef * hl.rolling(w, min_periods=w).mean())
+        if annualize:
+            vol *= np.sqrt(periods_per_year)
+        df[f"vol_parkinson_{w}"] = vol
+    return df
+
+
+def add_garman_klass_vol(
+    df: pd.DataFrame,
+    open_col: str = "open",
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+    windows: Sequence[int] = (20, 63, 126),
+    annualize: bool = True,
+    periods_per_year: int = 252,
+) -> pd.DataFrame:
+    """Garmanâ€“Klass (1980) volatility estimator."""
+    o, h, l, c = [df[k].astype(float) for k in (open_col, high_col, low_col, close_col)]
+    rs = 0.5 * (np.log(h/l))**2 - (2*np.log(2)-1) * (np.log(c/o))**2
+    for w in windows:
+        vol = np.sqrt(rs.rolling(w, min_periods=w).mean())
+        if annualize:
+            vol *= np.sqrt(periods_per_year)
+        df[f"vol_gk_{w}"] = vol
+    return df

-def add_atr(df: pd.DataFrame, period: int = 14,
-            high_col="high", low_col="low", close_col="close"):
-    high = df[high_col].astype(float)
-    low  = df[low_col].astype(float)
-    close = df[close_col].astype(float)
-    prev_close = close.shift(1)
-    tr = (high - low).abs()
-    tr = np.maximum(tr, (high - prev_close).abs())
-    tr = np.maximum(tr, (low - prev_close).abs())
+
+def add_rogers_satchell_vol(
+    df: pd.DataFrame,
+    open_col: str = "open",
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+    windows: Sequence[int] = (20, 63, 126),
+    annualize: bool = True,
+    periods_per_year: int = 252,
+) -> pd.DataFrame:
+    """Rogersâ€“Satchell (1991) volatility estimator."""
+    o, h, l, c = [df[k].astype(float) for k in (open_col, high_col, low_col, close_col)]
+    rs = (np.log(h/c) * np.log(h/o) + np.log(l/c) * np.log(l/o))
+    for w in windows:
+        vol = np.sqrt(rs.rolling(w, min_periods=w).mean())
+        if annualize:
+            vol *= np.sqrt(periods_per_year)
+        df[f"vol_rs_{w}"] = vol
+    return df
+
+
+def add_atr(
+    df: pd.DataFrame,
+    period: int = 14,
+    open_col: str = "open",
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+) -> pd.DataFrame:
+    """Average True Range (Wilder)."""
+    h, l, c = df[high_col].astype(float), df[low_col].astype(float), df[close_col].astype(float)
+    prev_close = c.shift(1)
+    tr = (h - l).abs()
+    tr = np.maximum(tr, (h - prev_close).abs())
+    tr = np.maximum(tr, (l - prev_close).abs())
     df[f"atr_{period}"] = tr.ewm(alpha=1/period, adjust=False).mean()
     return df
+
+
+def add_logret_stdev_vol(
+    df: pd.DataFrame,
+    logret_cols: Sequence[str] = ("close_log_delta",),
+    windows: Sequence[int] = (20, 63, 126),
+    annualize: bool = True,
+    periods_per_year: int = 252,
+    ddof: int = 0,
+    prefix: str = "vol",
+) -> pd.DataFrame:
+    """Rolling std of log returns."""
+    for name in logret_cols:
+        if name not in df.columns:
+            continue
+        r = df[name].astype(float)
+        for w in windows:
+            vol = r.rolling(w, min_periods=w).std(ddof=ddof)
+            if annualize:
+                vol *= np.sqrt(periods_per_year)
+            df[f"{prefix}_{name}_stdev_{w}"] = vol
+    return df
+
+
+def add_rolling_realized_batch(
+    df: pd.DataFrame,
+    windows: Sequence[int] = (20, 63, 126),
+    which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
+    annualize: bool = True,
+    periods_per_year: int = 252,
+    open_col: str = "open",
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+) -> pd.DataFrame:
+    """Compute realized vol (Parkinson, RS, GK) across windows."""
+    if "parkinson" in which:
+        add_parkinson_vol(df, high_col=high_col, low_col=low_col, windows=windows,
+                          annualize=annualize, periods_per_year=periods_per_year)
+    if "rs" in which:
+        add_rogers_satchell_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
+                                windows=windows, annualize=annualize, periods_per_year=periods_per_year)
+    if "gk" in which:
+        add_garman_klass_vol(df, open_col=open_col, high_col=high_col, low_col=low_col, close_col=close_col,
+                             windows=windows, annualize=annualize, periods_per_year=periods_per_year)
+    return df
+
+
+# =========================================================
+# -------------- Compatibility Shims ----------------------
+# =========================================================
+
+def add_rolling_vol_from_returns_batch(
+    df: pd.DataFrame,
+    *,
+    # New API
+    close_col: str = "close",
+    windows: Sequence[int] = (20, 63, 126),
+    types: Literal["log", "pct", "both"] = "log",
+    annualize: bool = True,
+    periods_per_year: int = 252,
+    ddof: int = 0,
+    prefix: str = "vol",
+    # Legacy API
+    price_col: str | None = None,
+    modes: Iterable[str] | None = None,
+    direction: str | None = None,
+) -> pd.DataFrame:
+    """Rolling historical volatility (new + legacy API)."""
+    # --- Backward compat mapping ---
+    if price_col is not None:
+        close_col = price_col
+    if modes is not None:
+        modes = tuple(str(m).lower() for m in modes)
+        if "log" in modes and "pct" in modes:
+            types = "both"
+        elif "pct" in modes:
+            types = "pct"
+        else:
+            types = "log"
+
+    px = df[close_col].astype(float)
+    r_log = np.log(px / px.shift(1))
+    r_pct = px.pct_change()
+
+    if types in ("log", "both"):
+        for w in windows:
+            vol = r_log.rolling(w, min_periods=w).std(ddof=ddof)
+            if annualize:
+                vol *= np.sqrt(periods_per_year)
+            df[f"{prefix}_log_roll_{w}"] = vol
+
+    if types in ("pct", "both"):
+        for w in windows:
+            vol = r_pct.rolling(w, min_periods=w).std(ddof=ddof)
+            if annualize:
+                vol *= np.sqrt(periods_per_year)
+            df[f"{prefix}_pct_roll_{w}"] = vol
+
+    return df
+
+
+def add_volatility_features(
+    df: pd.DataFrame,
+    *,
+    # single-bar
+    do_atr: bool = True,
+    do_parkinson: bool = True,
+    do_rs: bool = True,
+    do_gk: bool = True,
+    atr_period: int = 14,
+    # rolling returns vol
+    ret_windows: Sequence[int] = (20, 63, 126),
+    ret_types: Literal["log", "pct", "both"] = "both",
+    ret_annualize: bool = True,
+    ret_periods_per_year: int = 252,
+    ret_ddof: int = 0,
+    ret_prefix: str = "vol",
+    # rolling realized vol
+    rv_windows: Sequence[int] = (20, 63, 126),
+    rv_which: Iterable[Literal["parkinson", "rs", "gk"]] = ("parkinson", "rs", "gk"),
+    rv_annualize: bool = True,
+    rv_periods_per_year: int = 252,
+    # column names
+    open_col: str = "open",
+    high_col: str = "high",
+    low_col: str = "low",
+    close_col: str = "close",
+    # Legacy API
+    rolling_windows: Sequence[int] | None = None,
+    direction: str | None = None,
+) -> pd.DataFrame:
+    """Unified volatility orchestrator with legacy support."""
+    # ---- Backward compatibility ----
+    if rolling_windows is not None:
+        ret_windows = tuple(rolling_windows)
+        rv_windows = tuple(rolling_windows)
+    # (direction accepted but unused; kept for API continuity)
+
+    # ---- Single-bar ----
+    if do_parkinson:
+        add_parkinson_vol(df, high_col=high_col, low_col=low_col, windows=(1,))
+    if do_rs:
+        add_rogers_satchell_vol(df, open_col=open_col, high_col=high_col, low_col=low_col,
+                                close_col=close_col, windows=(1,))
+    if do_gk:
+        add_garman_klass_vol(df, open_col=open_col, high_col=high_col, low_col=low_col,
+                             close_col=close_col, windows=(1,))
+    if do_atr:
+        add_atr(df, period=atr_period, high_col=high_col, low_col=low_col, close_col=close_col)
+
+    # ---- Rolling from returns ----
+    add_rolling_vol_from_returns_batch(
+        df,
+        close_col=close_col,
+        windows=ret_windows,
+        types=ret_types,
+        annualize=ret_annualize,
+        periods_per_year=ret_periods_per_year,
+        ddof=ret_ddof,
+        prefix=ret_prefix,
+    )
+
+    # ---- Rolling realized batch ----
+    add_rolling_realized_batch(
+        df,
+        windows=rv_windows,
+        which=rv_which,
+        annualize=rv_annualize,
+        periods_per_year=rv_periods_per_year,
+        open_col=open_col,
+        high_col=high_col,
+        low_col=low_col,
+        close_col=close_col,
+    )
+
+    return df
diff --git a/src/ta_lab2/pipelines/btc_pipeline.py b/src/ta_lab2/pipelines/btc_pipeline.py
index 26e2182..5c00f95 100644
--- a/src/ta_lab2/pipelines/btc_pipeline.py
+++ b/src/ta_lab2/pipelines/btc_pipeline.py
@@ -1,188 +1,379 @@
-# -*- coding: utf-8 -*-
-"""
-Created on Fri Oct 31 16:05:09 2025
+# src/ta_lab2/pipelines/btc_pipeline.py
+from __future__ import annotations

-@author: asafi
-"""
-
-import os, re, argparse
-import pandas as pd
+from dataclasses import asdict, is_dataclass
+from typing import Iterable, Mapping, Dict, Any
+import inspect
 import numpy as np
+import pandas as pd

-from ta_lab2.resample import bin_by_calendar
+# --- Features / indicators ---
 from ta_lab2.features.calendar import expand_datetime_features_inplace
-from ta_lab2.features.ema import add_ema_columns, add_ema_d1, add_ema_d2
-from ta_lab2.features.returns import add_returns
-from ta_lab2.features.vol import add_atr
-from ta_lab2.regimes.comovement import build_alignment_frame, sign_agreement, rolling_agreement
-from ta_lab2.regimes.flips import (
-    sign_from_series, detect_flips, label_regimes_from_flips,
-    attach_regimes, regime_stats
+from ta_lab2.features.ema import (
+    add_ema_columns,
+    add_ema_d1,
+    add_ema_d2,
+    prepare_ema_helpers,
+)
+from ta_lab2.features.indicators import rsi, macd, bollinger
+from ta_lab2.features.returns import b2t_pct_delta, b2t_log_delta
+from ta_lab2.features.vol import (
+    add_volatility_features,            # single-bar + Parkinson/RS/GK + ATR
+    add_rolling_vol_from_returns_batch, # realized vol from returns
 )

-# -------- utils --------
-
-def _clean_headers(cols):
-    return [re.sub(r"\s+", " ", c.strip().lower()).replace(" ", "_") for c in cols]
-
-def _to_num(s):
-    return pd.to_numeric(
-        pd.Series(s).astype(str).str.replace(",", "", regex=False).replace({"-": None, "": None}),
-        errors="coerce"
-    )
-
-def _parse_epoch_series(x: pd.Series) -> pd.Series:
-    x = pd.to_numeric(x, errors="coerce")
-    if x.dropna().median() > 10_000_000_000:
-        return pd.to_datetime(x, unit="ms", utc=True, errors="coerce")
-    return pd.to_datetime(x, unit="s", utc=True, errors="coerce")
-
-def _scal(s):
-    return s.iloc[0] if hasattr(s, "iloc") else s
-
-# -------- IO + cleaning --------
-
-def load_clean_csv(csv_path: str) -> pd.DataFrame:
-    df = pd.read_csv(csv_path)
-    df.columns = _clean_headers(df.columns)
+# --- Regimes / segments ---
+from ta_lab2.regimes.comovement import (
+    compute_ema_comovement_stats,
+    compute_ema_comovement_hierarchy,
+)

-    # Build timeopen (prefer timeopen; fallback to epoch timestamp)
-    if "timeopen" in df.columns:
-        dt = pd.to_datetime(df["timeopen"], errors="coerce", utc=True)
+# segments live under features
+from ta_lab2.features.segments import build_flip_segments
+
+
+# ===========================
+# Signature-tolerant helpers
+# ===========================
+def _filter_kwargs(func, kwargs: Dict[str, Any]) -> Dict[str, Any]:
+    sig = inspect.signature(func)
+    return {k: v for k, v in kwargs.items() if k in sig.parameters}
+
+def _try_call_with_windows(func, df: pd.DataFrame, ema_windows, **kwargs):
+    """
+    For comovement/hierarchy funcs that accept a windows argument.
+    Tries periods=, windows=, ema_windows=, then positional.
+    """
+    fk = _filter_kwargs(func, kwargs)
+    psig = inspect.signature(func).parameters
+
+    for key in ("periods", "windows", "ema_windows"):
+        try:
+            if key in psig:
+                return func(df, **{key: list(ema_windows)}, **fk)
+        except TypeError:
+            pass
+
+    # Positional windows
+    try:
+        return func(df, list(ema_windows), **fk)
+    except TypeError:
+        return func(df, **fk)
+
+def _call_ema_comovement(df: pd.DataFrame, ema_windows, **kwargs):
+    func = compute_ema_comovement_stats
+    try:
+        return _try_call_with_windows(func, df, ema_windows, **kwargs)
+    except TypeError:
+        pass
+    kw2 = dict(kwargs)
+    if "close_col" in kw2 and "price_col" not in kw2:
+        kw2["price_col"] = kw2.pop("close_col")
+    return _try_call_with_windows(func, df, ema_windows, **kw2)
+
+def _call_ema_hierarchy(df: pd.DataFrame, ema_windows, **kwargs):
+    func = compute_ema_comovement_hierarchy
+    try:
+        return _try_call_with_windows(func, df, ema_windows, **kwargs)
+    except TypeError:
+        pass
+    kw2 = dict(kwargs)
+    if "close_col" in kw2 and "price_col" not in kw2:
+        kw2["price_col"] = kw2.pop("close_col")
+    return _try_call_with_windows(func, df, ema_windows, **kw2)
+
+def _call_build_segments(df: pd.DataFrame, *, price_col="close", state_col="trend_state", date_col="timestamp"):
+    """
+    Robust caller for features.segments.build_flip_segments (no windows here).
+    Only pass kwargs the function accepts; map alternate param names if present.
+    """
+    func = build_flip_segments
+    psig = inspect.signature(func).parameters
+    kwargs: Dict[str, Any] = {}
+
+    # price column
+    for k in ("price_col", "field", "col"):
+        if k in psig:
+            kwargs[k] = price_col
+            break
+
+    # state column
+    for k in ("state_col", "label_col", "trend_col"):
+        if k in psig:
+            kwargs[k] = state_col
+            break
+
+    # timestamp column
+    for k in ("timestamp_col", "date_col", "time_col", "ts_col"):
+        if k in psig:
+            kwargs[k] = date_col
+            break
+
+    kwargs = _filter_kwargs(func, kwargs)
+    return func(df, **kwargs)
+
+
+# ===========================
+# Utility helpers
+# ===========================
+def _infer_timestamp_col(df: pd.DataFrame, fallback: str = "timestamp") -> str:
+    if fallback in df.columns:
+        return fallback
+    for c in df.columns:
+        cl = str(c).lower()
+        if "time" in cl or "date" in cl:
+            return c
+    return fallback
+
+def _coerce_df(df_or_path: str | pd.DataFrame) -> pd.DataFrame:
+    if isinstance(df_or_path, pd.DataFrame):
+        df = df_or_path.copy()
     else:
-        dt = pd.NaT
-
-    if dt.isna().mean() > 0.5 and "timestamp" in df.columns:
-        ts_dt = _parse_epoch_series(df["timestamp"])
-        if ts_dt.notna().sum() > dt.notna().sum():
-            dt = ts_dt
-
-    if pd.isna(dt).all():
-        raise KeyError("Could not parse timestamps from 'timeOpen' or 'timestamp'.")
-
-    df["timeopen"] = dt
-    for col in ["open", "high", "low", "close", "volume", "marketcap"]:
-        if col in df.columns:
-            df[col] = _to_num(df[col])
-
-    df = df.dropna(subset=["timeopen"]).sort_values("timeopen").reset_index(drop=True)
-
-    print("Loaded rows:", len(df))
-    print("Date range:", df["timeopen"].min(), "â†’", df["timeopen"].max())
-    print("Columns now:", list(df.columns))
+        df = pd.read_csv(df_or_path)
+    df.columns = [str(c).strip().lower() for c in df.columns]
+    ts = _infer_timestamp_col(df, "timestamp")
+    if ts != "timestamp":
+        df = df.rename(columns={ts: "timestamp"})
     return df

-# -------- timeframes --------
-
-def build_timeframes(df: pd.DataFrame):
-    expand_datetime_features_inplace(df, "timeopen", prefix="timeopen")
-
-    weekly = bin_by_calendar(df, "timeopen", "W-SUN").rename(columns={"period_end": "date"})
-    weekly["timeframe"] = "1W"
-
-    monthly = bin_by_calendar(df, "timeopen", "MS").rename(columns={"period_end": "date"})
-    monthly["timeframe"] = "1M"
-
-    daily = df.rename(columns={"timeopen": "date"})[["date","open","high","low","close","volume"]].copy()
-    daily["timeframe"] = "1D"
-
-    for d in (daily, weekly, monthly):
-        d["symbol"] = "BTC-USD"
-
-    return daily, weekly, monthly
-
-# -------- enrichment --------
-
-def enrich(bars: pd.DataFrame) -> pd.DataFrame:
-    add_returns(bars, close_col="close")  # local impl: creates close_ret_1
-    add_ema_columns(bars, ["close"], [21,50,100,200])
-    add_ema_d1(bars, ["close"], [21,50,100,200])
-    add_ema_d2(bars, ["close"], [21,50,100,200])
-    add_atr(bars, period=14, high_col="high", low_col="low", close_col="close")
-    return bars
-
-def enrich_all(daily, weekly, monthly):
-    return enrich(daily.copy()), enrich(weekly.copy()), enrich(monthly.copy())
-
-# -------- diagnostics --------
-
-def print_ema21_agreement(daily_en: pd.DataFrame, weekly_en: pd.DataFrame):
-    d = daily_en[["date","close_ema_21_d1"]].sort_values("date")
-    w = weekly_en[["date","close_ema_21_d1"]].sort_values("date").rename(columns={"close_ema_21_d1":"close_ema_21_d1_w"})
-    cmp = pd.merge_asof(d, w, on="date", direction="backward")
-    cmp["ema21_d1_agree"] = (cmp["close_ema_21_d1"] * cmp["close_ema_21_d1_w"]) > 0
-    print("Daily vs Weekly EMA21 slope agreement:", f"{cmp['ema21_d1_agree'].mean():.2%}")
-
-def boundary_check(daily, weekly, monthly, dates_utc):
-    for dt_str in dates_utc:
-        dt = pd.Timestamp(dt_str, tz="UTC")
-        drow = daily.loc[daily["date"] == dt]
-        wrow = weekly.loc[weekly["date"] == dt]
-        mrow = monthly.loc[monthly["date"] == dt]
-        if not drow.empty and not wrow.empty:
-            print("WEEK check:", dt_str, "daily open:", float(_scal(drow["open"])), "weekly open:", float(_scal(wrow["open"])))
-        if not drow.empty and not mrow.empty:
-            print("MONTH check:", dt_str, "daily open:", float(_scal(drow["open"])), "monthly open:", float(_scal(mrow["open"])))
-
-# -------- regimes --------
-
-def compute_regimes(daily_en: pd.DataFrame):
-    daily_sig = sign_from_series(daily_en.copy(), "close_ema_21_d1", out_col="d_slope_sign")
-
-    if "close_ret_1" not in daily_sig.columns:
-        add_returns(daily_sig, close_col="close")
-
-    flips = detect_flips(daily_sig, "d_slope_sign", min_separation=2)
-    regime_ids = label_regimes_from_flips(len(daily_sig), flips["idx"].tolist())
-    daily_reg = attach_regimes(daily_sig, regime_ids, col="regime_id")
-
-    if "close_ret_1" not in daily_reg.columns:
-        # fallback: compute forward simple return
-        daily_reg["close_ret_1"] = (daily_reg["close"].shift(-1) / daily_reg["close"]) - 1
-
-    stats = regime_stats(daily_reg, regime_col="regime_id", ret_col="close_ret_1")
-    return daily_reg, stats
-
-# -------- comovement --------
-
-def compute_comovement(daily_en: pd.DataFrame, weekly_en: pd.DataFrame):
-    al = build_alignment_frame(
-        daily_en, weekly_en,
-        on="date", low_cols=["close_ema_21_d1"], high_cols=["close_ema_21_d1"]
-    ).rename(columns={"close_ema_21_d1": "d_slope", "close_ema_21_d1_w": "w_slope"})
-    al, pct = sign_agreement(al, "d_slope", "w_slope", out_col="agree")
-    al = rolling_agreement(al, "d_slope", "w_slope", window=63)
-    return al, pct
-
-# -------- main --------
-
-def main(argv=None):
-    ap = argparse.ArgumentParser()
-    ap.add_argument("--csv", required=True, help="Path to BTC CSV (CoinMarketCap export).")
-    ap.add_argument("--outdir", default="", help="Optional directory to save artifacts.")
-    ap.add_argument("--check", nargs="*", help="Optional UTC dates to boundary-check, e.g. 2015-01-01 2015-02-01")
-    args = ap.parse_args(argv)
-
-    df = load_clean_csv(args.csv)
-    daily, weekly, monthly = build_timeframes(df)
-    daily_en, weekly_en, monthly_en = enrich_all(daily, weekly, monthly)
-
-    print_ema21_agreement(daily_en, weekly_en)
-
-    if args.check:
-        boundary_check(daily, weekly, monthly, args.check)
-
-    daily_reg, stats = compute_regimes(daily_en)
-    print(stats.head())
-
-    al, pct = compute_comovement(daily_en, weekly_en)
-
-    if args.outdir:
-        os.makedirs(args.outdir, exist_ok=True)
-        daily_en.to_parquet(os.path.join(args.outdir, "daily_en.parquet"), index=False)
-        weekly_en.to_parquet(os.path.join(args.outdir, "weekly_en.parquet"), index=False)
-        monthly_en.to_parquet(os.path.join(args.outdir, "monthly_en.parquet"), index=False)
-        daily_reg.to_parquet(os.path.join(args.outdir, "daily_regimes.parquet"), index=False)
-        stats.to_csv(os.path.join(args.outdir, "regime_stats.csv"), index=False)
-        al.to_parquet(os.path.join(args.outdir, "alignment.parquet"), index=False)
-        print(f"Saved outputs to: {args.outdir}")
+def _maybe_from_config(value, default):
+    if value is None:
+        return default
+    if is_dataclass(value):
+        value = asdict(value)
+    if isinstance(value, Mapping):
+        return value
+    return value
+
+
+# ===========================
+# Main pipeline
+# ===========================
+def run_btc_pipeline(
+    csv_path: str | pd.DataFrame,
+    *,
+    # Columns & windows
+    price_cols: Iterable[str] = ("open", "high", "low", "close"),
+    ema_windows: Iterable[int] = (21, 50, 100, 200),
+    returns_modes: Iterable[str] = ("log", "pct"),
+    returns_windows: Iterable[int] = (30, 60, 90),
+
+    # Optional resample (e.g., "1H", "1D")
+    resample: str | None = None,
+
+    # Feature-stage toggles
+    do_calendar: bool = True,
+    do_indicators: bool = True,
+    do_returns: bool = True,
+    do_volatility: bool = True,
+    do_ema: bool = True,
+    do_regimes: bool = True,
+    do_segments: bool = True,
+
+    # Optional config override
+    config: Mapping | object | None = None,
+) -> dict:
+    """End-to-end, testable pipeline aligned to the modular ta_lab2 layout."""
+    # --- Config override ---
+    if config is not None:
+        cfg = _maybe_from_config(config, {})
+        if isinstance(cfg, Mapping):
+            price_cols      = tuple(cfg.get("price_cols",      price_cols))
+            ema_windows     = tuple(cfg.get("ema_windows",     ema_windows))
+            returns_modes   = tuple(cfg.get("returns_modes",   returns_modes))
+            returns_windows = tuple(cfg.get("returns_windows", returns_windows))
+            resample        = cfg.get("resample",              resample)
+
+            do_calendar   = cfg.get("do_calendar",   do_calendar)
+            do_indicators = cfg.get("do_indicators", do_indicators)
+            do_returns    = cfg.get("do_returns",    do_returns)
+            do_volatility = cfg.get("do_volatility", do_volatility)
+            do_ema        = cfg.get("do_ema",        do_ema)
+            do_regimes    = cfg.get("do_regimes",    do_regimes)
+            do_segments   = cfg.get("do_segments",   do_segments)
+
+    # --- Load / normalize ---
+    df = _coerce_df(csv_path)
+
+    # --- Calendar ---
+    if do_calendar:
+        expand_datetime_features_inplace(df, base_timestamp_col="timestamp")
+
+    # --- Optional resample ---
+    if resample:
+        agg = {"open": "first", "high": "max", "low": "min", "close": "last", "volume": "sum"}
+        have = {k: v for k, v in agg.items() if k in df.columns}
+        if have:
+            df = (
+                df.set_index("timestamp").resample(resample).agg(have).dropna().reset_index()
+            )
+            if do_calendar:
+                expand_datetime_features_inplace(df, base_timestamp_col="timestamp")
+
+    # --- Indicators ---
+    if do_indicators and "close" in df.columns:
+        out = rsi(df, period=14, price_col="close")
+        df[out.name] = out
+        df = df.join(macd(df, price_col="close"))
+        df = df.join(bollinger(df, price_col="close"))
+
+    # --- Engineered columns ---
+    if all(k in df.columns for k in ("high", "low", "close", "open")):
+        df["close-open"] = df["close"].astype(float) - df["open"].astype(float)
+        df["range"] = df["high"].astype(float) - df["low"].astype(float)
+
+    # --- Returns (pct + log) ---
+    if do_returns:
+        b2t_pct_delta(
+            df,
+            cols=list(price_cols) + (["close-open"] if "close-open" in df.columns else []),
+            extra_cols=(["range"] if "range" in df.columns else []),
+            round_places=6,
+            direction="newest_top",
+            open_col="open",
+            close_col="close",
+        )
+        b2t_log_delta(
+            df,
+            cols=list(price_cols) + (["close-open"] if "close-open" in df.columns else []),
+            extra_cols=(["range"] if "range" in df.columns else []),
+            prefix="_log_delta",
+            round_places=6,
+            add_intraday=True,
+            open_col="open",
+            close_col="close",
+        )
+
+    # --- Volatility ---
+    if do_volatility:
+        df = add_volatility_features(
+            df,
+            do_atr=True,
+            do_parkinson=True,
+            do_rs=True,
+            do_gk=True,
+            rolling_windows=tuple(returns_windows),
+            direction="newest_top",
+        )
+        df = add_rolling_vol_from_returns_batch(
+            df,
+            price_col="close",
+            modes=tuple(returns_modes),
+            windows=tuple(returns_windows),
+            annualize=True,
+            direction="newest_top",
+        )
+
+    # --- EMAs + diffs + helpers ---
+    if do_ema:
+        base_cols = list(price_cols)
+        add_ema_columns(df, base_cols, list(ema_windows))
+        add_ema_d1(df, base_cols, list(ema_windows), direction="newest_top", overwrite=False, round_places=6)
+        add_ema_d2(df, base_cols, list(ema_windows), direction="newest_top", overwrite=False, round_places=6)
+        prepare_ema_helpers(df, base_cols, list(ema_windows), direction="newest_top", scale="bps")
+
+    # --- Regimes ---
+    major_stats = None
+    if do_regimes:
+        res = _call_ema_comovement(
+            df.copy(),
+            ema_windows,
+            direction="newest_top",
+            close_col="close",
+            return_col="close_pct_delta",
+        )
+        labeled = None
+        if isinstance(res, tuple):
+            if len(res) >= 2:
+                major_stats, labeled = res[0], res[1]
+            elif len(res) == 1:
+                major_stats = res[0]
+        elif isinstance(res, dict):
+            major_stats = res  # dict (corr/agree/meta)
+
+        # If no labeled regimes returned, synthesize a minimal trend_state from EMA slope
+        if isinstance(labeled, pd.DataFrame) and "regime_label" in labeled.columns:
+            df["trend_state"] = labeled["regime_label"]
+        else:
+            slope_col = "close_ema_21_slope"
+            if slope_col in df.columns:
+                df["trend_state"] = np.sign(pd.to_numeric(df[slope_col], errors="coerce")).fillna(0).astype(int)
+            else:
+                if "close_pct_delta" in df.columns:
+                    df["trend_state"] = np.sign(pd.to_numeric(df["close_pct_delta"], errors="coerce")).fillna(0).astype(int)
+                else:
+                    df["trend_state"] = 0
+
+    # --- Segments ---
+    segments = pd.DataFrame()
+    seg_summary = pd.DataFrame()
+    seg_by_year = pd.DataFrame()
+    if do_segments:
+        seg_res = _call_build_segments(
+            df,
+            price_col="close",
+            state_col="trend_state",
+            date_col="timestamp",
+        )
+        # Accept DataFrame, (segments, summary), or (segments, summary, by_year)
+        if isinstance(seg_res, pd.DataFrame):
+            segments = seg_res
+        elif isinstance(seg_res, tuple):
+            if len(seg_res) >= 3:
+                segments, seg_summary, seg_by_year = seg_res[:3]
+            elif len(seg_res) == 2:
+                segments, seg_summary = seg_res
+            elif len(seg_res) == 1:
+                segments = seg_res[0]
+        elif isinstance(seg_res, dict):
+            segments = seg_res.get("segments", pd.DataFrame())
+            seg_summary = seg_res.get("summary", pd.DataFrame())
+            seg_by_year = seg_res.get("by_year", pd.DataFrame())
+
+    # --- Hierarchy (major/sub) ---
+    h_major = pd.DataFrame()
+    h_scores = pd.DataFrame()
+    if do_regimes:
+        hres = _call_ema_hierarchy(
+            df,
+            ema_windows,
+            close_col="close",
+            direction="newest_top",
+            return_col="close_pct_delta",
+        )
+        if isinstance(hres, tuple):
+            if len(hres) == 3:
+                h_major, _, h_scores = hres
+            elif len(hres) == 2:
+                h_major, h_scores = hres
+            elif len(hres) == 1:
+                h_major = hres[0]
+        elif isinstance(hres, dict):
+            h_major = hres.get("corr", pd.DataFrame())
+            h_scores = hres.get("scores", pd.DataFrame())
+
+    # --- Summary (robust to different segment schemas) ---
+    ret_col = next((c for c in ("ret_close_to_close", "seg_return", "return", "ret")
+                    if c in segments.columns), None)
+    len_col = next((c for c in ("bars", "seg_len", "length", "len")
+                    if c in segments.columns), None)
+
+    mean_seg_return = float(segments[ret_col].mean()) if ret_col else 0.0
+    mean_seg_len    = float(segments[len_col].mean()) if len_col else 0.0
+
+    summary = {
+        "n_rows": int(len(df)),
+        "n_segments": int(len(segments)),
+        "mean_seg_return": mean_seg_return,
+        "mean_seg_len": mean_seg_len,
+    }
+
+    return {
+        "data": df,
+        "segments": segments,
+        "segment_summary": seg_summary,
+        "segment_by_year": seg_by_year,
+        "regime_major": (major_stats.get("corr") if isinstance(major_stats, dict) else major_stats),
+        "regime_sub": h_scores,
+        "summary": summary,
+    }
diff --git a/src/ta_lab2/regimes/__init__.py b/src/ta_lab2/regimes/__init__.py
index 1a6b0bd..7370a59 100644
--- a/src/ta_lab2/regimes/__init__.py
+++ b/src/ta_lab2/regimes/__init__.py
@@ -1,5 +1,33 @@
-from .flips import (
-    sign_from_series, detect_flips, label_regimes_from_flips,
-    attach_regimes, regime_stats
+# src/ta_lab2/regimes/__init__.py
+"""
+Public API for `ta_lab2.regimes`.
+
+Exports analytics utilities from `comovement` and the `build_flip_segments`
+shim (implementation lives in `ta_lab2.features.segments`).
+"""
+
+from .comovement import (
+    compute_ema_comovement_stats,
+    compute_ema_comovement_hierarchy,
+    build_alignment_frame,
+    sign_agreement,
+    rolling_agreement,
+    forward_return_split,
+    lead_lag_max_corr,
 )
-from .comovement import build_alignment_frame, sign_agreement, rolling_agreement
+
+# Legacy import path:
+#   from ta_lab2.regimes.segments import build_flip_segments
+# The actual implementation resides in ta_lab2.features.segments.
+from .segments import build_flip_segments
+
+__all__ = [
+    "compute_ema_comovement_stats",
+    "compute_ema_comovement_hierarchy",
+    "build_alignment_frame",
+    "sign_agreement",
+    "rolling_agreement",
+    "forward_return_split",
+    "lead_lag_max_corr",
+    "build_flip_segments",
+]
diff --git a/src/ta_lab2/regimes/comovement.py b/src/ta_lab2/regimes/comovement.py
index 2d99560..77b253b 100644
--- a/src/ta_lab2/regimes/comovement.py
+++ b/src/ta_lab2/regimes/comovement.py
@@ -1,10 +1,28 @@
-# ta_lab2/regimes/comovement.py
+# src/ta_lab2/regimes/comovement.py
+"""
+Comovement utilities (no-loss merged module)
+
+Preserves original helpers:
+- _ensure_sorted, build_alignment_frame
+- sign_agreement, rolling_agreement
+- forward_return_split
+- lead_lag_max_corr
+
+Adds:
+- compute_ema_comovement_stats: correlation + sign-agreement across EMA columns
+- compute_ema_comovement_hierarchy: derives an ordered â€œhierarchyâ€ from EMA corr
+"""
+
 from __future__ import annotations
-from typing import Optional, Dict, Iterable
+from typing import Optional, Dict, Iterable, Sequence, Iterable as _Iterable
+import itertools
 import numpy as np
 import pandas as pd


+# ---------------------------------------------------------------------
+# Original utilities (PRESERVED)
+# ---------------------------------------------------------------------
 def _ensure_sorted(df: pd.DataFrame, on: str) -> pd.DataFrame:
     if on not in df.columns:
         raise KeyError(f"Column '{on}' not found in DataFrame.")
@@ -18,19 +36,14 @@ def build_alignment_frame(
     high_df: pd.DataFrame,
     *,
     on: str = "date",
-    low_cols: Optional[Iterable[str]] = None,
-    high_cols: Optional[Iterable[str]] = None,
+    low_cols: Optional[_Iterable[str]] = None,
+    high_cols: Optional[_Iterable[str]] = None,
     suffix_low: str = "",
     suffix_high: str = "_w",
     direction: str = "backward",
 ) -> pd.DataFrame:
     """
     Merge-asof align low timeframe rows with the most recent high timeframe row.
-
-    low_df:  typically daily/enriched data
-    high_df: typically weekly/monthly enriched data
-    on:      timestamp column present in both dataframes (tz-aware OK)
-    direction: 'backward' means use the last high-row <= low-row timestamp
     """
     low_cols = list(low_cols or [])
     high_cols = list(high_cols or [])
@@ -38,7 +51,6 @@ def build_alignment_frame(
     a = _ensure_sorted(low_df[[on] + low_cols].copy(), on)
     b = _ensure_sorted(high_df[[on] + high_cols].copy(), on)

-    # apply suffixes (keep the 'on' column name intact)
     if suffix_low:
         a = a.rename(columns={c: f"{c}{suffix_low}" for c in low_cols})
     if suffix_high:
@@ -55,10 +67,7 @@ def sign_agreement(
     *,
     out_col: str = "agree",
 ) -> tuple[pd.DataFrame, float]:
-    """
-    Mark True where signs of two series match (strictly > 0).
-    Returns the modified df and the agreement rate.
-    """
+    """Mark True where signs of two series match (strictly > 0)."""
     s = (np.sign(df[col_a]) * np.sign(df[col_b])) > 0
     df[out_col] = s
     return df, float(np.nanmean(s.astype(float)))
@@ -73,9 +82,7 @@ def rolling_agreement(
     out_col: Optional[str] = None,
     min_periods: Optional[int] = None,
 ) -> pd.DataFrame:
-    """
-    Rolling share of days where signs match over a window.
-    """
+    """Rolling share of days where signs match over a window."""
     if out_col is None:
         out_col = f"agree_{window}"
     if min_periods is None:
@@ -86,22 +93,15 @@ def rolling_agreement(
     return df


-# ---- optional extras (nice to have) -----------------------------------------
-
-def forward_return_split(
-    df: pd.DataFrame,
-    agree_col: str,
-    fwd_ret_col: str,
-) -> pd.DataFrame:
-    """
-    Compare forward returns when agree==True vs False.
-    """
+def forward_return_split(df: pd.DataFrame, agree_col: str, fwd_ret_col: str) -> pd.DataFrame:
+    """Compare forward returns when agree==True vs False."""
     sub = df[[agree_col, fwd_ret_col]].dropna()
-    return (sub
-            .groupby(agree_col)[fwd_ret_col]
-            .agg(count="count", mean="mean", median="median", std="std")
-            .reset_index()
-            .rename(columns={agree_col: "agree"}))
+    return (
+        sub.groupby(agree_col)[fwd_ret_col]
+        .agg(count="count", mean="mean", median="median", std="std")
+        .reset_index()
+        .rename(columns={agree_col: "agree"})
+    )


 def lead_lag_max_corr(
@@ -128,3 +128,115 @@ def lead_lag_max_corr(
     s = pd.Series(corrs).dropna()
     best_lag = int(s.abs().idxmax()) if not s.empty else 0
     return {"best_lag": best_lag, "best_corr": float(s.loc[best_lag]) if not s.empty else np.nan, "corr_by_lag": s}
+
+
+# ---------------------------------------------------------------------
+# New EMA comovement stats (ADDED)
+# ---------------------------------------------------------------------
+def _find_ema_columns(df: pd.DataFrame, token: str = "_ema_") -> list[str]:
+    """Auto-detect EMA columns by substring token (default: '_ema_')."""
+    cols = [c for c in df.columns if token in c]
+    def _tail_int(name: str) -> int:
+        try:
+            return int(name.split("_")[-1])
+        except Exception:
+            return 10**9
+    return sorted(cols, key=_tail_int)
+
+
+def _pairwise(cols: Sequence[str]) -> Iterable[tuple[str, str]]:
+    return itertools.combinations(cols, 2)
+
+
+def compute_ema_comovement_stats(
+    df: pd.DataFrame,
+    *,
+    ema_cols: Sequence[str] | None = None,
+    method: str = "spearman",      # "pearson" | "spearman"
+    agree_on_sign_of_diff: bool = True,
+    diff_window: int = 1,
+) -> Dict[str, pd.DataFrame]:
+    """
+    Compute co-movement stats among EMA series.
+
+    Returns dict:
+      - 'corr':  correlation matrix over EMA levels
+      - 'agree': pairwise agreement of sign(dEMA) over `diff_window`
+      - 'meta':  one-row metadata (n_ema, method, diff_window)
+    """
+    if ema_cols is None:
+        ema_cols = _find_ema_columns(df)
+
+    ema_cols = [c for c in ema_cols if c in df.columns]
+    if len(ema_cols) < 2:
+        return {
+            "corr": pd.DataFrame(index=ema_cols, columns=ema_cols, dtype=float),
+            "agree": pd.DataFrame(columns=["a", "b", "agree_rate"], dtype=float),
+            "meta": pd.DataFrame([{"n_ema": len(ema_cols)}]),
+        }
+
+    corr = df[ema_cols].corr(method=method)
+
+    if agree_on_sign_of_diff:
+        diffs = df[ema_cols].diff(diff_window)
+        signs = np.sign(diffs)
+        rows = []
+        for a, b in _pairwise(list(ema_cols)):
+            s_a, s_b = signs[a], signs[b]
+            valid = s_a.notna() & s_b.notna()
+            agree = float((s_a[valid] == s_b[valid]).mean()) if valid.any() else np.nan
+            rows.append({"a": a, "b": b, "agree_rate": agree})
+        agree_df = pd.DataFrame(rows)
+    else:
+        agree_df = pd.DataFrame(columns=["a", "b", "agree_rate"], dtype=float)
+
+    meta = pd.DataFrame([{"n_ema": len(ema_cols), "method": method, "diff_window": diff_window}])
+    return {"corr": corr, "agree": agree_df, "meta": meta}
+
+
+def compute_ema_comovement_hierarchy(
+    df: pd.DataFrame,
+    *,
+    ema_cols: Sequence[str] | None = None,
+    method: str = "spearman",
+) -> Dict[str, object]:
+    """
+    Build a simple ordering (â€œhierarchyâ€) of EMA columns from the correlation matrix.
+
+    - If scipy is not available (default), we derive an order by sorting columns
+      on mean absolute correlation (highest first). This is lightweight and
+      dependency-free.
+    - Returns dictionary with:
+        * 'corr'   : correlation matrix among EMA columns
+        * 'order'  : list of column names sorted by mean |corr|
+        * 'scores' : DataFrame with per-column mean_abs_corr used for ordering
+    """
+    if ema_cols is None:
+        ema_cols = _find_ema_columns(df)
+    ema_cols = [c for c in ema_cols if c in df.columns]
+
+    corr = df[ema_cols].corr(method=method) if len(ema_cols) >= 2 else pd.DataFrame(index=ema_cols, columns=ema_cols)
+    if corr.empty:
+        return {"corr": corr, "order": ema_cols, "scores": pd.DataFrame({"col": ema_cols, "mean_abs_corr": []})}
+
+    # Mean absolute correlation per EMA column (ignore self-corr on the diagonal)
+    abs_corr = corr.abs()
+    np.fill_diagonal(abs_corr.values, np.nan)
+    scores = abs_corr.mean(skipna=True).rename("mean_abs_corr").to_frame()
+    order = list(scores.sort_values("mean_abs_corr", ascending=False).index)
+
+    return {"corr": corr, "order": order, "scores": scores.reset_index().rename(columns={"index": "col"})}
+
+
+__all__ = [
+    # original
+    "_ensure_sorted",
+    "build_alignment_frame",
+    "sign_agreement",
+    "rolling_agreement",
+    "forward_return_split",
+    "lead_lag_max_corr",
+    # added
+    "compute_ema_comovement_stats",
+    "compute_ema_comovement_hierarchy",
+]
diff --git a/src/ta_lab2/regimes/run_btc_pipeline.py b/src/ta_lab2/regimes/run_btc_pipeline.py
index e620e67..62fc958 100644
--- a/src/ta_lab2/regimes/run_btc_pipeline.py
+++ b/src/ta_lab2/regimes/run_btc_pipeline.py
@@ -1,56 +1,85 @@
-@@
--# ---- load your CSV ---------------------------------------------------------
--csv_path = r"C:/Users/asafi/Downloads/ta_lab2/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
--df2 = pd.read_csv(csv_path)
--# Normalize headers to stable names
--df2.columns = _clean_headers(df2.columns)
--...   # (rest of pipeline at import time)
-+from pathlib import Path
-+import pandas as pd
-+import logging
-+
-+log = logging.getLogger(__name__)
-+
-+def run_btc_pipeline(csv_path: str | Path, out_dir: str | Path, **kwargs) -> dict:
-+    """
-+    Run the BTC pipeline.
-+    Parameters
-+    ----------
-+    csv_path : path to source CSV
-+    out_dir  : output directory for artifacts (parquet/csv)
-+    kwargs   : optional tuning params (ema windows, resample rules, etc.)
-+    Returns
-+    -------
-+    dict with key outputs, e.g. file paths or small result stats
-+    """
-+    csv_path = Path(csv_path)
-+    out_dir = Path(out_dir)
-+    out_dir.mkdir(parents=True, exist_ok=True)
-+
-+    if not csv_path.exists():
-+        raise FileNotFoundError(f"Input CSV not found: {csv_path}")
-+
-+    log.info("Loading data from %s", csv_path)
-+    df2 = pd.read_csv(csv_path)
-+    df2.columns = _clean_headers(df2.columns)  # your existing helper
-+
-+    # ... your existing transforms/features/resampling/regimes here ...
-+    # write outputs to out_dir
-+    # e.g., (keep your current filenames, just write relative to out_dir)
-+    # df_daily.to_parquet(out_dir / "daily_en.parquet")
-+    # df_weekly.to_parquet(out_dir / "weekly_en.parquet")
-+    # stats.to_csv(out_dir / "regime_stats.csv", index=False)
-+
-+    return {
-+        "input": str(csv_path),
-+        "out_dir": str(out_dir),
-+        # "n_rows": len(df2),
-+        # "artifacts": [str(out_dir / "daily_en.parquet"), ...]
-+    }
-+
-+if __name__ == "__main__":
-+    # Local manual run (kept for convenience)
-+    DEFAULT_ROOT = Path(__file__).resolve().parents[3]
-+    csv = DEFAULT_ROOT / "data" / "Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv"
-+    out_ = DEFAULT_ROOT / "out"
-+    run_btc_pipeline(csv_path=csv, out_dir=out_)
+# src/ta_lab2/regimes/run_btc_pipeline.py
+from __future__ import annotations
+from pathlib import Path
+from typing import Any
+import pandas as pd
+
+# Import the high-level BTC pipeline from pipelines (keeps orchestration unified)
+from ta_lab2.pipelines.btc_pipeline import run_btc_pipeline as _btc_core
+
+
+def run_btc_pipeline(
+    csv_path: str | Path,
+    out_dir: str | Path,
+    ema_windows: list[int] | None = None,
+    resample: dict | None = None,
+    *,
+    do_calendar: bool = True,
+    do_indicators: bool = True,
+    do_returns: bool = True,
+    do_volatility: bool = True,
+    do_ema: bool = True,
+    do_regimes: bool = True,
+    do_segments: bool = True,
+    config: dict | None = None,
+) -> dict[str, Any]:
+    """
+    Orchestrate the BTC pipeline end-to-end.
+      1) Load CSV from csv_path
+      2) Compute all requested features / regimes
+      3) Write outputs to out_dir
+      4) Return a structured result dict (data + metadata)
+
+    This wrapper keeps the CLI and tests portable while delegating core logic
+    to src/ta_lab2/pipelines/btc_pipeline.py (the canonical implementation).
+    """
+
+    csv_path = Path(csv_path)
+    out_dir = Path(out_dir)
+    out_dir.mkdir(parents=True, exist_ok=True)
+
+    # ---- 1) Load data ----
+    df = pd.read_csv(csv_path)
+
+    # ---- 2) Delegate to the main pipeline ----
+    result = _btc_core(
+        df,
+        price_cols=("open", "high", "low", "close"),
+        ema_windows=tuple(ema_windows or (21, 50, 100, 200)),
+        returns_modes=("log", "pct"),
+        returns_windows=(30, 60, 90),
+        resample=resample.get("freq") if isinstance(resample, dict) else None,
+        do_calendar=do_calendar,
+        do_indicators=do_indicators,
+        do_returns=do_returns,
+        do_volatility=do_volatility,
+        do_ema=do_ema,
+        do_regimes=do_regimes,
+        do_segments=do_segments,
+        config=config,
+    )
+
+    # ---- 3) Persist key outputs (parquet for speed) ----
+    if isinstance(result, dict) and "data" in result:
+        df_out = result["data"]
+        if isinstance(df_out, pd.DataFrame):
+            df_out.to_parquet(out_dir / "daily_en.parquet", index=False)
+    if isinstance(result, dict) and "regime_major" in result:
+        rm = result["regime_major"]
+        if isinstance(rm, pd.DataFrame):
+            rm.to_parquet(out_dir / "daily_regimes.parquet", index=False)
+
+    # ---- 4) Minimal fallback if core returned primitive ----
+    if not isinstance(result, dict):
+        result = {"data": df, "rows": len(df), "out_dir": str(out_dir)}
+
+    # ---- 5) Return result summary ----
+    return {
+        "rows": len(result.get("data", df)),
+        "out_dir": str(out_dir),
+        "keys": list(result.keys()),
+    }
+
+
+if __name__ == "__main__":
+    raise SystemExit("Use CLI entry points or import run_btc_pipeline() from code.")
diff --git a/src/ta_lab2/regimes/segments.py b/src/ta_lab2/regimes/segments.py
new file mode 100644
index 0000000..e028f5f
--- /dev/null
+++ b/src/ta_lab2/regimes/segments.py
@@ -0,0 +1,12 @@
+# src/ta_lab2/regimes/segments.py
+"""
+Shim to preserve legacy imports:
+    from ta_lab2.regimes.segments import build_flip_segments
+
+The actual implementation lives in `ta_lab2.features.segments`.
+"""
+
+from __future__ import annotations
+from ..features.segments import build_flip_segments
+
+__all__ = ["build_flip_segments"]
diff --git a/src/ta_lab2/viz/all_plots.py b/src/ta_lab2/viz/all_plots.py
new file mode 100644
index 0000000..667df9a
--- /dev/null
+++ b/src/ta_lab2/viz/all_plots.py
@@ -0,0 +1,195 @@
+from __future__ import annotations
+import pandas as pd
+import numpy as np
+import matplotlib.pyplot as plt
+
+# --- small utility: choose a time column if present ---
+def _pick_time_index(d: pd.DataFrame) -> pd.Index:
+    for c in ("timestamp", "timeclose", "date", "timeopen"):
+        if c in d.columns:
+            return pd.to_datetime(d[c], errors="coerce")
+    return d.index
+
+# --- Price + EMAs (+ optional slopes & flips), newest bar on the right ---
+def plot_ema_with_trend(
+    df: pd.DataFrame,
+    price_col: str = "close",
+    ema_cols=None,
+    trend_col: str = "trend_state",
+    *,
+    include_slopes: bool = True,
+    include_flips: bool = True,
+    n: int = 1000
+):
+    d = df.tail(n).copy()
+    # If caller didnâ€™t pass explicit EMA cols, auto-detect like <base>_ema_<p>
+    if ema_cols is None:
+        ema_cols = [c for c in d.columns if c.lower().startswith(("open_ema_","high_ema_","low_ema_","close_ema_"))]
+        if not ema_cols:  # fall back to any column starting with "ema_"
+            ema_cols = [c for c in d.columns if c.lower().startswith("ema_")]
+
+    x = np.arange(len(d))  # newest-on-top visual: invert x later
+    t = _pick_time_index(d)
+
+    fig, ax = plt.subplots(figsize=(12, 6))
+    ax.plot(x, d[price_col].to_numpy(), lw=1.3, label=price_col)
+
+    # left axis: EMAs
+    for c in ema_cols:
+        if c in d:
+            ax.plot(x, d[c].to_numpy(), lw=1.0, label=c)
+
+    ax2 = None
+    if include_slopes:
+        # try to find slope columns that match attached helpers: *_d1_bps / *_d1_norm
+        slope_cols = [c for c in d.columns if c.endswith("_d1_bps") or c.endswith("_d1_norm")]
+        if slope_cols:
+            ax2 = ax.twinx()
+            for sc in slope_cols:
+                ax2.plot(x, d[sc].to_numpy(), lw=0.8, alpha=0.8, label=sc)
+            ax2.axhline(0, ls="--", lw=1, alpha=0.8)
+
+            # match attached â€œsensible y-lims from all drawn slope seriesâ€
+            right_vals = np.concatenate([d[c].to_numpy()[~np.isnan(d[c].to_numpy())] for c in slope_cols if c in d])
+            if right_vals.size:
+                qlo, qhi = np.percentile(right_vals, [1, 99])
+                span = qhi - qlo
+                pad = (span * 0.25) if np.isfinite(span) and span > 0 else 10
+                ax2.set_ylim(qlo - pad, qhi + pad)
+
+    # optional flip markers (columns named like <base>_ema_<p>_flip), as in your attached utils
+    if include_flips:
+        flip_cols = [c for c in d.columns if c.endswith("_ema_21_flip") or c.endswith("_flip")]
+        # de-dup to avoid plotting tons of labels
+        plotted = False
+        for fc in flip_cols:
+            if fc in d:
+                idx = np.where(d[fc].to_numpy())[0]
+                if idx.size:
+                    # mark flips on the shortest EMA series available for better alignment
+                    base_for_mark = ema_cols[0] if ema_cols else price_col
+                    ax.scatter(idx, d[base_for_mark].to_numpy()[idx], c="k", marker="x", s=40,
+                               label=("flip" if not plotted else None))
+                    plotted = True
+
+    # optional trend track (your custom column)
+    if trend_col in d.columns:
+        ax3 = ax.twinx()
+        ax3.spines.right.set_position(("axes", 1.08))
+        ax3.plot(x, d[trend_col].to_numpy(), lw=0.8, alpha=0.25)
+        ax3.set_yticks([-1, 0, 1])
+        ax3.set_ylabel("trend")
+
+    # newest bar on the RIGHT to match your figures
+    ax.invert_xaxis()
+    ax.set_xticks(np.linspace(0, len(d)-1, 6, dtype=int))
+    ax.set_xticklabels(pd.to_datetime(t).astype("datetime64[ns]").to_series().iloc[ax.get_xticks().astype(int)].dt.date.astype(str), rotation=0)
+
+    ax.set_title("Price + EMAs + Slopes/Flips (newest on right)")
+    ax.set_xlabel("bars")
+    ax.legend(loc="upper left")
+    if include_slopes and ax2:
+        ax2.legend(loc="upper right")
+    plt.tight_layout()
+    return ax
+
+# --- Consolidated EMAs view (mirrors daf.plot_consolidated_emas) ---
+def plot_consolidated_emas_like(
+    df: pd.DataFrame,
+    base_col: str = "close",
+    periods=(21, 50, 100, 200),
+    *,
+    include_slopes: bool = True,
+    include_flips: bool = True,
+    n: int = 1000
+):
+    d = df.tail(n).copy()
+    x = np.arange(len(d))
+    t = _pick_time_index(d)
+
+    fig, ax = plt.subplots(figsize=(12, 6))
+
+    # all EMAs for this base on left axis
+    for p in periods:
+        ema = f"{base_col}_ema_{p}"
+        if ema not in d:
+            continue
+        ax.plot(x, d[ema].to_numpy(), lw=1.2, label=ema)
+
+    ax.invert_xaxis()
+    ax.set_title(f"{base_col.upper()} EMAs {', '.join(map(str, periods))}")
+    ax.set_xlabel("bars (newest on right)")
+    ax.legend(loc="upper left")
+
+    if include_slopes:
+        ax2 = ax.twinx()
+        right_series = []
+        for p in periods:
+            bps = f"{base_col}_ema_{p}_d1_bps"
+            pct = f"{base_col}_ema_{p}_d1_norm"
+            if bps in d:
+                ax2.plot(x, d[bps].to_numpy(), alpha=0.5, lw=0.9, label=f"slope bps (p={p})")
+                right_series.append(d[bps].to_numpy())
+            if pct in d:
+                ax2.plot(x, d[pct].to_numpy(), alpha=0.5, lw=0.9, label=f"slope % (p={p})")
+                right_series.append(d[pct].to_numpy())
+
+            if include_flips:
+                flip = f"{base_col}_ema_{p}_flip"
+                if flip in d:
+                    idx = np.where(d[flip].to_numpy())[0]
+                    if idx.size:
+                        ax.scatter(idx, d[f"{base_col}_ema_{p}"].to_numpy()[idx],
+                                   c="k", marker="x", s=40, label=f"flip {p}")
+        ax2.axhline(0, ls="--", lw=1, alpha=0.8)
+        ax2.legend(loc="upper right")
+
+        if right_series:
+            rs = np.concatenate([r[~np.isnan(r)] for r in right_series if r.size])
+            if rs.size:
+                qlo, qhi = np.percentile(rs, [1, 99])
+                span = qhi - qlo
+                pad = (span * 0.25) if np.isfinite(span) and span > 0 else 10
+                ax2.set_ylim(qlo - pad, qhi + pad)
+
+    plt.tight_layout()
+    return ax
+
+# --- Realized volatility panel: Parkinson, GK, RS (+ optional stdev of log returns) ---
+def plot_realized_vol(
+    df: pd.DataFrame,
+    *,
+    windows=(30, 60, 90),
+    include_logret_stdev: bool = True,
+    n: int = 1000
+):
+    d = df.tail(n).copy()
+    x = np.arange(len(d))
+    t = _pick_time_index(d)
+
+    fig, ax = plt.subplots(figsize=(12, 4))
+    plotted = False
+
+    # match generated names: parkinson_vol_<w>, gk_vol_<w> (or gk_vol_<w>), rs_vol_<w>
+    for w in windows:
+        for name in (f"parkinson_vol_{w}", f"gk_vol_{w}", f"rs_vol_{w}"):
+            if name in d.columns:
+                ax.plot(x, d[name].to_numpy(), lw=1.0, label=name)
+                plotted = True
+
+    # optional: rolling stdev of log returns (add_logret_stdev_vol)
+    if include_logret_stdev:
+        stdev_cols = [c for c in d.columns if c.endswith(tuple(f"_vol_stdev_{w}" for w in windows))]
+        for c in stdev_cols:
+            ax.plot(x, d[c].to_numpy(), lw=0.9, alpha=0.8, label=c)
+
+    if not plotted and not [c for c in d.columns if c.endswith("_vol_stdev_")]:
+        print("[plot skipped] No realized-vol columns found.")
+        return ax
+
+    ax.invert_xaxis()
+    ax.set_title("Realized Volatility (rolling)")
+    ax.set_xlabel("bars (newest on right)")
+    ax.legend(loc="upper left", ncol=2)
+    plt.tight_layout()
+    return ax
diff --git a/structure.json b/structure.json
new file mode 100644
index 0000000..9c137bb
--- /dev/null
+++ b/structure.json
@@ -0,0 +1,4347 @@
+{
+  "name": "ta_lab2",
+  "type": "dir",
+  "path": "",
+  "size": 0,
+  "mtime": "2025-11-01T17:51:49+00:00",
+  "children": [
+    {
+      "name": "-p",
+      "type": "dir",
+      "path": "-p",
+      "size": 0,
+      "mtime": "2025-11-01T15:22:11+00:00",
+      "children": []
+    },
+    {
+      "name": ".benchmarks",
+      "type": "dir",
+      "path": ".benchmarks",
+      "size": 0,
+      "mtime": "2025-11-01T15:47:33+00:00",
+      "children": []
+    },
+    {
+      "name": ".git",
+      "type": "dir",
+      "path": ".git",
+      "size": 0,
+      "mtime": "2025-11-01T18:19:55+00:00",
+      "children": [
+        {
+          "name": "COMMIT_EDITMSG",
+          "type": "file",
+          "path": ".git/COMMIT_EDITMSG",
+          "size": 119,
+          "mtime": "2025-11-01T18:01:51+00:00",
+          "children": null
+        },
+        {
+          "name": "HEAD",
+          "type": "file",
+          "path": ".git/HEAD",
+          "size": 21,
+          "mtime": "2025-11-01T04:07:08+00:00",
+          "children": null
+        },
+        {
+          "name": "config",
+          "type": "file",
+          "path": ".git/config",
+          "size": 299,
+          "mtime": "2025-11-01T04:08:09+00:00",
+          "children": null
+        },
+        {
+          "name": "description",
+          "type": "file",
+          "path": ".git/description",
+          "size": 73,
+          "mtime": "2025-11-01T03:59:19+00:00",
+          "children": null
+        },
+        {
+          "name": "hooks",
+          "type": "dir",
+          "path": ".git/hooks",
+          "size": 0,
+          "mtime": "2025-11-01T03:59:19+00:00",
+          "children": [
+            {
+              "name": "applypatch-msg.sample",
+              "type": "file",
+              "path": ".git/hooks/applypatch-msg.sample",
+              "size": 478,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "commit-msg.sample",
+              "type": "file",
+              "path": ".git/hooks/commit-msg.sample",
+              "size": 896,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "fsmonitor-watchman.sample",
+              "type": "file",
+              "path": ".git/hooks/fsmonitor-watchman.sample",
+              "size": 4726,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "post-update.sample",
+              "type": "file",
+              "path": ".git/hooks/post-update.sample",
+              "size": 189,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "pre-applypatch.sample",
+              "type": "file",
+              "path": ".git/hooks/pre-applypatch.sample",
+              "size": 424,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "pre-commit.sample",
+              "type": "file",
+              "path": ".git/hooks/pre-commit.sample",
+              "size": 1649,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "pre-merge-commit.sample",
+              "type": "file",
+              "path": ".git/hooks/pre-merge-commit.sample",
+              "size": 416,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "pre-push.sample",
+              "type": "file",
+              "path": ".git/hooks/pre-push.sample",
+              "size": 1374,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "pre-rebase.sample",
+              "type": "file",
+              "path": ".git/hooks/pre-rebase.sample",
+              "size": 4898,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "pre-receive.sample",
+              "type": "file",
+              "path": ".git/hooks/pre-receive.sample",
+              "size": 544,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "prepare-commit-msg.sample",
+              "type": "file",
+              "path": ".git/hooks/prepare-commit-msg.sample",
+              "size": 1492,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "push-to-checkout.sample",
+              "type": "file",
+              "path": ".git/hooks/push-to-checkout.sample",
+              "size": 2783,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "sendemail-validate.sample",
+              "type": "file",
+              "path": ".git/hooks/sendemail-validate.sample",
+              "size": 2308,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            },
+            {
+              "name": "update.sample",
+              "type": "file",
+              "path": ".git/hooks/update.sample",
+              "size": 3650,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            }
+          ]
+        },
+        {
+          "name": "index",
+          "type": "file",
+          "path": ".git/index",
+          "size": 4556,
+          "mtime": "2025-11-01T18:01:51+00:00",
+          "children": null
+        },
+        {
+          "name": "info",
+          "type": "dir",
+          "path": ".git/info",
+          "size": 0,
+          "mtime": "2025-11-01T03:59:19+00:00",
+          "children": [
+            {
+              "name": "exclude",
+              "type": "file",
+              "path": ".git/info/exclude",
+              "size": 240,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": null
+            }
+          ]
+        },
+        {
+          "name": "logs",
+          "type": "dir",
+          "path": ".git/logs",
+          "size": 0,
+          "mtime": "2025-11-01T04:06:54+00:00",
+          "children": [
+            {
+              "name": "HEAD",
+              "type": "file",
+              "path": ".git/logs/HEAD",
+              "size": 5617,
+              "mtime": "2025-11-01T18:01:51+00:00",
+              "children": null
+            },
+            {
+              "name": "refs",
+              "type": "dir",
+              "path": ".git/logs/refs",
+              "size": 0,
+              "mtime": "2025-11-01T04:08:09+00:00",
+              "children": [
+                {
+                  "name": "heads",
+                  "type": "dir",
+                  "path": ".git/logs/refs/heads",
+                  "size": 0,
+                  "mtime": "2025-11-01T04:07:08+00:00",
+                  "children": [
+                    {
+                      "name": "main",
+                      "type": "file",
+                      "path": ".git/logs/refs/heads/main",
+                      "size": 5435,
+                      "mtime": "2025-11-01T18:01:51+00:00",
+                      "children": null
+                    }
+                  ]
+                },
+                {
+                  "name": "remotes",
+                  "type": "dir",
+                  "path": ".git/logs/refs/remotes",
+                  "size": 0,
+                  "mtime": "2025-11-01T04:08:09+00:00",
+                  "children": [
+                    {
+                      "name": "origin",
+                      "type": "dir",
+                      "path": ".git/logs/refs/remotes/origin",
+                      "size": 0,
+                      "mtime": "2025-11-01T04:08:09+00:00",
+                      "children": [
+                        {
+                          "name": "main",
+                          "type": "file",
+                          "path": ".git/logs/refs/remotes/origin/main",
+                          "size": 3504,
+                          "mtime": "2025-11-01T18:02:00+00:00",
+                          "children": null
+                        }
+                      ]
+                    }
+                  ]
+                }
+              ]
+            }
+          ]
+        },
+        {
+          "name": "objects",
+          "type": "dir",
+          "path": ".git/objects",
+          "size": 0,
+          "mtime": "2025-11-01T18:01:51+00:00",
+          "children": [
+            {
+              "name": "05",
+              "type": "dir",
+              "path": ".git/objects/05",
+              "size": 0,
+              "mtime": "2025-11-01T17:53:06+00:00",
+              "children": [
+                {
+                  "name": "d0b2aaab358b4353aebaa7d7fb3a812899de52",
+                  "type": "file",
+                  "path": ".git/objects/05/d0b2aaab358b4353aebaa7d7fb3a812899de52",
+                  "size": 214,
+                  "mtime": "2025-11-01T17:53:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "06",
+              "type": "dir",
+              "path": ".git/objects/06",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:49+00:00",
+              "children": [
+                {
+                  "name": "81e7542e81e9a4cc916dea946b791c1911a1a4",
+                  "type": "file",
+                  "path": ".git/objects/06/81e7542e81e9a4cc916dea946b791c1911a1a4",
+                  "size": 50,
+                  "mtime": "2025-11-01T16:38:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "0c",
+              "type": "dir",
+              "path": ".git/objects/0c",
+              "size": 0,
+              "mtime": "2025-11-01T17:19:39+00:00",
+              "children": [
+                {
+                  "name": "1316d607d63503b3aba0d249e5fa1fe8605a63",
+                  "type": "file",
+                  "path": ".git/objects/0c/1316d607d63503b3aba0d249e5fa1fe8605a63",
+                  "size": 202,
+                  "mtime": "2025-11-01T17:19:39+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "0e",
+              "type": "dir",
+              "path": ".git/objects/0e",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:48+00:00",
+              "children": [
+                {
+                  "name": "500fad8a4cf5ada11c0b5de5dbd2e72c3390e8",
+                  "type": "file",
+                  "path": ".git/objects/0e/500fad8a4cf5ada11c0b5de5dbd2e72c3390e8",
+                  "size": 131,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "0f",
+              "type": "dir",
+              "path": ".git/objects/0f",
+              "size": 0,
+              "mtime": "2025-11-01T17:29:55+00:00",
+              "children": [
+                {
+                  "name": "79c7ecbc5c389b42795124d4188614f146e490",
+                  "type": "file",
+                  "path": ".git/objects/0f/79c7ecbc5c389b42795124d4188614f146e490",
+                  "size": 474,
+                  "mtime": "2025-11-01T17:29:55+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "13",
+              "type": "dir",
+              "path": ".git/objects/13",
+              "size": 0,
+              "mtime": "2025-11-01T17:22:38+00:00",
+              "children": [
+                {
+                  "name": "52163bb6d1986d22598896bfc6fc5131713b4b",
+                  "type": "file",
+                  "path": ".git/objects/13/52163bb6d1986d22598896bfc6fc5131713b4b",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:22:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "72ae02857d42ddc57407319c53e2e59aee1586",
+                  "type": "file",
+                  "path": ".git/objects/13/72ae02857d42ddc57407319c53e2e59aee1586",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:16:25+00:00",
+                  "children": null
+                },
+                {
+                  "name": "fc3735e1af78b092c3b8bc540daf2478d76322",
+                  "type": "file",
+                  "path": ".git/objects/13/fc3735e1af78b092c3b8bc540daf2478d76322",
+                  "size": 218,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "16",
+              "type": "dir",
+              "path": ".git/objects/16",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:49+00:00",
+              "children": [
+                {
+                  "name": "541e78a2d06de7a2b7e83a7d8d2a07aa8476e1",
+                  "type": "file",
+                  "path": ".git/objects/16/541e78a2d06de7a2b7e83a7d8d2a07aa8476e1",
+                  "size": 309,
+                  "mtime": "2025-11-01T16:38:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "f47b9fa519e538051ccc548b37f45928086bf9",
+                  "type": "file",
+                  "path": ".git/objects/16/f47b9fa519e538051ccc548b37f45928086bf9",
+                  "size": 367,
+                  "mtime": "2025-11-01T16:10:27+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "18",
+              "type": "dir",
+              "path": ".git/objects/18",
+              "size": 0,
+              "mtime": "2025-11-01T16:54:14+00:00",
+              "children": [
+                {
+                  "name": "35cd19654eb3a841b3e52dda6de8770fc4088f",
+                  "type": "file",
+                  "path": ".git/objects/18/35cd19654eb3a841b3e52dda6de8770fc4088f",
+                  "size": 49,
+                  "mtime": "2025-11-01T16:54:14+00:00",
+                  "children": null
+                },
+                {
+                  "name": "ce4c37198cc80657b40e942fa38e12c885a722",
+                  "type": "file",
+                  "path": ".git/objects/18/ce4c37198cc80657b40e942fa38e12c885a722",
+                  "size": 49,
+                  "mtime": "2025-11-01T16:10:27+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "1a",
+              "type": "dir",
+              "path": ".git/objects/1a",
+              "size": 0,
+              "mtime": "2025-11-01T17:27:55+00:00",
+              "children": [
+                {
+                  "name": "2e6f1c13169e8d58b15b1fe6c9c45485f3598f",
+                  "type": "file",
+                  "path": ".git/objects/1a/2e6f1c13169e8d58b15b1fe6c9c45485f3598f",
+                  "size": 54,
+                  "mtime": "2025-11-01T17:11:21+00:00",
+                  "children": null
+                },
+                {
+                  "name": "54c1bab42c6dde25495b0cb7e8311b49496312",
+                  "type": "file",
+                  "path": ".git/objects/1a/54c1bab42c6dde25495b0cb7e8311b49496312",
+                  "size": 217,
+                  "mtime": "2025-11-01T17:27:55+00:00",
+                  "children": null
+                },
+                {
+                  "name": "6b0bd56cb7014b42ffe44edcaa5cd474417c88",
+                  "type": "file",
+                  "path": ".git/objects/1a/6b0bd56cb7014b42ffe44edcaa5cd474417c88",
+                  "size": 138,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "1b",
+              "type": "dir",
+              "path": ".git/objects/1b",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:33+00:00",
+              "children": [
+                {
+                  "name": "001568c4e27bbf53aac51afb2602cce15803d1",
+                  "type": "file",
+                  "path": ".git/objects/1b/001568c4e27bbf53aac51afb2602cce15803d1",
+                  "size": 57,
+                  "mtime": "2025-11-01T15:12:33+00:00",
+                  "children": null
+                },
+                {
+                  "name": "8350c38a04f27e53ca47dcec80cf4f0dd985ef",
+                  "type": "file",
+                  "path": ".git/objects/1b/8350c38a04f27e53ca47dcec80cf4f0dd985ef",
+                  "size": 563,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "dc623f9d098267bb8bbddf0e58992f8cad904d",
+                  "type": "file",
+                  "path": ".git/objects/1b/dc623f9d098267bb8bbddf0e58992f8cad904d",
+                  "size": 92,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "1d",
+              "type": "dir",
+              "path": ".git/objects/1d",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "16d546d32e5cc0e850de211407674788e0b71f",
+                  "type": "file",
+                  "path": ".git/objects/1d/16d546d32e5cc0e850de211407674788e0b71f",
+                  "size": 454,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "1e",
+              "type": "dir",
+              "path": ".git/objects/1e",
+              "size": 0,
+              "mtime": "2025-11-01T17:29:55+00:00",
+              "children": [
+                {
+                  "name": "0fa8d1f70827c4643e401661ec775f36bfa86f",
+                  "type": "file",
+                  "path": ".git/objects/1e/0fa8d1f70827c4643e401661ec775f36bfa86f",
+                  "size": 298,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                },
+                {
+                  "name": "85f24493741e6d0e0d34c828a571cca5bfa6ea",
+                  "type": "file",
+                  "path": ".git/objects/1e/85f24493741e6d0e0d34c828a571cca5bfa6ea",
+                  "size": 211,
+                  "mtime": "2025-11-01T17:29:55+00:00",
+                  "children": null
+                },
+                {
+                  "name": "e7cbeb176f684d0f6addc66930a389c5488c13",
+                  "type": "file",
+                  "path": ".git/objects/1e/e7cbeb176f684d0f6addc66930a389c5488c13",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:29:55+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "1f",
+              "type": "dir",
+              "path": ".git/objects/1f",
+              "size": 0,
+              "mtime": "2025-11-01T17:27:55+00:00",
+              "children": [
+                {
+                  "name": "59bce670ef04f1ebf3c8a4cbc62b6abea013a8",
+                  "type": "file",
+                  "path": ".git/objects/1f/59bce670ef04f1ebf3c8a4cbc62b6abea013a8",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:27:55+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "22",
+              "type": "dir",
+              "path": ".git/objects/22",
+              "size": 0,
+              "mtime": "2025-11-01T17:19:31+00:00",
+              "children": [
+                {
+                  "name": "56d90979ceb0cc24508ab64e7a5f64963b9b16",
+                  "type": "file",
+                  "path": ".git/objects/22/56d90979ceb0cc24508ab64e7a5f64963b9b16",
+                  "size": 1904,
+                  "mtime": "2025-11-01T17:19:31+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "23",
+              "type": "dir",
+              "path": ".git/objects/23",
+              "size": 0,
+              "mtime": "2025-11-01T15:52:09+00:00",
+              "children": [
+                {
+                  "name": "bed1dae10df9a22ac45551ec9ab8d9ab9a6109",
+                  "type": "file",
+                  "path": ".git/objects/23/bed1dae10df9a22ac45551ec9ab8d9ab9a6109",
+                  "size": 50,
+                  "mtime": "2025-11-01T15:52:09+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "24",
+              "type": "dir",
+              "path": ".git/objects/24",
+              "size": 0,
+              "mtime": "2025-11-01T17:29:47+00:00",
+              "children": [
+                {
+                  "name": "85775d0d5285146f2dd146c51a4c629c46a21c",
+                  "type": "file",
+                  "path": ".git/objects/24/85775d0d5285146f2dd146c51a4c629c46a21c",
+                  "size": 1690,
+                  "mtime": "2025-11-01T17:29:47+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "26",
+              "type": "dir",
+              "path": ".git/objects/26",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "e21821ad168739a741bbfba0b11c685ae14e5c",
+                  "type": "file",
+                  "path": ".git/objects/26/e21821ad168739a741bbfba0b11c685ae14e5c",
+                  "size": 2698,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "28",
+              "type": "dir",
+              "path": ".git/objects/28",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:22+00:00",
+              "children": [
+                {
+                  "name": "766370211a2741d6d268162620aefa30f5f88e",
+                  "type": "file",
+                  "path": ".git/objects/28/766370211a2741d6d268162620aefa30f5f88e",
+                  "size": 1905,
+                  "mtime": "2025-11-01T15:12:22+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "29",
+              "type": "dir",
+              "path": ".git/objects/29",
+              "size": 0,
+              "mtime": "2025-11-01T17:22:32+00:00",
+              "children": [
+                {
+                  "name": "9cf6db80dbe60855c8590b03df975c10998b61",
+                  "type": "file",
+                  "path": ".git/objects/29/9cf6db80dbe60855c8590b03df975c10998b61",
+                  "size": 1690,
+                  "mtime": "2025-11-01T17:22:32+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "2a",
+              "type": "dir",
+              "path": ".git/objects/2a",
+              "size": 0,
+              "mtime": "2025-11-01T17:05:18+00:00",
+              "children": [
+                {
+                  "name": "600c6f9be97c58341a76a6364bd9d2777413ad",
+                  "type": "file",
+                  "path": ".git/objects/2a/600c6f9be97c58341a76a6364bd9d2777413ad",
+                  "size": 446,
+                  "mtime": "2025-11-01T17:05:18+00:00",
+                  "children": null
+                },
+                {
+                  "name": "aa5a0762b80c23366277e1165700ded2bbfbc4",
+                  "type": "file",
+                  "path": ".git/objects/2a/aa5a0762b80c23366277e1165700ded2bbfbc4",
+                  "size": 309,
+                  "mtime": "2025-11-01T14:51:56+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "2d",
+              "type": "dir",
+              "path": ".git/objects/2d",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "995600390e9adbc3608aa054cb17f81deb930c",
+                  "type": "file",
+                  "path": ".git/objects/2d/995600390e9adbc3608aa054cb17f81deb930c",
+                  "size": 1612,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "30",
+              "type": "dir",
+              "path": ".git/objects/30",
+              "size": 0,
+              "mtime": "2025-11-01T16:54:15+00:00",
+              "children": [
+                {
+                  "name": "003833691449fcf75559cd021e3d90608a462e",
+                  "type": "file",
+                  "path": ".git/objects/30/003833691449fcf75559cd021e3d90608a462e",
+                  "size": 446,
+                  "mtime": "2025-11-01T16:54:15+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "31",
+              "type": "dir",
+              "path": ".git/objects/31",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "31e8dae69807372eb523a15889905a913addd0",
+                  "type": "file",
+                  "path": ".git/objects/31/31e8dae69807372eb523a15889905a913addd0",
+                  "size": 490,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "32",
+              "type": "dir",
+              "path": ".git/objects/32",
+              "size": 0,
+              "mtime": "2025-11-01T16:10:27+00:00",
+              "children": [
+                {
+                  "name": "a3b2e7acf4d177cd48486ed6fa20d00cf07eb0",
+                  "type": "file",
+                  "path": ".git/objects/32/a3b2e7acf4d177cd48486ed6fa20d00cf07eb0",
+                  "size": 310,
+                  "mtime": "2025-11-01T16:10:27+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "33",
+              "type": "dir",
+              "path": ".git/objects/33",
+              "size": 0,
+              "mtime": "2025-11-01T17:11:21+00:00",
+              "children": [
+                {
+                  "name": "3e9afa96421babc6504bb1ab911759b1164d26",
+                  "type": "file",
+                  "path": ".git/objects/33/3e9afa96421babc6504bb1ab911759b1164d26",
+                  "size": 474,
+                  "mtime": "2025-11-01T17:11:21+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "35",
+              "type": "dir",
+              "path": ".git/objects/35",
+              "size": 0,
+              "mtime": "2025-11-01T17:53:06+00:00",
+              "children": [
+                {
+                  "name": "0c79453fa60fb9ac0509ad899347943de7e002",
+                  "type": "file",
+                  "path": ".git/objects/35/0c79453fa60fb9ac0509ad899347943de7e002",
+                  "size": 1843,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "368cbc614e36b272bd8168a2a0ec6495b874ea",
+                  "type": "file",
+                  "path": ".git/objects/35/368cbc614e36b272bd8168a2a0ec6495b874ea",
+                  "size": 56,
+                  "mtime": "2025-11-01T17:53:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "3e615c159c03677f36fbe48a9d094fa92caeba",
+                  "type": "file",
+                  "path": ".git/objects/35/3e615c159c03677f36fbe48a9d094fa92caeba",
+                  "size": 50,
+                  "mtime": "2025-11-01T17:16:25+00:00",
+                  "children": null
+                },
+                {
+                  "name": "b4b137fbfda80f1e5a2ecb938a92b27783d526",
+                  "type": "file",
+                  "path": ".git/objects/35/b4b137fbfda80f1e5a2ecb938a92b27783d526",
+                  "size": 247,
+                  "mtime": "2025-11-01T14:06:32+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "36",
+              "type": "dir",
+              "path": ".git/objects/36",
+              "size": 0,
+              "mtime": "2025-11-01T16:13:36+00:00",
+              "children": [
+                {
+                  "name": "7a48ede7399fc23ddf15b14af11c297ed37ebc",
+                  "type": "file",
+                  "path": ".git/objects/36/7a48ede7399fc23ddf15b14af11c297ed37ebc",
+                  "size": 196,
+                  "mtime": "2025-11-01T16:13:36+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "38",
+              "type": "dir",
+              "path": ".git/objects/38",
+              "size": 0,
+              "mtime": "2025-11-01T17:35:53+00:00",
+              "children": [
+                {
+                  "name": "5262348f40ba23f16dceefd138751a3ea22d75",
+                  "type": "file",
+                  "path": ".git/objects/38/5262348f40ba23f16dceefd138751a3ea22d75",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:35:53+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "39",
+              "type": "dir",
+              "path": ".git/objects/39",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:48+00:00",
+              "children": [
+                {
+                  "name": "40f82c7b951e0cf7d207ea318cef1be7523b9b",
+                  "type": "file",
+                  "path": ".git/objects/39/40f82c7b951e0cf7d207ea318cef1be7523b9b",
+                  "size": 368,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "3a",
+              "type": "dir",
+              "path": ".git/objects/3a",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "b7b119791c022a861786f00bd042149303a186",
+                  "type": "file",
+                  "path": ".git/objects/3a/b7b119791c022a861786f00bd042149303a186",
+                  "size": 428,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "3e",
+              "type": "dir",
+              "path": ".git/objects/3e",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:48+00:00",
+              "children": [
+                {
+                  "name": "f84ade56705bae952cf69f489d79ce87a41b6b",
+                  "type": "file",
+                  "path": ".git/objects/3e/f84ade56705bae952cf69f489d79ce87a41b6b",
+                  "size": 49,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "3f",
+              "type": "dir",
+              "path": ".git/objects/3f",
+              "size": 0,
+              "mtime": "2025-11-01T14:25:23+00:00",
+              "children": [
+                {
+                  "name": "dde6025fd70aa7fecfd96684134955cd5a501a",
+                  "type": "file",
+                  "path": ".git/objects/3f/dde6025fd70aa7fecfd96684134955cd5a501a",
+                  "size": 178,
+                  "mtime": "2025-11-01T14:25:23+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "40",
+              "type": "dir",
+              "path": ".git/objects/40",
+              "size": 0,
+              "mtime": "2025-11-01T14:06:32+00:00",
+              "children": [
+                {
+                  "name": "30c6d8d99a074041a308e8c7d2bd094521b08d",
+                  "type": "file",
+                  "path": ".git/objects/40/30c6d8d99a074041a308e8c7d2bd094521b08d",
+                  "size": 57,
+                  "mtime": "2025-11-01T14:06:32+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "41",
+              "type": "dir",
+              "path": ".git/objects/41",
+              "size": 0,
+              "mtime": "2025-11-01T14:06:32+00:00",
+              "children": [
+                {
+                  "name": "2dfa42783dcb50b3088c539a83b3400586ac76",
+                  "type": "file",
+                  "path": ".git/objects/41/2dfa42783dcb50b3088c539a83b3400586ac76",
+                  "size": 49,
+                  "mtime": "2025-11-01T14:06:32+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "44",
+              "type": "dir",
+              "path": ".git/objects/44",
+              "size": 0,
+              "mtime": "2025-11-01T16:21:08+00:00",
+              "children": [
+                {
+                  "name": "d6b795dd3fa358ce30f09a4f4ad00b8783fc7f",
+                  "type": "file",
+                  "path": ".git/objects/44/d6b795dd3fa358ce30f09a4f4ad00b8783fc7f",
+                  "size": 192,
+                  "mtime": "2025-11-01T16:21:08+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "46",
+              "type": "dir",
+              "path": ".git/objects/46",
+              "size": 0,
+              "mtime": "2025-11-01T14:25:17+00:00",
+              "children": [
+                {
+                  "name": "6df71c83b8a7e33fc928e10a3b357954ff91b3",
+                  "type": "file",
+                  "path": ".git/objects/46/6df71c83b8a7e33fc928e10a3b357954ff91b3",
+                  "size": 35,
+                  "mtime": "2025-11-01T14:25:17+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "47",
+              "type": "dir",
+              "path": ".git/objects/47",
+              "size": 0,
+              "mtime": "2025-11-01T14:25:17+00:00",
+              "children": [
+                {
+                  "name": "4c5c5fdf80f028e32a19f1b5c1539becaa9a6f",
+                  "type": "file",
+                  "path": ".git/objects/47/4c5c5fdf80f028e32a19f1b5c1539becaa9a6f",
+                  "size": 241,
+                  "mtime": "2025-11-01T14:25:17+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "49",
+              "type": "dir",
+              "path": ".git/objects/49",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:33+00:00",
+              "children": [
+                {
+                  "name": "1984b0ab665918d9dbe14a1459e79aeef62b84",
+                  "type": "file",
+                  "path": ".git/objects/49/1984b0ab665918d9dbe14a1459e79aeef62b84",
+                  "size": 49,
+                  "mtime": "2025-11-01T15:12:33+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "4d",
+              "type": "dir",
+              "path": ".git/objects/4d",
+              "size": 0,
+              "mtime": "2025-11-01T17:19:39+00:00",
+              "children": [
+                {
+                  "name": "93773f9e75598f1367e33af3cd041ef3c365aa",
+                  "type": "file",
+                  "path": ".git/objects/4d/93773f9e75598f1367e33af3cd041ef3c365aa",
+                  "size": 473,
+                  "mtime": "2025-11-01T17:19:39+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a5e136d5ed61ddb33238828c4753b13c426b5f",
+                  "type": "file",
+                  "path": ".git/objects/4d/a5e136d5ed61ddb33238828c4753b13c426b5f",
+                  "size": 243,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "4e",
+              "type": "dir",
+              "path": ".git/objects/4e",
+              "size": 0,
+              "mtime": "2025-11-01T16:49:36+00:00",
+              "children": [
+                {
+                  "name": "142f23a10836fcbca3d51bf2f55002160b3481",
+                  "type": "file",
+                  "path": ".git/objects/4e/142f23a10836fcbca3d51bf2f55002160b3481",
+                  "size": 2103,
+                  "mtime": "2025-11-01T16:49:36+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "4f",
+              "type": "dir",
+              "path": ".git/objects/4f",
+              "size": 0,
+              "mtime": "2025-11-01T17:35:53+00:00",
+              "children": [
+                {
+                  "name": "df728e8a369bc94d786c1d9ba64212d24a2f16",
+                  "type": "file",
+                  "path": ".git/objects/4f/df728e8a369bc94d786c1d9ba64212d24a2f16",
+                  "size": 366,
+                  "mtime": "2025-11-01T17:35:53+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "50",
+              "type": "dir",
+              "path": ".git/objects/50",
+              "size": 0,
+              "mtime": "2025-11-01T16:05:26+00:00",
+              "children": [
+                {
+                  "name": "2af742f5b8ca88005a9447478cca6ec72db352",
+                  "type": "file",
+                  "path": ".git/objects/50/2af742f5b8ca88005a9447478cca6ec72db352",
+                  "size": 139,
+                  "mtime": "2025-11-01T14:25:23+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a0575478c1a5196cd18d3d9de5705add6fa78a",
+                  "type": "file",
+                  "path": ".git/objects/50/a0575478c1a5196cd18d3d9de5705add6fa78a",
+                  "size": 2141,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a615e648856eabe9bca56f81bcf20d0dda8d4c",
+                  "type": "file",
+                  "path": ".git/objects/50/a615e648856eabe9bca56f81bcf20d0dda8d4c",
+                  "size": 446,
+                  "mtime": "2025-11-01T16:05:26+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "51",
+              "type": "dir",
+              "path": ".git/objects/51",
+              "size": 0,
+              "mtime": "2025-11-01T14:51:56+00:00",
+              "children": [
+                {
+                  "name": "6b06b3e114154e82986f2b1f96a6ec29f69260",
+                  "type": "file",
+                  "path": ".git/objects/51/6b06b3e114154e82986f2b1f96a6ec29f69260",
+                  "size": 247,
+                  "mtime": "2025-11-01T14:51:56+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "52",
+              "type": "dir",
+              "path": ".git/objects/52",
+              "size": 0,
+              "mtime": "2025-11-01T16:21:08+00:00",
+              "children": [
+                {
+                  "name": "d7f5409a17b1c7e523eb3f7bd26eacfd172353",
+                  "type": "file",
+                  "path": ".git/objects/52/d7f5409a17b1c7e523eb3f7bd26eacfd172353",
+                  "size": 199,
+                  "mtime": "2025-11-01T16:21:08+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "53",
+              "type": "dir",
+              "path": ".git/objects/53",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "aeb7ecd4abbca0a763c1446f8356cc09877387",
+                  "type": "file",
+                  "path": ".git/objects/53/aeb7ecd4abbca0a763c1446f8356cc09877387",
+                  "size": 151,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "56",
+              "type": "dir",
+              "path": ".git/objects/56",
+              "size": 0,
+              "mtime": "2025-11-01T17:05:11+00:00",
+              "children": [
+                {
+                  "name": "0e7e8e38053e1917770d3624b16063258de50f",
+                  "type": "file",
+                  "path": ".git/objects/56/0e7e8e38053e1917770d3624b16063258de50f",
+                  "size": 2999,
+                  "mtime": "2025-11-01T17:05:11+00:00",
+                  "children": null
+                },
+                {
+                  "name": "c1eca2c3f9090dffeb04f71d92e11e1f60fe20",
+                  "type": "file",
+                  "path": ".git/objects/56/c1eca2c3f9090dffeb04f71d92e11e1f60fe20",
+                  "size": 355,
+                  "mtime": "2025-11-01T14:06:32+00:00",
+                  "children": null
+                },
+                {
+                  "name": "d317c792e73fa9ec993680ce805228db3f7372",
+                  "type": "file",
+                  "path": ".git/objects/56/d317c792e73fa9ec993680ce805228db3f7372",
+                  "size": 190,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "59",
+              "type": "dir",
+              "path": ".git/objects/59",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:51+00:00",
+              "children": [
+                {
+                  "name": "de3287f7078cb10f755cf19a5578a055f6aa09",
+                  "type": "file",
+                  "path": ".git/objects/59/de3287f7078cb10f755cf19a5578a055f6aa09",
+                  "size": 232,
+                  "mtime": "2025-11-01T18:01:51+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "5a",
+              "type": "dir",
+              "path": ".git/objects/5a",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "f57d49cd39ca9910aa37361068428f1a5d7f16",
+                  "type": "file",
+                  "path": ".git/objects/5a/f57d49cd39ca9910aa37361068428f1a5d7f16",
+                  "size": 269,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "5d",
+              "type": "dir",
+              "path": ".git/objects/5d",
+              "size": 0,
+              "mtime": "2025-11-01T17:19:39+00:00",
+              "children": [
+                {
+                  "name": "7147ebce62d603a725a5c737180a79d6a8a784",
+                  "type": "file",
+                  "path": ".git/objects/5d/7147ebce62d603a725a5c737180a79d6a8a784",
+                  "size": 367,
+                  "mtime": "2025-11-01T17:19:39+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "5e",
+              "type": "dir",
+              "path": ".git/objects/5e",
+              "size": 0,
+              "mtime": "2025-11-01T16:05:26+00:00",
+              "children": [
+                {
+                  "name": "20aea0cf7799e5ac209ab51b29cd22d1d13bd0",
+                  "type": "file",
+                  "path": ".git/objects/5e/20aea0cf7799e5ac209ab51b29cd22d1d13bd0",
+                  "size": 201,
+                  "mtime": "2025-11-01T14:25:17+00:00",
+                  "children": null
+                },
+                {
+                  "name": "64820aaf1c00ca3a2c7f290b0fa56caf70a553",
+                  "type": "file",
+                  "path": ".git/objects/5e/64820aaf1c00ca3a2c7f290b0fa56caf70a553",
+                  "size": 367,
+                  "mtime": "2025-11-01T16:05:26+00:00",
+                  "children": null
+                },
+                {
+                  "name": "d16f77d3ab246359b74c4ba3993327b4697a63",
+                  "type": "file",
+                  "path": ".git/objects/5e/d16f77d3ab246359b74c4ba3993327b4697a63",
+                  "size": 194,
+                  "mtime": "2025-11-01T15:52:09+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "5f",
+              "type": "dir",
+              "path": ".git/objects/5f",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:49+00:00",
+              "children": [
+                {
+                  "name": "07b952b2cdfc491257dd90db93603c693714f4",
+                  "type": "file",
+                  "path": ".git/objects/5f/07b952b2cdfc491257dd90db93603c693714f4",
+                  "size": 223,
+                  "mtime": "2025-11-01T16:38:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "60",
+              "type": "dir",
+              "path": ".git/objects/60",
+              "size": 0,
+              "mtime": "2025-11-01T17:53:06+00:00",
+              "children": [
+                {
+                  "name": "08fce86730c3c716003a117a61dcdac6f01b99",
+                  "type": "file",
+                  "path": ".git/objects/60/08fce86730c3c716003a117a61dcdac6f01b99",
+                  "size": 93,
+                  "mtime": "2025-11-01T17:53:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "e10e58f94c66184d6880dbbb50fbb0589245a4",
+                  "type": "file",
+                  "path": ".git/objects/60/e10e58f94c66184d6880dbbb50fbb0589245a4",
+                  "size": 367,
+                  "mtime": "2025-11-01T16:21:08+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "61",
+              "type": "dir",
+              "path": ".git/objects/61",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "85b5ad62ccf1bb527550589c71ad2dd6497ac6",
+                  "type": "file",
+                  "path": ".git/objects/61/85b5ad62ccf1bb527550589c71ad2dd6497ac6",
+                  "size": 3068,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "64",
+              "type": "dir",
+              "path": ".git/objects/64",
+              "size": 0,
+              "mtime": "2025-11-01T14:25:17+00:00",
+              "children": [
+                {
+                  "name": "a2fe2aa524a5ed2121b25c9b07278cd9f69dea",
+                  "type": "file",
+                  "path": ".git/objects/64/a2fe2aa524a5ed2121b25c9b07278cd9f69dea",
+                  "size": 1064,
+                  "mtime": "2025-11-01T14:25:17+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a9858793c04249dd583b6e95d3effad3c78219",
+                  "type": "file",
+                  "path": ".git/objects/64/a9858793c04249dd583b6e95d3effad3c78219",
+                  "size": 276,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "65",
+              "type": "dir",
+              "path": ".git/objects/65",
+              "size": 0,
+              "mtime": "2025-11-01T17:29:55+00:00",
+              "children": [
+                {
+                  "name": "6ee705183089b9983ecd4879c767b0c4adee40",
+                  "type": "file",
+                  "path": ".git/objects/65/6ee705183089b9983ecd4879c767b0c4adee40",
+                  "size": 227,
+                  "mtime": "2025-11-01T17:12:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "f8e25951f2371c40ba55db8078ff98a7d12301",
+                  "type": "file",
+                  "path": ".git/objects/65/f8e25951f2371c40ba55db8078ff98a7d12301",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:29:55+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "66",
+              "type": "dir",
+              "path": ".git/objects/66",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:22+00:00",
+              "children": [
+                {
+                  "name": "7df9a667c5d9a70a7d064d0290f331b340f390",
+                  "type": "file",
+                  "path": ".git/objects/66/7df9a667c5d9a70a7d064d0290f331b340f390",
+                  "size": 2615,
+                  "mtime": "2025-11-01T15:12:22+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "68",
+              "type": "dir",
+              "path": ".git/objects/68",
+              "size": 0,
+              "mtime": "2025-11-01T17:27:55+00:00",
+              "children": [
+                {
+                  "name": "6fb31819633800088b785e4e5e612d4c01ab76",
+                  "type": "file",
+                  "path": ".git/objects/68/6fb31819633800088b785e4e5e612d4c01ab76",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:27:55+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "69",
+              "type": "dir",
+              "path": ".git/objects/69",
+              "size": 0,
+              "mtime": "2025-11-01T17:22:38+00:00",
+              "children": [
+                {
+                  "name": "3380ac930ef1a2dfc2fb332f54b286a4b536cd",
+                  "type": "file",
+                  "path": ".git/objects/69/3380ac930ef1a2dfc2fb332f54b286a4b536cd",
+                  "size": 338,
+                  "mtime": "2025-11-01T15:52:09+00:00",
+                  "children": null
+                },
+                {
+                  "name": "7dece274cba4635c6488cd0d49fa197650c58b",
+                  "type": "file",
+                  "path": ".git/objects/69/7dece274cba4635c6488cd0d49fa197650c58b",
+                  "size": 367,
+                  "mtime": "2025-11-01T17:22:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "6b",
+              "type": "dir",
+              "path": ".git/objects/6b",
+              "size": 0,
+              "mtime": "2025-11-01T14:50:59+00:00",
+              "children": [
+                {
+                  "name": "daf8151a835781a6244711b816d97ead44e4e8",
+                  "type": "file",
+                  "path": ".git/objects/6b/daf8151a835781a6244711b816d97ead44e4e8",
+                  "size": 2984,
+                  "mtime": "2025-11-01T14:50:59+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "6c",
+              "type": "dir",
+              "path": ".git/objects/6c",
+              "size": 0,
+              "mtime": "2025-11-01T17:22:38+00:00",
+              "children": [
+                {
+                  "name": "f04269476e80298c74b718dabd384509d4d0c7",
+                  "type": "file",
+                  "path": ".git/objects/6c/f04269476e80298c74b718dabd384509d4d0c7",
+                  "size": 210,
+                  "mtime": "2025-11-01T17:22:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "6d",
+              "type": "dir",
+              "path": ".git/objects/6d",
+              "size": 0,
+              "mtime": "2025-11-01T14:51:56+00:00",
+              "children": [
+                {
+                  "name": "8dd617cdf5ff4bd1c01e17ca07364dd5a5cafe",
+                  "type": "file",
+                  "path": ".git/objects/6d/8dd617cdf5ff4bd1c01e17ca07364dd5a5cafe",
+                  "size": 49,
+                  "mtime": "2025-11-01T14:51:56+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "73",
+              "type": "dir",
+              "path": ".git/objects/73",
+              "size": 0,
+              "mtime": "2025-11-01T16:21:08+00:00",
+              "children": [
+                {
+                  "name": "22f9d78f1575d83b0186dc502e93ebff5789c8",
+                  "type": "file",
+                  "path": ".git/objects/73/22f9d78f1575d83b0186dc502e93ebff5789c8",
+                  "size": 446,
+                  "mtime": "2025-11-01T16:21:08+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "74",
+              "type": "dir",
+              "path": ".git/objects/74",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:51+00:00",
+              "children": [
+                {
+                  "name": "20906c3b450e721d388cec512985ca8e0b2f8f",
+                  "type": "file",
+                  "path": ".git/objects/74/20906c3b450e721d388cec512985ca8e0b2f8f",
+                  "size": 53,
+                  "mtime": "2025-11-01T17:11:14+00:00",
+                  "children": null
+                },
+                {
+                  "name": "7a83902ed6236ec19090a7fcc1aed353a33816",
+                  "type": "file",
+                  "path": ".git/objects/74/7a83902ed6236ec19090a7fcc1aed353a33816",
+                  "size": 50,
+                  "mtime": "2025-11-01T18:01:51+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "76",
+              "type": "dir",
+              "path": ".git/objects/76",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:48+00:00",
+              "children": [
+                {
+                  "name": "f22a40d87474a4bf4f07b5d8ed3288ec7a2212",
+                  "type": "file",
+                  "path": ".git/objects/76/f22a40d87474a4bf4f07b5d8ed3288ec7a2212",
+                  "size": 93,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "77",
+              "type": "dir",
+              "path": ".git/objects/77",
+              "size": 0,
+              "mtime": "2025-11-01T16:24:40+00:00",
+              "children": [
+                {
+                  "name": "57bed0e05ab2faff2896d1183146976680be9c",
+                  "type": "file",
+                  "path": ".git/objects/77/57bed0e05ab2faff2896d1183146976680be9c",
+                  "size": 347,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "b253b890dd005c3d9d964e8a9d5f3a04928416",
+                  "type": "file",
+                  "path": ".git/objects/77/b253b890dd005c3d9d964e8a9d5f3a04928416",
+                  "size": 3011,
+                  "mtime": "2025-11-01T16:24:40+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "78",
+              "type": "dir",
+              "path": ".git/objects/78",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "40e436926b2e1a5277d2e48904556bcb7ae4ee",
+                  "type": "file",
+                  "path": ".git/objects/78/40e436926b2e1a5277d2e48904556bcb7ae4ee",
+                  "size": 109,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "7a",
+              "type": "dir",
+              "path": ".git/objects/7a",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:48+00:00",
+              "children": [
+                {
+                  "name": "a8177c92e259544b4516c783f9115ea7f8e772",
+                  "type": "file",
+                  "path": ".git/objects/7a/a8177c92e259544b4516c783f9115ea7f8e772",
+                  "size": 57,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "7b",
+              "type": "dir",
+              "path": ".git/objects/7b",
+              "size": 0,
+              "mtime": "2025-11-01T17:53:06+00:00",
+              "children": [
+                {
+                  "name": "1442c6464a8f3be83047a3839832bb13ec91b8",
+                  "type": "file",
+                  "path": ".git/objects/7b/1442c6464a8f3be83047a3839832bb13ec91b8",
+                  "size": 192,
+                  "mtime": "2025-11-01T16:24:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "65836c63415031bcfc8238939d166039abbaae",
+                  "type": "file",
+                  "path": ".git/objects/7b/65836c63415031bcfc8238939d166039abbaae",
+                  "size": 367,
+                  "mtime": "2025-11-01T17:53:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "7e",
+              "type": "dir",
+              "path": ".git/objects/7e",
+              "size": 0,
+              "mtime": "2025-11-01T17:52:07+00:00",
+              "children": [
+                {
+                  "name": "0fa242cd9c94160aefbcac57133ea84d63438c",
+                  "type": "file",
+                  "path": ".git/objects/7e/0fa242cd9c94160aefbcac57133ea84d63438c",
+                  "size": 206,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "118b8ef65534d3aa3ea77c9fe79625160be6aa",
+                  "type": "file",
+                  "path": ".git/objects/7e/118b8ef65534d3aa3ea77c9fe79625160be6aa",
+                  "size": 3472,
+                  "mtime": "2025-11-01T17:52:07+00:00",
+                  "children": null
+                },
+                {
+                  "name": "2ba6613ad9230bf7b53a338e877b1a515b4f03",
+                  "type": "file",
+                  "path": ".git/objects/7e/2ba6613ad9230bf7b53a338e877b1a515b4f03",
+                  "size": 2768,
+                  "mtime": "2025-11-01T17:12:43+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "80",
+              "type": "dir",
+              "path": ".git/objects/80",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:22+00:00",
+              "children": [
+                {
+                  "name": "c88490029446ba1eb0bdeaf6b7a02b84615b48",
+                  "type": "file",
+                  "path": ".git/objects/80/c88490029446ba1eb0bdeaf6b7a02b84615b48",
+                  "size": 431,
+                  "mtime": "2025-11-01T15:12:22+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "83",
+              "type": "dir",
+              "path": ".git/objects/83",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:49+00:00",
+              "children": [
+                {
+                  "name": "cabaccf80cd60974ac8da235e984f29c4aca17",
+                  "type": "file",
+                  "path": ".git/objects/83/cabaccf80cd60974ac8da235e984f29c4aca17",
+                  "size": 367,
+                  "mtime": "2025-11-01T16:38:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "84",
+              "type": "dir",
+              "path": ".git/objects/84",
+              "size": 0,
+              "mtime": "2025-11-01T17:53:06+00:00",
+              "children": [
+                {
+                  "name": "2d86ee6d988e10580844821ae9769f7881dcb0",
+                  "type": "file",
+                  "path": ".git/objects/84/2d86ee6d988e10580844821ae9769f7881dcb0",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:53:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "85",
+              "type": "dir",
+              "path": ".git/objects/85",
+              "size": 0,
+              "mtime": "2025-11-01T17:12:49+00:00",
+              "children": [
+                {
+                  "name": "2a8bfd63fac41f6116297907a2e52a51477ea6",
+                  "type": "file",
+                  "path": ".git/objects/85/2a8bfd63fac41f6116297907a2e52a51477ea6",
+                  "size": 473,
+                  "mtime": "2025-11-01T17:12:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "87",
+              "type": "dir",
+              "path": ".git/objects/87",
+              "size": 0,
+              "mtime": "2025-11-01T16:13:36+00:00",
+              "children": [
+                {
+                  "name": "345f68be1d1b6d93adb18f18c08c4b3312ccfa",
+                  "type": "file",
+                  "path": ".git/objects/87/345f68be1d1b6d93adb18f18c08c4b3312ccfa",
+                  "size": 367,
+                  "mtime": "2025-11-01T16:13:36+00:00",
+                  "children": null
+                },
+                {
+                  "name": "7728c6c24e0af90df9455fc9c3e8e1768688ed",
+                  "type": "file",
+                  "path": ".git/objects/87/7728c6c24e0af90df9455fc9c3e8e1768688ed",
+                  "size": 667,
+                  "mtime": "2025-11-01T14:25:17+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "88",
+              "type": "dir",
+              "path": ".git/objects/88",
+              "size": 0,
+              "mtime": "2025-11-01T17:05:18+00:00",
+              "children": [
+                {
+                  "name": "80c38eb23a5d9b6ad0ba6aeceab5e473e0d3fd",
+                  "type": "file",
+                  "path": ".git/objects/88/80c38eb23a5d9b6ad0ba6aeceab5e473e0d3fd",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:05:18+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "89",
+              "type": "dir",
+              "path": ".git/objects/89",
+              "size": 0,
+              "mtime": "2025-11-01T17:35:53+00:00",
+              "children": [
+                {
+                  "name": "b3364c2a3e09de034163683c5e6a573763ffc9",
+                  "type": "file",
+                  "path": ".git/objects/89/b3364c2a3e09de034163683c5e6a573763ffc9",
+                  "size": 309,
+                  "mtime": "2025-11-01T17:35:53+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "8a",
+              "type": "dir",
+              "path": ".git/objects/8a",
+              "size": 0,
+              "mtime": "2025-11-01T16:24:49+00:00",
+              "children": [
+                {
+                  "name": "c0b904b515002dbeb3c268f4465a88e162c708",
+                  "type": "file",
+                  "path": ".git/objects/8a/c0b904b515002dbeb3c268f4465a88e162c708",
+                  "size": 367,
+                  "mtime": "2025-11-01T16:24:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "8b",
+              "type": "dir",
+              "path": ".git/objects/8b",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:33+00:00",
+              "children": [
+                {
+                  "name": "f635c51728641a69bbb963dd3f5bec5af3df51",
+                  "type": "file",
+                  "path": ".git/objects/8b/f635c51728641a69bbb963dd3f5bec5af3df51",
+                  "size": 446,
+                  "mtime": "2025-11-01T15:12:33+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "8e",
+              "type": "dir",
+              "path": ".git/objects/8e",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:43+00:00",
+              "children": [
+                {
+                  "name": "3aa4aa516499bc77f38cc64d4dd5aaec962770",
+                  "type": "file",
+                  "path": ".git/objects/8e/3aa4aa516499bc77f38cc64d4dd5aaec962770",
+                  "size": 366,
+                  "mtime": "2025-11-01T17:29:55+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a1cb13662f539c800adff6af3d26dcf6c6446c",
+                  "type": "file",
+                  "path": ".git/objects/8e/a1cb13662f539c800adff6af3d26dcf6c6446c",
+                  "size": 499,
+                  "mtime": "2025-11-01T16:10:12+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a9036a8148bea17780f9ff9d7ef2c4ea91d347",
+                  "type": "file",
+                  "path": ".git/objects/8e/a9036a8148bea17780f9ff9d7ef2c4ea91d347",
+                  "size": 446,
+                  "mtime": "2025-11-01T16:24:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "ae5a95308afba7a759b11e83ea122d1e2052d8",
+                  "type": "file",
+                  "path": ".git/objects/8e/ae5a95308afba7a759b11e83ea122d1e2052d8",
+                  "size": 3368,
+                  "mtime": "2025-11-01T18:01:43+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "91",
+              "type": "dir",
+              "path": ".git/objects/91",
+              "size": 0,
+              "mtime": "2025-11-01T14:50:59+00:00",
+              "children": [
+                {
+                  "name": "280df0da5410a77b6cc24f4635833531069032",
+                  "type": "file",
+                  "path": ".git/objects/91/280df0da5410a77b6cc24f4635833531069032",
+                  "size": 8636,
+                  "mtime": "2025-11-01T14:50:59+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "94",
+              "type": "dir",
+              "path": ".git/objects/94",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:22+00:00",
+              "children": [
+                {
+                  "name": "5ce28c494b08e11ea0e2ada33949b3f1f62561",
+                  "type": "file",
+                  "path": ".git/objects/94/5ce28c494b08e11ea0e2ada33949b3f1f62561",
+                  "size": 2148,
+                  "mtime": "2025-11-01T15:12:22+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "95",
+              "type": "dir",
+              "path": ".git/objects/95",
+              "size": 0,
+              "mtime": "2025-11-01T14:51:56+00:00",
+              "children": [
+                {
+                  "name": "dacf2d8f27b06938728b8507eab7a95c651c6e",
+                  "type": "file",
+                  "path": ".git/objects/95/dacf2d8f27b06938728b8507eab7a95c651c6e",
+                  "size": 225,
+                  "mtime": "2025-11-01T14:51:56+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "96",
+              "type": "dir",
+              "path": ".git/objects/96",
+              "size": 0,
+              "mtime": "2025-11-01T17:16:16+00:00",
+              "children": [
+                {
+                  "name": "00a25f2498d79d22c6e380441472405e70d2e0",
+                  "type": "file",
+                  "path": ".git/objects/96/00a25f2498d79d22c6e380441472405e70d2e0",
+                  "size": 294,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "032a013dc51613d5a8b4605ec27d53ec626faf",
+                  "type": "file",
+                  "path": ".git/objects/96/032a013dc51613d5a8b4605ec27d53ec626faf",
+                  "size": 409,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "20e8e29998ea47829d7ed33d491f544c42a750",
+                  "type": "file",
+                  "path": ".git/objects/96/20e8e29998ea47829d7ed33d491f544c42a750",
+                  "size": 1669,
+                  "mtime": "2025-11-01T17:16:16+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "97",
+              "type": "dir",
+              "path": ".git/objects/97",
+              "size": 0,
+              "mtime": "2025-11-01T17:22:38+00:00",
+              "children": [
+                {
+                  "name": "12a8ae8926090fd7f889609e4a626979b5d687",
+                  "type": "file",
+                  "path": ".git/objects/97/12a8ae8926090fd7f889609e4a626979b5d687",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:22:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "f450683d3db536cfe332e8a36460cf62381197",
+                  "type": "file",
+                  "path": ".git/objects/97/f450683d3db536cfe332e8a36460cf62381197",
+                  "size": 196,
+                  "mtime": "2025-11-01T14:06:32+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "98",
+              "type": "dir",
+              "path": ".git/objects/98",
+              "size": 0,
+              "mtime": "2025-11-01T17:35:53+00:00",
+              "children": [
+                {
+                  "name": "17aff1d803c11af264c8cac28fa2227966115f",
+                  "type": "file",
+                  "path": ".git/objects/98/17aff1d803c11af264c8cac28fa2227966115f",
+                  "size": 473,
+                  "mtime": "2025-11-01T17:35:53+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "99",
+              "type": "dir",
+              "path": ".git/objects/99",
+              "size": 0,
+              "mtime": "2025-11-01T17:16:25+00:00",
+              "children": [
+                {
+                  "name": "40ae094ba11d9480a92286e05c0f929faed81c",
+                  "type": "file",
+                  "path": ".git/objects/99/40ae094ba11d9480a92286e05c0f929faed81c",
+                  "size": 218,
+                  "mtime": "2025-11-01T17:16:25+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "9a",
+              "type": "dir",
+              "path": ".git/objects/9a",
+              "size": 0,
+              "mtime": "2025-11-01T14:06:32+00:00",
+              "children": [
+                {
+                  "name": "6a43d87d9e02f61ffc22834bd0fa09bdfdd738",
+                  "type": "file",
+                  "path": ".git/objects/9a/6a43d87d9e02f61ffc22834bd0fa09bdfdd738",
+                  "size": 220,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a58f99c9fa9b378c751ed1813919589f75dd1d",
+                  "type": "file",
+                  "path": ".git/objects/9a/a58f99c9fa9b378c751ed1813919589f75dd1d",
+                  "size": 309,
+                  "mtime": "2025-11-01T14:06:32+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "9c",
+              "type": "dir",
+              "path": ".git/objects/9c",
+              "size": 0,
+              "mtime": "2025-11-01T16:13:27+00:00",
+              "children": [
+                {
+                  "name": "80f11d3eb5f3e43174b5d309c819d2065c106e",
+                  "type": "file",
+                  "path": ".git/objects/9c/80f11d3eb5f3e43174b5d309c819d2065c106e",
+                  "size": 1030,
+                  "mtime": "2025-11-01T16:13:27+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "9d",
+              "type": "dir",
+              "path": ".git/objects/9d",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:43+00:00",
+              "children": [
+                {
+                  "name": "581a5d549313b2f3826067ad9c3ebe36500092",
+                  "type": "file",
+                  "path": ".git/objects/9d/581a5d549313b2f3826067ad9c3ebe36500092",
+                  "size": 491,
+                  "mtime": "2025-11-01T18:01:43+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "9e",
+              "type": "dir",
+              "path": ".git/objects/9e",
+              "size": 0,
+              "mtime": "2025-11-01T17:05:18+00:00",
+              "children": [
+                {
+                  "name": "5f2af3afe54890b0d20371c07a28854d3f5faf",
+                  "type": "file",
+                  "path": ".git/objects/9e/5f2af3afe54890b0d20371c07a28854d3f5faf",
+                  "size": 226,
+                  "mtime": "2025-11-01T17:05:18+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "9f",
+              "type": "dir",
+              "path": ".git/objects/9f",
+              "size": 0,
+              "mtime": "2025-11-01T15:52:02+00:00",
+              "children": [
+                {
+                  "name": "10137620e1cb0c5312f3985224470fdcd9f470",
+                  "type": "file",
+                  "path": ".git/objects/9f/10137620e1cb0c5312f3985224470fdcd9f470",
+                  "size": 179,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                },
+                {
+                  "name": "a317e1f554806dcfe9817ee8ab85e7e1cfdfeb",
+                  "type": "file",
+                  "path": ".git/objects/9f/a317e1f554806dcfe9817ee8ab85e7e1cfdfeb",
+                  "size": 114,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "b85acad03997520c8b85c819a96f8029f013ae",
+                  "type": "file",
+                  "path": ".git/objects/9f/b85acad03997520c8b85c819a96f8029f013ae",
+                  "size": 968,
+                  "mtime": "2025-11-01T15:52:02+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "a0",
+              "type": "dir",
+              "path": ".git/objects/a0",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:51+00:00",
+              "children": [
+                {
+                  "name": "d0adf62066aaa2d5e09f8d1872c53eb4e5c809",
+                  "type": "file",
+                  "path": ".git/objects/a0/d0adf62066aaa2d5e09f8d1872c53eb4e5c809",
+                  "size": 366,
+                  "mtime": "2025-11-01T18:01:51+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "a1",
+              "type": "dir",
+              "path": ".git/objects/a1",
+              "size": 0,
+              "mtime": "2025-11-01T16:13:36+00:00",
+              "children": [
+                {
+                  "name": "bca40f1f2bddf844b5dde6b01c539464ba5fa0",
+                  "type": "file",
+                  "path": ".git/objects/a1/bca40f1f2bddf844b5dde6b01c539464ba5fa0",
+                  "size": 49,
+                  "mtime": "2025-11-01T16:13:36+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "a3",
+              "type": "dir",
+              "path": ".git/objects/a3",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:33+00:00",
+              "children": [
+                {
+                  "name": "2ef1d7487071ec86faf65062df5db8b4c12452",
+                  "type": "file",
+                  "path": ".git/objects/a3/2ef1d7487071ec86faf65062df5db8b4c12452",
+                  "size": 446,
+                  "mtime": "2025-11-01T14:51:56+00:00",
+                  "children": null
+                },
+                {
+                  "name": "c9b73fa858455f0f6106d3c86d29aff3025426",
+                  "type": "file",
+                  "path": ".git/objects/a3/c9b73fa858455f0f6106d3c86d29aff3025426",
+                  "size": 93,
+                  "mtime": "2025-11-01T15:12:33+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "a4",
+              "type": "dir",
+              "path": ".git/objects/a4",
+              "size": 0,
+              "mtime": "2025-11-01T17:53:06+00:00",
+              "children": [
+                {
+                  "name": "199bdfd87e2285bd96831311a0c815f288b860",
+                  "type": "file",
+                  "path": ".git/objects/a4/199bdfd87e2285bd96831311a0c815f288b860",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:53:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "328bad5175a89b6c8f294e60cd5d16d4fc4520",
+                  "type": "file",
+                  "path": ".git/objects/a4/328bad5175a89b6c8f294e60cd5d16d4fc4520",
+                  "size": 367,
+                  "mtime": "2025-11-01T17:05:18+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "a6",
+              "type": "dir",
+              "path": ".git/objects/a6",
+              "size": 0,
+              "mtime": "2025-11-01T17:52:07+00:00",
+              "children": [
+                {
+                  "name": "6443c08ebd12d77223fc7320e0ce35601325f6",
+                  "type": "file",
+                  "path": ".git/objects/a6/6443c08ebd12d77223fc7320e0ce35601325f6",
+                  "size": 3046,
+                  "mtime": "2025-11-01T17:52:07+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "a7",
+              "type": "dir",
+              "path": ".git/objects/a7",
+              "size": 0,
+              "mtime": "2025-11-01T14:05:06+00:00",
+              "children": [
+                {
+                  "name": "1a0a43712e19e6753cf1187708c236e6fbb725",
+                  "type": "file",
+                  "path": ".git/objects/a7/1a0a43712e19e6753cf1187708c236e6fbb725",
+                  "size": 1268,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "a9",
+              "type": "dir",
+              "path": ".git/objects/a9",
+              "size": 0,
+              "mtime": "2025-11-01T17:12:49+00:00",
+              "children": [
+                {
+                  "name": "5f81ee72ebfd5451864d1f003f91a608369f61",
+                  "type": "file",
+                  "path": ".git/objects/a9/5f81ee72ebfd5451864d1f003f91a608369f61",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:12:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "aa",
+              "type": "dir",
+              "path": ".git/objects/aa",
+              "size": 0,
+              "mtime": "2025-11-01T16:13:36+00:00",
+              "children": [
+                {
+                  "name": "f4283863979833edba17bd89614b2e08fc350e",
+                  "type": "file",
+                  "path": ".git/objects/aa/f4283863979833edba17bd89614b2e08fc350e",
+                  "size": 446,
+                  "mtime": "2025-11-01T16:13:36+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "ae",
+              "type": "dir",
+              "path": ".git/objects/ae",
+              "size": 0,
+              "mtime": "2025-11-01T16:54:14+00:00",
+              "children": [
+                {
+                  "name": "19a63286482365968318232019427c68f7876e",
+                  "type": "file",
+                  "path": ".git/objects/ae/19a63286482365968318232019427c68f7876e",
+                  "size": 366,
+                  "mtime": "2025-11-01T16:54:14+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "b0",
+              "type": "dir",
+              "path": ".git/objects/b0",
+              "size": 0,
+              "mtime": "2025-11-01T17:53:06+00:00",
+              "children": [
+                {
+                  "name": "0d140f308799c3a103debd0d6a48bf93b7c97f",
+                  "type": "file",
+                  "path": ".git/objects/b0/0d140f308799c3a103debd0d6a48bf93b7c97f",
+                  "size": 499,
+                  "mtime": "2025-11-01T17:53:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "9a47311ec016f1d3504f0c32779195f6d8a89d",
+                  "type": "file",
+                  "path": ".git/objects/b0/9a47311ec016f1d3504f0c32779195f6d8a89d",
+                  "size": 427,
+                  "mtime": "2025-11-01T15:12:22+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "b1",
+              "type": "dir",
+              "path": ".git/objects/b1",
+              "size": 0,
+              "mtime": "2025-11-01T14:05:06+00:00",
+              "children": [
+                {
+                  "name": "69b797696f7812385052400772d606f8576d69",
+                  "type": "file",
+                  "path": ".git/objects/b1/69b797696f7812385052400772d606f8576d69",
+                  "size": 336,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "797bd3c255b6462fab249d4edbefd12dbd8528",
+                  "type": "file",
+                  "path": ".git/objects/b1/797bd3c255b6462fab249d4edbefd12dbd8528",
+                  "size": 460,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "b3",
+              "type": "dir",
+              "path": ".git/objects/b3",
+              "size": 0,
+              "mtime": "2025-11-01T17:52:07+00:00",
+              "children": [
+                {
+                  "name": "fe2e2c1a802812966645013c313bc1211b8959",
+                  "type": "file",
+                  "path": ".git/objects/b3/fe2e2c1a802812966645013c313bc1211b8959",
+                  "size": 1713,
+                  "mtime": "2025-11-01T17:52:07+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "b4",
+              "type": "dir",
+              "path": ".git/objects/b4",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "f2cda603bdaa4e3d95eaaf3a5813603e0277fd",
+                  "type": "file",
+                  "path": ".git/objects/b4/f2cda603bdaa4e3d95eaaf3a5813603e0277fd",
+                  "size": 836,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "b6",
+              "type": "dir",
+              "path": ".git/objects/b6",
+              "size": 0,
+              "mtime": "2025-11-01T17:27:55+00:00",
+              "children": [
+                {
+                  "name": "14b95c1514e313d1f0aa045721b781349c73d4",
+                  "type": "file",
+                  "path": ".git/objects/b6/14b95c1514e313d1f0aa045721b781349c73d4",
+                  "size": 473,
+                  "mtime": "2025-11-01T17:22:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "70d473d622bee15a366590c5070538e3860940",
+                  "type": "file",
+                  "path": ".git/objects/b6/70d473d622bee15a366590c5070538e3860940",
+                  "size": 367,
+                  "mtime": "2025-11-01T17:27:55+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "b7",
+              "type": "dir",
+              "path": ".git/objects/b7",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:49+00:00",
+              "children": [
+                {
+                  "name": "724c479e38c6538b134621826f5a2a4ff53e00",
+                  "type": "file",
+                  "path": ".git/objects/b7/724c479e38c6538b134621826f5a2a4ff53e00",
+                  "size": 207,
+                  "mtime": "2025-11-01T16:38:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "b9",
+              "type": "dir",
+              "path": ".git/objects/b9",
+              "size": 0,
+              "mtime": "2025-11-01T04:06:54+00:00",
+              "children": [
+                {
+                  "name": "855a9771f26f3cbf658b46d4dbace4dbdfaa8d",
+                  "type": "file",
+                  "path": ".git/objects/b9/855a9771f26f3cbf658b46d4dbace4dbdfaa8d",
+                  "size": 160,
+                  "mtime": "2025-11-01T04:06:54+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "bc",
+              "type": "dir",
+              "path": ".git/objects/bc",
+              "size": 0,
+              "mtime": "2025-11-01T16:54:14+00:00",
+              "children": [
+                {
+                  "name": "7f1b6cd705964c8a9968a154c99ac5c1574221",
+                  "type": "file",
+                  "path": ".git/objects/bc/7f1b6cd705964c8a9968a154c99ac5c1574221",
+                  "size": 3164,
+                  "mtime": "2025-11-01T16:49:36+00:00",
+                  "children": null
+                },
+                {
+                  "name": "95a11f2d703c2e8ef581f279782ed08b75aa07",
+                  "type": "file",
+                  "path": ".git/objects/bc/95a11f2d703c2e8ef581f279782ed08b75aa07",
+                  "size": 309,
+                  "mtime": "2025-11-01T16:54:14+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "bd",
+              "type": "dir",
+              "path": ".git/objects/bd",
+              "size": 0,
+              "mtime": "2025-11-01T14:05:06+00:00",
+              "children": [
+                {
+                  "name": "9650062995f68af3d80315f422224087ef9d9d",
+                  "type": "file",
+                  "path": ".git/objects/bd/9650062995f68af3d80315f422224087ef9d9d",
+                  "size": 882,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "c0",
+              "type": "dir",
+              "path": ".git/objects/c0",
+              "size": 0,
+              "mtime": "2025-11-01T17:16:25+00:00",
+              "children": [
+                {
+                  "name": "15d9bfa490f040dc298d4fb1c9a137eba9c6e8",
+                  "type": "file",
+                  "path": ".git/objects/c0/15d9bfa490f040dc298d4fb1c9a137eba9c6e8",
+                  "size": 367,
+                  "mtime": "2025-11-01T17:16:25+00:00",
+                  "children": null
+                },
+                {
+                  "name": "4914ec6f6f6b41d5c28beeb26f50bbbea7f988",
+                  "type": "file",
+                  "path": ".git/objects/c0/4914ec6f6f6b41d5c28beeb26f50bbbea7f988",
+                  "size": 213,
+                  "mtime": "2025-11-01T15:12:33+00:00",
+                  "children": null
+                },
+                {
+                  "name": "f9df63dcb92b88d4e864fe94b34fdd5f461e39",
+                  "type": "file",
+                  "path": ".git/objects/c0/f9df63dcb92b88d4e864fe94b34fdd5f461e39",
+                  "size": 206,
+                  "mtime": "2025-11-01T16:24:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "c1",
+              "type": "dir",
+              "path": ".git/objects/c1",
+              "size": 0,
+              "mtime": "2025-11-01T17:05:18+00:00",
+              "children": [
+                {
+                  "name": "4b9d9cf778462335232b7796cbd7d7df854251",
+                  "type": "file",
+                  "path": ".git/objects/c1/4b9d9cf778462335232b7796cbd7d7df854251",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:05:18+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "c4",
+              "type": "dir",
+              "path": ".git/objects/c4",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:48+00:00",
+              "children": [
+                {
+                  "name": "4e546cb6aea2ae036b0c471ab9ca2c59edc5cf",
+                  "type": "file",
+                  "path": ".git/objects/c4/4e546cb6aea2ae036b0c471ab9ca2c59edc5cf",
+                  "size": 701,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "9bb2cb349ca2fa7bb7c83f442f9965ec5c6eb8",
+                  "type": "file",
+                  "path": ".git/objects/c4/9bb2cb349ca2fa7bb7c83f442f9965ec5c6eb8",
+                  "size": 51,
+                  "mtime": "2025-11-01T03:59:47+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "c5",
+              "type": "dir",
+              "path": ".git/objects/c5",
+              "size": 0,
+              "mtime": "2025-11-01T16:05:18+00:00",
+              "children": [
+                {
+                  "name": "2b27f0907ec166a5af392f85cc5e259b58a8dc",
+                  "type": "file",
+                  "path": ".git/objects/c5/2b27f0907ec166a5af392f85cc5e259b58a8dc",
+                  "size": 193,
+                  "mtime": "2025-11-01T14:06:32+00:00",
+                  "children": null
+                },
+                {
+                  "name": "78c4292291b13ec641329e0c89267975521e68",
+                  "type": "file",
+                  "path": ".git/objects/c5/78c4292291b13ec641329e0c89267975521e68",
+                  "size": 393,
+                  "mtime": "2025-11-01T16:05:18+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "c7",
+              "type": "dir",
+              "path": ".git/objects/c7",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "15c5226b51d4eda5195aeef6f2726521ad498a",
+                  "type": "file",
+                  "path": ".git/objects/c7/15c5226b51d4eda5195aeef6f2726521ad498a",
+                  "size": 2650,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "ca",
+              "type": "dir",
+              "path": ".git/objects/ca",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:38+00:00",
+              "children": [
+                {
+                  "name": "4e064f70664cdc4ec5a66a8b59a84f72dde652",
+                  "type": "file",
+                  "path": ".git/objects/ca/4e064f70664cdc4ec5a66a8b59a84f72dde652",
+                  "size": 2627,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "cb",
+              "type": "dir",
+              "path": ".git/objects/cb",
+              "size": 0,
+              "mtime": "2025-11-01T16:10:27+00:00",
+              "children": [
+                {
+                  "name": "2db622da90a08f0d3103831e13c2614b1fc393",
+                  "type": "file",
+                  "path": ".git/objects/cb/2db622da90a08f0d3103831e13c2614b1fc393",
+                  "size": 208,
+                  "mtime": "2025-11-01T16:10:27+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "cc",
+              "type": "dir",
+              "path": ".git/objects/cc",
+              "size": 0,
+              "mtime": "2025-11-01T14:25:23+00:00",
+              "children": [
+                {
+                  "name": "7263727ed76f91964d291abc5eb74902289e35",
+                  "type": "file",
+                  "path": ".git/objects/cc/7263727ed76f91964d291abc5eb74902289e35",
+                  "size": 413,
+                  "mtime": "2025-11-01T14:25:23+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "cf",
+              "type": "dir",
+              "path": ".git/objects/cf",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:49+00:00",
+              "children": [
+                {
+                  "name": "3974be7a65517776e28f366630ab375f17459a",
+                  "type": "file",
+                  "path": ".git/objects/cf/3974be7a65517776e28f366630ab375f17459a",
+                  "size": 446,
+                  "mtime": "2025-11-01T16:38:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "7acad7005b814bf4968710a9ba2088719b7f1d",
+                  "type": "file",
+                  "path": ".git/objects/cf/7acad7005b814bf4968710a9ba2088719b7f1d",
+                  "size": 988,
+                  "mtime": "2025-11-01T16:38:41+00:00",
+                  "children": null
+                },
+                {
+                  "name": "807d3d7b4661790d2be53e70f179d9a8efe1db",
+                  "type": "file",
+                  "path": ".git/objects/cf/807d3d7b4661790d2be53e70f179d9a8efe1db",
+                  "size": 49,
+                  "mtime": "2025-11-01T16:24:49+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "d1",
+              "type": "dir",
+              "path": ".git/objects/d1",
+              "size": 0,
+              "mtime": "2025-11-01T17:27:44+00:00",
+              "children": [
+                {
+                  "name": "0dd72ce619173fdd6baf630815f5a7556ccd0c",
+                  "type": "file",
+                  "path": ".git/objects/d1/0dd72ce619173fdd6baf630815f5a7556ccd0c",
+                  "size": 1656,
+                  "mtime": "2025-11-01T17:27:44+00:00",
+                  "children": null
+                },
+                {
+                  "name": "64bdd841999ed1933bdde6fb0ff3dd445f6fe6",
+                  "type": "file",
+                  "path": ".git/objects/d1/64bdd841999ed1933bdde6fb0ff3dd445f6fe6",
+                  "size": 193,
+                  "mtime": "2025-11-01T03:59:48+00:00",
+                  "children": null
+                },
+                {
+                  "name": "f9901d46cc0287f869247dd37f1e4f30304dd9",
+                  "type": "file",
+                  "path": ".git/objects/d1/f9901d46cc0287f869247dd37f1e4f30304dd9",
+                  "size": 93,
+                  "mtime": "2025-11-01T14:25:23+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "d5",
+              "type": "dir",
+              "path": ".git/objects/d5",
+              "size": 0,
+              "mtime": "2025-11-01T14:05:06+00:00",
+              "children": [
+                {
+                  "name": "11080bc49b6143207a6bbccc27cf843a5b3efd",
+                  "type": "file",
+                  "path": ".git/objects/d5/11080bc49b6143207a6bbccc27cf843a5b3efd",
+                  "size": 758,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "d7",
+              "type": "dir",
+              "path": ".git/objects/d7",
+              "size": 0,
+              "mtime": "2025-11-01T16:49:36+00:00",
+              "children": [
+                {
+                  "name": "56ac2a225c0d726c29ee03c9ecb23e4e154fc0",
+                  "type": "file",
+                  "path": ".git/objects/d7/56ac2a225c0d726c29ee03c9ecb23e4e154fc0",
+                  "size": 2688,
+                  "mtime": "2025-11-01T16:49:36+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "d8",
+              "type": "dir",
+              "path": ".git/objects/d8",
+              "size": 0,
+              "mtime": "2025-11-01T16:10:27+00:00",
+              "children": [
+                {
+                  "name": "f2dbe3772a6648670a96123ce382114e3cc4f2",
+                  "type": "file",
+                  "path": ".git/objects/d8/f2dbe3772a6648670a96123ce382114e3cc4f2",
+                  "size": 446,
+                  "mtime": "2025-11-01T16:10:27+00:00",
+                  "children": null
+                },
+                {
+                  "name": "f7d3316578b89234463b00c5a5162f99cb3472",
+                  "type": "file",
+                  "path": ".git/objects/d8/f7d3316578b89234463b00c5a5162f99cb3472",
+                  "size": 185,
+                  "mtime": "2025-11-01T16:05:26+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "dc",
+              "type": "dir",
+              "path": ".git/objects/dc",
+              "size": 0,
+              "mtime": "2025-11-01T16:10:12+00:00",
+              "children": [
+                {
+                  "name": "e438ba93da53abeb3de4b78d98d49cf1d23888",
+                  "type": "file",
+                  "path": ".git/objects/dc/e438ba93da53abeb3de4b78d98d49cf1d23888",
+                  "size": 607,
+                  "mtime": "2025-11-01T16:10:12+00:00",
+                  "children": null
+                },
+                {
+                  "name": "eb8d2fb324a0e18f58aab17247db11fbfa2cf1",
+                  "type": "file",
+                  "path": ".git/objects/dc/eb8d2fb324a0e18f58aab17247db11fbfa2cf1",
+                  "size": 623,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "dd",
+              "type": "dir",
+              "path": ".git/objects/dd",
+              "size": 0,
+              "mtime": "2025-11-01T17:11:21+00:00",
+              "children": [
+                {
+                  "name": "83af6951159ff851f1d22809d36d96e7e24141",
+                  "type": "file",
+                  "path": ".git/objects/dd/83af6951159ff851f1d22809d36d96e7e24141",
+                  "size": 198,
+                  "mtime": "2025-11-01T17:11:21+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "de",
+              "type": "dir",
+              "path": ".git/objects/de",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:33+00:00",
+              "children": [
+                {
+                  "name": "6e655d8af66e942a3d25f1d47a1e4d39a215dc",
+                  "type": "file",
+                  "path": ".git/objects/de/6e655d8af66e942a3d25f1d47a1e4d39a215dc",
+                  "size": 337,
+                  "mtime": "2025-11-01T15:12:33+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e0",
+              "type": "dir",
+              "path": ".git/objects/e0",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:41+00:00",
+              "children": [
+                {
+                  "name": "28f5ff18d86ee206b64765f59b4a6bcad3940e",
+                  "type": "file",
+                  "path": ".git/objects/e0/28f5ff18d86ee206b64765f59b4a6bcad3940e",
+                  "size": 188,
+                  "mtime": "2025-11-01T16:38:41+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e1",
+              "type": "dir",
+              "path": ".git/objects/e1",
+              "size": 0,
+              "mtime": "2025-11-01T16:05:26+00:00",
+              "children": [
+                {
+                  "name": "11f81fb060efeeb7fff0b99e9f6fcb213552ac",
+                  "type": "file",
+                  "path": ".git/objects/e1/11f81fb060efeeb7fff0b99e9f6fcb213552ac",
+                  "size": 111,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "63f60708daca45546dfc3acf4a5ac527216cc2",
+                  "type": "file",
+                  "path": ".git/objects/e1/63f60708daca45546dfc3acf4a5ac527216cc2",
+                  "size": 49,
+                  "mtime": "2025-11-01T16:05:26+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e3",
+              "type": "dir",
+              "path": ".git/objects/e3",
+              "size": 0,
+              "mtime": "2025-11-01T15:52:09+00:00",
+              "children": [
+                {
+                  "name": "50ec368e95d2720d9b7a5ec886a3acb7ab8509",
+                  "type": "file",
+                  "path": ".git/objects/e3/50ec368e95d2720d9b7a5ec886a3acb7ab8509",
+                  "size": 309,
+                  "mtime": "2025-11-01T15:52:09+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e4",
+              "type": "dir",
+              "path": ".git/objects/e4",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:51+00:00",
+              "children": [
+                {
+                  "name": "4a1b647efa3975d5710141393c1f6a29a56e30",
+                  "type": "file",
+                  "path": ".git/objects/e4/4a1b647efa3975d5710141393c1f6a29a56e30",
+                  "size": 49,
+                  "mtime": "2025-11-01T17:19:39+00:00",
+                  "children": null
+                },
+                {
+                  "name": "756cdfb147391993ac15d7a92cbcd214fbcb4c",
+                  "type": "file",
+                  "path": ".git/objects/e4/756cdfb147391993ac15d7a92cbcd214fbcb4c",
+                  "size": 1120,
+                  "mtime": "2025-11-01T15:52:02+00:00",
+                  "children": null
+                },
+                {
+                  "name": "81efd43b98e25ea5c2ed655b2a4f678a587b87",
+                  "type": "file",
+                  "path": ".git/objects/e4/81efd43b98e25ea5c2ed655b2a4f678a587b87",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:12:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "d10eb7e7f654a16ada784ff967f37a683bcc13",
+                  "type": "file",
+                  "path": ".git/objects/e4/d10eb7e7f654a16ada784ff967f37a683bcc13",
+                  "size": 194,
+                  "mtime": "2025-11-01T17:35:53+00:00",
+                  "children": null
+                },
+                {
+                  "name": "e94d07099a2d3c066843df056649080b8c12c8",
+                  "type": "file",
+                  "path": ".git/objects/e4/e94d07099a2d3c066843df056649080b8c12c8",
+                  "size": 309,
+                  "mtime": "2025-11-01T18:01:51+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e6",
+              "type": "dir",
+              "path": ".git/objects/e6",
+              "size": 0,
+              "mtime": "2025-11-01T17:12:49+00:00",
+              "children": [
+                {
+                  "name": "043558423b5a8a7fcb96b5fe47457ab61557e2",
+                  "type": "file",
+                  "path": ".git/objects/e6/043558423b5a8a7fcb96b5fe47457ab61557e2",
+                  "size": 367,
+                  "mtime": "2025-11-01T17:12:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "20e672b92cb95f2c9f5dc50a94a2e02cc2971f",
+                  "type": "file",
+                  "path": ".git/objects/e6/20e672b92cb95f2c9f5dc50a94a2e02cc2971f",
+                  "size": 994,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e7",
+              "type": "dir",
+              "path": ".git/objects/e7",
+              "size": 0,
+              "mtime": "2025-11-01T15:12:33+00:00",
+              "children": [
+                {
+                  "name": "2ca89f965a09759edef7fa562e248d8b7b6556",
+                  "type": "file",
+                  "path": ".git/objects/e7/2ca89f965a09759edef7fa562e248d8b7b6556",
+                  "size": 247,
+                  "mtime": "2025-11-01T15:12:33+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e8",
+              "type": "dir",
+              "path": ".git/objects/e8",
+              "size": 0,
+              "mtime": "2025-11-01T16:21:08+00:00",
+              "children": [
+                {
+                  "name": "b12ddeb43eb7d5cf723a20b6adb807252fc69d",
+                  "type": "file",
+                  "path": ".git/objects/e8/b12ddeb43eb7d5cf723a20b6adb807252fc69d",
+                  "size": 49,
+                  "mtime": "2025-11-01T16:21:08+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "e9",
+              "type": "dir",
+              "path": ".git/objects/e9",
+              "size": 0,
+              "mtime": "2025-11-01T17:19:39+00:00",
+              "children": [
+                {
+                  "name": "7a01ccb2463c74533290a6255a8e3370c4d24d",
+                  "type": "file",
+                  "path": ".git/objects/e9/7a01ccb2463c74533290a6255a8e3370c4d24d",
+                  "size": 2735,
+                  "mtime": "2025-11-01T16:20:51+00:00",
+                  "children": null
+                },
+                {
+                  "name": "f57e08849c9c4fd4fb059d5aef11d6f0c475d8",
+                  "type": "file",
+                  "path": ".git/objects/e9/f57e08849c9c4fd4fb059d5aef11d6f0c475d8",
+                  "size": 308,
+                  "mtime": "2025-11-01T17:19:39+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "ea",
+              "type": "dir",
+              "path": ".git/objects/ea",
+              "size": 0,
+              "mtime": "2025-11-01T14:05:06+00:00",
+              "children": [
+                {
+                  "name": "337c40e0f11a54d65dfa1fc437a6b2500eadf2",
+                  "type": "file",
+                  "path": ".git/objects/ea/337c40e0f11a54d65dfa1fc437a6b2500eadf2",
+                  "size": 336,
+                  "mtime": "2025-11-01T14:05:06+00:00",
+                  "children": null
+                },
+                {
+                  "name": "9fa24101c660c434505be7fc88158525deab3a",
+                  "type": "file",
+                  "path": ".git/objects/ea/9fa24101c660c434505be7fc88158525deab3a",
+                  "size": 1514,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "eb",
+              "type": "dir",
+              "path": ".git/objects/eb",
+              "size": 0,
+              "mtime": "2025-11-01T17:27:55+00:00",
+              "children": [
+                {
+                  "name": "3a3bb2955f9b588bbcd471a5cb8f74f5e1cc58",
+                  "type": "file",
+                  "path": ".git/objects/eb/3a3bb2955f9b588bbcd471a5cb8f74f5e1cc58",
+                  "size": 473,
+                  "mtime": "2025-11-01T17:27:55+00:00",
+                  "children": null
+                },
+                {
+                  "name": "9118c7a0d86650798394e9cc0040903b775dae",
+                  "type": "file",
+                  "path": ".git/objects/eb/9118c7a0d86650798394e9cc0040903b775dae",
+                  "size": 50,
+                  "mtime": "2025-11-01T03:59:47+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "ec",
+              "type": "dir",
+              "path": ".git/objects/ec",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:51+00:00",
+              "children": [
+                {
+                  "name": "3b2ac829ffc97afda2a3cdfe09acb5150c7534",
+                  "type": "file",
+                  "path": ".git/objects/ec/3b2ac829ffc97afda2a3cdfe09acb5150c7534",
+                  "size": 499,
+                  "mtime": "2025-11-01T18:01:51+00:00",
+                  "children": null
+                },
+                {
+                  "name": "72a726d1abc135a3d48d89c7a1d130f67a7217",
+                  "type": "file",
+                  "path": ".git/objects/ec/72a726d1abc135a3d48d89c7a1d130f67a7217",
+                  "size": 211,
+                  "mtime": "2025-11-01T16:54:15+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "ee",
+              "type": "dir",
+              "path": ".git/objects/ee",
+              "size": 0,
+              "mtime": "2025-11-01T17:16:25+00:00",
+              "children": [
+                {
+                  "name": "8f49c84ce480358da08f37ab7660fecd19ea25",
+                  "type": "file",
+                  "path": ".git/objects/ee/8f49c84ce480358da08f37ab7660fecd19ea25",
+                  "size": 473,
+                  "mtime": "2025-11-01T17:16:25+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "f6",
+              "type": "dir",
+              "path": ".git/objects/f6",
+              "size": 0,
+              "mtime": "2025-11-01T17:35:45+00:00",
+              "children": [
+                {
+                  "name": "8e4dc0090f9e37a02c5b3f6586e3d5c711014c",
+                  "type": "file",
+                  "path": ".git/objects/f6/8e4dc0090f9e37a02c5b3f6586e3d5c711014c",
+                  "size": 179,
+                  "mtime": "2025-11-01T03:59:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "cf30d52230c99b47dd380d6896c62eb108df6e",
+                  "type": "file",
+                  "path": ".git/objects/f6/cf30d52230c99b47dd380d6896c62eb108df6e",
+                  "size": 1925,
+                  "mtime": "2025-11-01T17:35:45+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "fb",
+              "type": "dir",
+              "path": ".git/objects/fb",
+              "size": 0,
+              "mtime": "2025-11-01T16:13:36+00:00",
+              "children": [
+                {
+                  "name": "1c52e104a18f54d0ce3c801682c4c449ba0aa4",
+                  "type": "file",
+                  "path": ".git/objects/fb/1c52e104a18f54d0ce3c801682c4c449ba0aa4",
+                  "size": 309,
+                  "mtime": "2025-11-01T16:13:36+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "fc",
+              "type": "dir",
+              "path": ".git/objects/fc",
+              "size": 0,
+              "mtime": "2025-11-01T15:52:09+00:00",
+              "children": [
+                {
+                  "name": "c77898384c40a1ea11f5de7355c52f04257077",
+                  "type": "file",
+                  "path": ".git/objects/fc/c77898384c40a1ea11f5de7355c52f04257077",
+                  "size": 446,
+                  "mtime": "2025-11-01T15:52:09+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "info",
+              "type": "dir",
+              "path": ".git/objects/info",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": []
+            },
+            {
+              "name": "pack",
+              "type": "dir",
+              "path": ".git/objects/pack",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": []
+            }
+          ]
+        },
+        {
+          "name": "refs",
+          "type": "dir",
+          "path": ".git/refs",
+          "size": 0,
+          "mtime": "2025-11-01T04:08:09+00:00",
+          "children": [
+            {
+              "name": "heads",
+              "type": "dir",
+              "path": ".git/refs/heads",
+              "size": 0,
+              "mtime": "2025-11-01T18:01:51+00:00",
+              "children": [
+                {
+                  "name": "main",
+                  "type": "file",
+                  "path": ".git/refs/heads/main",
+                  "size": 41,
+                  "mtime": "2025-11-01T18:01:51+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "remotes",
+              "type": "dir",
+              "path": ".git/refs/remotes",
+              "size": 0,
+              "mtime": "2025-11-01T04:08:09+00:00",
+              "children": [
+                {
+                  "name": "origin",
+                  "type": "dir",
+                  "path": ".git/refs/remotes/origin",
+                  "size": 0,
+                  "mtime": "2025-11-01T18:02:00+00:00",
+                  "children": [
+                    {
+                      "name": "main",
+                      "type": "file",
+                      "path": ".git/refs/remotes/origin/main",
+                      "size": 41,
+                      "mtime": "2025-11-01T18:02:00+00:00",
+                      "children": null
+                    }
+                  ]
+                }
+              ]
+            },
+            {
+              "name": "tags",
+              "type": "dir",
+              "path": ".git/refs/tags",
+              "size": 0,
+              "mtime": "2025-11-01T03:59:19+00:00",
+              "children": []
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "name": ".github",
+      "type": "dir",
+      "path": ".github",
+      "size": 0,
+      "mtime": "2025-11-01T14:19:06+00:00",
+      "children": [
+        {
+          "name": ".release-please-manifest.json",
+          "type": "file",
+          "path": ".github/.release-please-manifest.json",
+          "size": 22,
+          "mtime": "2025-11-01T14:18:42+00:00",
+          "children": null
+        },
+        {
+          "name": "release-please-config.json",
+          "type": "file",
+          "path": ".github/release-please-config.json",
+          "size": 275,
+          "mtime": "2025-11-01T14:18:25+00:00",
+          "children": null
+        },
+        {
+          "name": "workflows",
+          "type": "dir",
+          "path": ".github/workflows",
+          "size": 0,
+          "mtime": "2025-11-01T14:19:34+00:00",
+          "children": [
+            {
+              "name": "publish-release.yml",
+              "type": "file",
+              "path": ".github/workflows/publish-release.yml",
+              "size": 1039,
+              "mtime": "2025-11-01T14:21:52+00:00",
+              "children": null
+            },
+            {
+              "name": "release-please.yml",
+              "type": "file",
+              "path": ".github/workflows/release-please.yml",
+              "size": 474,
+              "mtime": "2025-11-01T14:19:17+00:00",
+              "children": null
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "name": ".gitignore",
+      "type": "file",
+      "path": ".gitignore",
+      "size": 1708,
+      "mtime": "2025-10-31T20:49:23+00:00",
+      "children": null
+    },
+    {
+      "name": ".pytest_cache",
+      "type": "dir",
+      "path": ".pytest_cache",
+      "size": 0,
+      "mtime": "2025-11-01T15:47:20+00:00",
+      "children": [
+        {
+          "name": ".gitignore",
+          "type": "file",
+          "path": ".pytest_cache/.gitignore",
+          "size": 39,
+          "mtime": "2025-11-01T15:47:20+00:00",
+          "children": null
+        },
+        {
+          "name": "CACHEDIR.TAG",
+          "type": "file",
+          "path": ".pytest_cache/CACHEDIR.TAG",
+          "size": 191,
+          "mtime": "2025-11-01T15:47:20+00:00",
+          "children": null
+        },
+        {
+          "name": "README.md",
+          "type": "file",
+          "path": ".pytest_cache/README.md",
+          "size": 310,
+          "mtime": "2025-11-01T15:47:20+00:00",
+          "children": null
+        },
+        {
+          "name": "v",
+          "type": "dir",
+          "path": ".pytest_cache/v",
+          "size": 0,
+          "mtime": "2025-11-01T15:47:20+00:00",
+          "children": [
+            {
+              "name": "cache",
+              "type": "dir",
+              "path": ".pytest_cache/v/cache",
+              "size": 0,
+              "mtime": "2025-11-01T15:47:20+00:00",
+              "children": [
+                {
+                  "name": "lastfailed",
+                  "type": "file",
+                  "path": ".pytest_cache/v/cache/lastfailed",
+                  "size": 167,
+                  "mtime": "2025-11-01T17:28:04+00:00",
+                  "children": null
+                },
+                {
+                  "name": "nodeids",
+                  "type": "file",
+                  "path": ".pytest_cache/v/cache/nodeids",
+                  "size": 221,
+                  "mtime": "2025-11-01T18:02:06+00:00",
+                  "children": null
+                }
+              ]
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "name": "API_MAP.md",
+      "type": "file",
+      "path": "API_MAP.md",
+      "size": 10120,
+      "mtime": "2025-11-01T18:17:49+00:00",
+      "children": null
+    },
+    {
+      "name": "README.md",
+      "type": "file",
+      "path": "README.md",
+      "size": 684,
+      "mtime": "2025-10-31T15:12:02+00:00",
+      "children": null
+    },
+    {
+      "name": "__pycache__",
+      "type": "dir",
+      "path": "__pycache__",
+      "size": 0,
+      "mtime": "2025-11-01T17:05:34+00:00",
+      "children": [
+        {
+          "name": "__init__.cpython-312.pyc",
+          "type": "file",
+          "path": "__pycache__/__init__.cpython-312.pyc",
+          "size": 366,
+          "mtime": "2025-10-31T15:26:55+00:00",
+          "children": null
+        },
+        {
+          "name": "compare.cpython-312.pyc",
+          "type": "file",
+          "path": "__pycache__/compare.cpython-312.pyc",
+          "size": 2395,
+          "mtime": "2025-10-31T15:26:55+00:00",
+          "children": null
+        },
+        {
+          "name": "config.cpython-312.pyc",
+          "type": "file",
+          "path": "__pycache__/config.cpython-312.pyc",
+          "size": 12070,
+          "mtime": "2025-11-01T17:05:34+00:00",
+          "children": null
+        },
+        {
+          "name": "io.cpython-312.pyc",
+          "type": "file",
+          "path": "__pycache__/io.cpython-312.pyc",
+          "size": 954,
+          "mtime": "2025-10-31T15:26:55+00:00",
+          "children": null
+        },
+        {
+          "name": "resample.cpython-312.pyc",
+          "type": "file",
+          "path": "__pycache__/resample.cpython-312.pyc",
+          "size": 9348,
+          "mtime": "2025-10-31T17:10:02+00:00",
+          "children": null
+        },
+        {
+          "name": "run_btc_pipeline.cpython-312.pyc",
+          "type": "file",
+          "path": "__pycache__/run_btc_pipeline.cpython-312.pyc",
+          "size": 8603,
+          "mtime": "2025-10-31T18:06:08+00:00",
+          "children": null
+        }
+      ]
+    },
+    {
+      "name": "changelog.md",
+      "type": "file",
+      "path": "changelog.md",
+      "size": 1933,
+      "mtime": "2025-11-01T14:13:33+00:00",
+      "children": null
+    },
+    {
+      "name": "config.py",
+      "type": "file",
+      "path": "config.py",
+      "size": 8356,
+      "mtime": "2025-11-01T17:51:34+00:00",
+      "children": null
+    },
+    {
+      "name": "configs",
+      "type": "dir",
+      "path": "configs",
+      "size": 0,
+      "mtime": "2025-11-01T00:51:51+00:00",
+      "children": [
+        {
+          "name": "default.yaml",
+          "type": "file",
+          "path": "configs/default.yaml",
+          "size": 4070,
+          "mtime": "2025-11-01T17:49:09+00:00",
+          "children": null
+        }
+      ]
+    },
+    {
+      "name": "data",
+      "type": "dir",
+      "path": "data",
+      "size": 0,
+      "mtime": "2025-11-01T17:09:42+00:00",
+      "children": [
+        {
+          "name": "Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv",
+          "type": "file",
+          "path": "data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap.csv",
+          "size": 746738,
+          "mtime": "2025-10-31T16:42:49+00:00",
+          "children": null
+        },
+        {
+          "name": "Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap_edit.csv",
+          "type": "file",
+          "path": "data/Bitcoin_01_1_2016-10_26_2025_historical_data_coinmarketcap_edit.csv",
+          "size": 763278,
+          "mtime": "2025-10-31T16:35:40+00:00",
+          "children": null
+        },
+        {
+          "name": "btcusd.csv",
+          "type": "file",
+          "path": "data/btcusd.csv",
+          "size": 38,
+          "mtime": "2025-11-01T17:09:42+00:00",
+          "children": null
+        },
+        {
+          "name": "ta_lab2_companion.xlsx",
+          "type": "file",
+          "path": "data/ta_lab2_companion.xlsx",
+          "size": 17696,
+          "mtime": "2025-10-31T20:01:53+00:00",
+          "children": null
+        }
+      ]
+    },
+    {
+      "name": "diff.txt",
+      "type": "file",
+      "path": "diff.txt",
+      "size": 29184,
+      "mtime": "2025-11-01T14:10:55+00:00",
+      "children": null
+    },
+    {
+      "name": "full_diff.patch",
+      "type": "file",
+      "path": "full_diff.patch",
+      "size": 92758,
+      "mtime": "2025-11-01T15:13:50+00:00",
+      "children": null
+    },
+    {
+      "name": "generate_structure_docs.py",
+      "type": "file",
+      "path": "generate_structure_docs.py",
+      "size": 7557,
+      "mtime": "2025-10-31T20:46:36+00:00",
+      "children": null
+    },
+    {
+      "name": "github",
+      "type": "dir",
+      "path": "github",
+      "size": 0,
+      "mtime": "2025-11-01T00:53:50+00:00",
+      "children": [
+        {
+          "name": "workflows",
+          "type": "dir",
+          "path": "github/workflows",
+          "size": 0,
+          "mtime": "2025-11-01T00:54:16+00:00",
+          "children": [
+            {
+              "name": "ci.yml",
+              "type": "file",
+              "path": "github/workflows/ci.yml",
+              "size": 512,
+              "mtime": "2025-11-01T00:54:16+00:00",
+              "children": null
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "name": "out",
+      "type": "dir",
+      "path": "out",
+      "size": 0,
+      "mtime": "2025-10-31T20:26:48+00:00",
+      "children": [
+        {
+          "name": "alignment.parquet",
+          "type": "file",
+          "path": "out/alignment.parquet",
+          "size": 86964,
+          "mtime": "2025-10-31T20:26:48+00:00",
+          "children": null
+        },
+        {
+          "name": "daily_en.parquet",
+          "type": "file",
+          "path": "out/daily_en.parquet",
+          "size": 755135,
+          "mtime": "2025-10-31T20:26:48+00:00",
+          "children": null
+        },
+        {
+          "name": "daily_regimes.parquet",
+          "type": "file",
+          "path": "out/daily_regimes.parquet",
+          "size": 797842,
+          "mtime": "2025-10-31T20:26:48+00:00",
+          "children": null
+        },
+        {
+          "name": "monthly_en.parquet",
+          "type": "file",
+          "path": "out/monthly_en.parquet",
+          "size": 37593,
+          "mtime": "2025-10-31T20:26:48+00:00",
+          "children": null
+        },
+        {
+          "name": "regime_stats.csv",
+          "type": "file",
+          "path": "out/regime_stats.csv",
+          "size": 34367,
+          "mtime": "2025-10-31T20:26:48+00:00",
+          "children": null
+        },
+        {
+          "name": "weekly_en.parquet",
+          "type": "file",
+          "path": "out/weekly_en.parquet",
+          "size": 118865,
+          "mtime": "2025-10-31T20:26:48+00:00",
+          "children": null
+        }
+      ]
+    },
+    {
+      "name": "pyproject.toml",
+      "type": "file",
+      "path": "pyproject.toml",
+      "size": 1105,
+      "mtime": "2025-11-01T15:46:49+00:00",
+      "children": null
+    },
+    {
+      "name": "run_btc.py",
+      "type": "file",
+      "path": "run_btc.py",
+      "size": 814,
+      "mtime": "2025-10-31T20:26:47+00:00",
+      "children": null
+    },
+    {
+      "name": "src",
+      "type": "dir",
+      "path": "src",
+      "size": 0,
+      "mtime": "2025-10-31T23:58:32+00:00",
+      "children": [
+        {
+          "name": "ta_lab2",
+          "type": "dir",
+          "path": "src/ta_lab2",
+          "size": 0,
+          "mtime": "2025-11-01T16:05:09+00:00",
+          "children": [
+            {
+              "name": "__init__.py",
+              "type": "file",
+              "path": "src/ta_lab2/__init__.py",
+              "size": 1760,
+              "mtime": "2025-11-01T16:38:15+00:00",
+              "children": null
+            },
+            {
+              "name": "__pycache__",
+              "type": "dir",
+              "path": "src/ta_lab2/__pycache__",
+              "size": 0,
+              "mtime": "2025-11-01T16:38:59+00:00",
+              "children": [
+                {
+                  "name": "__init__.cpython-312.pyc",
+                  "type": "file",
+                  "path": "src/ta_lab2/__pycache__/__init__.cpython-312.pyc",
+                  "size": 1536,
+                  "mtime": "2025-11-01T16:38:59+00:00",
+                  "children": null
+                },
+                {
+                  "name": "cli.cpython-312.pyc",
+                  "type": "file",
+                  "path": "src/ta_lab2/__pycache__/cli.cpython-312.pyc",
+                  "size": 1527,
+                  "mtime": "2025-11-01T04:42:44+00:00",
+                  "children": null
+                },
+                {
+                  "name": "compare.cpython-312.pyc",
+                  "type": "file",
+                  "path": "src/ta_lab2/__pycache__/compare.cpython-312.pyc",
+                  "size": 2407,
+                  "mtime": "2025-10-31T20:36:30+00:00",
+                  "children": null
+                },
+                {
+                  "name": "config.cpython-312.pyc",
+                  "type": "file",
+                  "path": "src/ta_lab2/__pycache__/config.cpython-312.pyc",
+                  "size": 1179,
+                  "mtime": "2025-11-01T16:13:49+00:00",
+                  "children": null
+                },
+                {
+                  "name": "io.cpython-312.pyc",
+                  "type": "file",
+                  "path": "src/ta_lab2/__pycache__/io.cpython-312.pyc",
+                  "size": 966,
+                  "mtime": "2025-10-31T20:36:30+00:00",
+                  "children": null
+                },
+                {
+                  "name": "resample.cpython-312.pyc",
+                  "type": "file",
+                  "path": "src/ta_lab2/__pycache__/resample.cpython-312.pyc",
+                  "size": 9360,
+                  "mtime": "2025-10-31T20:26:47+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "cli.py",
+              "type": "file",
+              "path": "src/ta_lab2/cli.py",
+              "size": 1147,
+              "mtime": "2025-11-01T04:33:34+00:00",
+              "children": null
+            },
+            {
+              "name": "compare.py",
+              "type": "file",
+              "path": "src/ta_lab2/compare.py",
+              "size": 1638,
+              "mtime": "2025-10-31T15:12:02+00:00",
+              "children": null
+            },
+            {
+              "name": "config.py",
+              "type": "file",
+              "path": "src/ta_lab2/config.py",
+              "size": 981,
+              "mtime": "2025-11-01T16:08:26+00:00",
+              "children": null
+            },
+            {
+              "name": "features",
+              "type": "dir",
+              "path": "src/ta_lab2/features",
+              "size": 0,
+              "mtime": "2025-11-01T15:51:17+00:00",
+              "children": [
+                {
+                  "name": "__init__.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/__init__.py",
+                  "size": 1218,
+                  "mtime": "2025-11-01T18:00:20+00:00",
+                  "children": null
+                },
+                {
+                  "name": "__pycache__",
+                  "type": "dir",
+                  "path": "src/ta_lab2/features/__pycache__",
+                  "size": 0,
+                  "mtime": "2025-11-01T18:02:06+00:00",
+                  "children": [
+                    {
+                      "name": "__init__.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/__init__.cpython-312.pyc",
+                      "size": 999,
+                      "mtime": "2025-11-01T18:02:06+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "calendar.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/calendar.cpython-312.pyc",
+                      "size": 13492,
+                      "mtime": "2025-11-01T18:02:06+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "correlation.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/correlation.cpython-312.pyc",
+                      "size": 5529,
+                      "mtime": "2025-11-01T15:47:19+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "ema.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/ema.cpython-312.pyc",
+                      "size": 7862,
+                      "mtime": "2025-11-01T17:36:08+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "indicators.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/indicators.cpython-312.pyc",
+                      "size": 15425,
+                      "mtime": "2025-11-01T17:13:02+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "returns.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/returns.cpython-312.pyc",
+                      "size": 5678,
+                      "mtime": "2025-11-01T17:22:53+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "segments.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/segments.cpython-312.pyc",
+                      "size": 3428,
+                      "mtime": "2025-11-01T16:38:59+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "trend.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/trend.cpython-312.pyc",
+                      "size": 3759,
+                      "mtime": "2025-11-01T15:52:22+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "vol.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/features/__pycache__/vol.cpython-312.pyc",
+                      "size": 10873,
+                      "mtime": "2025-11-01T15:47:19+00:00",
+                      "children": null
+                    }
+                  ]
+                },
+                {
+                  "name": "calendar.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/calendar.py",
+                  "size": 8773,
+                  "mtime": "2025-11-01T18:16:08+00:00",
+                  "children": null
+                },
+                {
+                  "name": "correlation.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/correlation.py",
+                  "size": 2450,
+                  "mtime": "2025-11-01T04:51:35+00:00",
+                  "children": null
+                },
+                {
+                  "name": "ema.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/ema.py",
+                  "size": 7535,
+                  "mtime": "2025-11-01T17:35:33+00:00",
+                  "children": null
+                },
+                {
+                  "name": "indicators.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/indicators.py",
+                  "size": 11008,
+                  "mtime": "2025-11-01T17:12:36+00:00",
+                  "children": null
+                },
+                {
+                  "name": "returns.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/returns.py",
+                  "size": 6044,
+                  "mtime": "2025-11-01T17:22:24+00:00",
+                  "children": null
+                },
+                {
+                  "name": "segments.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/segments.py",
+                  "size": 2341,
+                  "mtime": "2025-11-01T16:34:18+00:00",
+                  "children": null
+                },
+                {
+                  "name": "trend.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/trend.py",
+                  "size": 2541,
+                  "mtime": "2025-11-01T15:51:43+00:00",
+                  "children": null
+                },
+                {
+                  "name": "vol.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/features/vol.py",
+                  "size": 8772,
+                  "mtime": "2025-11-01T15:03:11+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "io.py",
+              "type": "file",
+              "path": "src/ta_lab2/io.py",
+              "size": 412,
+              "mtime": "2025-10-31T15:12:02+00:00",
+              "children": null
+            },
+            {
+              "name": "logging_setup.py",
+              "type": "file",
+              "path": "src/ta_lab2/logging_setup.py",
+              "size": 262,
+              "mtime": "2025-11-01T00:21:28+00:00",
+              "children": null
+            },
+            {
+              "name": "pipelines",
+              "type": "dir",
+              "path": "src/ta_lab2/pipelines",
+              "size": 0,
+              "mtime": "2025-10-31T20:26:47+00:00",
+              "children": [
+                {
+                  "name": "__init__.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/pipelines/__init__.py",
+                  "size": 109,
+                  "mtime": "2025-10-31T20:05:01+00:00",
+                  "children": null
+                },
+                {
+                  "name": "__pycache__",
+                  "type": "dir",
+                  "path": "src/ta_lab2/pipelines/__pycache__",
+                  "size": 0,
+                  "mtime": "2025-11-01T15:52:23+00:00",
+                  "children": [
+                    {
+                      "name": "__init__.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/pipelines/__pycache__/__init__.cpython-312.pyc",
+                      "size": 233,
+                      "mtime": "2025-10-31T20:26:47+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "btc_pipeline.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/pipelines/__pycache__/btc_pipeline.cpython-312.pyc",
+                      "size": 6286,
+                      "mtime": "2025-11-01T15:52:23+00:00",
+                      "children": null
+                    }
+                  ]
+                },
+                {
+                  "name": "btc_pipeline.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/pipelines/btc_pipeline.py",
+                  "size": 10816,
+                  "mtime": "2025-11-01T17:47:06+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "regimes",
+              "type": "dir",
+              "path": "src/ta_lab2/regimes",
+              "size": 0,
+              "mtime": "2025-11-01T16:34:37+00:00",
+              "children": [
+                {
+                  "name": "__init__.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/regimes/__init__.py",
+                  "size": 905,
+                  "mtime": "2025-11-01T16:37:22+00:00",
+                  "children": null
+                },
+                {
+                  "name": "__pycache__",
+                  "type": "dir",
+                  "path": "src/ta_lab2/regimes/__pycache__",
+                  "size": 0,
+                  "mtime": "2025-11-01T16:38:59+00:00",
+                  "children": [
+                    {
+                      "name": "__init__.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/regimes/__pycache__/__init__.cpython-312.pyc",
+                      "size": 739,
+                      "mtime": "2025-11-01T16:38:59+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "comovement.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/regimes/__pycache__/comovement.cpython-312.pyc",
+                      "size": 11930,
+                      "mtime": "2025-11-01T16:24:59+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "flips.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/regimes/__pycache__/flips.cpython-312.pyc",
+                      "size": 5605,
+                      "mtime": "2025-10-31T18:17:57+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "run_btc_pipeline.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/regimes/__pycache__/run_btc_pipeline.cpython-312.pyc",
+                      "size": 1193,
+                      "mtime": "2025-11-01T04:42:33+00:00",
+                      "children": null
+                    },
+                    {
+                      "name": "segments.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/regimes/__pycache__/segments.cpython-312.pyc",
+                      "size": 487,
+                      "mtime": "2025-11-01T16:38:59+00:00",
+                      "children": null
+                    }
+                  ]
+                },
+                {
+                  "name": "comovement.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/regimes/comovement.py",
+                  "size": 8180,
+                  "mtime": "2025-11-01T16:24:31+00:00",
+                  "children": null
+                },
+                {
+                  "name": "flips.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/regimes/flips.py",
+                  "size": 3510,
+                  "mtime": "2025-10-31T18:17:38+00:00",
+                  "children": null
+                },
+                {
+                  "name": "old_run_btc_pipeline.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/regimes/old_run_btc_pipeline.py",
+                  "size": 7769,
+                  "mtime": "2025-10-31T18:42:00+00:00",
+                  "children": null
+                },
+                {
+                  "name": "run_btc_pipeline.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/regimes/run_btc_pipeline.py",
+                  "size": 1233,
+                  "mtime": "2025-11-01T04:42:19+00:00",
+                  "children": null
+                },
+                {
+                  "name": "segments.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/regimes/segments.py",
+                  "size": 336,
+                  "mtime": "2025-11-01T16:34:37+00:00",
+                  "children": null
+                }
+              ]
+            },
+            {
+              "name": "resample.py",
+              "type": "file",
+              "path": "src/ta_lab2/resample.py",
+              "size": 7466,
+              "mtime": "2025-10-31T17:02:34+00:00",
+              "children": null
+            },
+            {
+              "name": "viz",
+              "type": "dir",
+              "path": "src/ta_lab2/viz",
+              "size": 0,
+              "mtime": "2025-11-01T15:52:22+00:00",
+              "children": [
+                {
+                  "name": "__pycache__",
+                  "type": "dir",
+                  "path": "src/ta_lab2/viz/__pycache__",
+                  "size": 0,
+                  "mtime": "2025-11-01T15:52:22+00:00",
+                  "children": [
+                    {
+                      "name": "all_plots.cpython-312.pyc",
+                      "type": "file",
+                      "path": "src/ta_lab2/viz/__pycache__/all_plots.cpython-312.pyc",
+                      "size": 11425,
+                      "mtime": "2025-11-01T15:52:22+00:00",
+                      "children": null
+                    }
+                  ]
+                },
+                {
+                  "name": "all_plots.py",
+                  "type": "file",
+                  "path": "src/ta_lab2/viz/all_plots.py",
+                  "size": 7585,
+                  "mtime": "2025-11-01T15:06:15+00:00",
+                  "children": null
+                }
+              ]
+            }
+          ]
+        },
+        {
+          "name": "ta_lab2.egg-info",
+          "type": "dir",
+          "path": "src/ta_lab2.egg-info",
+          "size": 0,
+          "mtime": "2025-11-01T04:46:59+00:00",
+          "children": [
+            {
+              "name": "PKG-INFO",
+              "type": "file",
+              "path": "src/ta_lab2.egg-info/PKG-INFO",
+              "size": 1148,
+              "mtime": "2025-11-01T04:46:59+00:00",
+              "children": null
+            },
+            {
+              "name": "SOURCES.txt",
+              "type": "file",
+              "path": "src/ta_lab2.egg-info/SOURCES.txt",
+              "size": 864,
+              "mtime": "2025-11-01T04:46:59+00:00",
+              "children": null
+            },
+            {
+              "name": "dependency_links.txt",
+              "type": "file",
+              "path": "src/ta_lab2.egg-info/dependency_links.txt",
+              "size": 1,
+              "mtime": "2025-11-01T04:46:59+00:00",
+              "children": null
+            },
+            {
+              "name": "entry_points.txt",
+              "type": "file",
+              "path": "src/ta_lab2.egg-info/entry_points.txt",
+              "size": 45,
+              "mtime": "2025-11-01T04:46:59+00:00",
+              "children": null
+            },
+            {
+              "name": "requires.txt",
+              "type": "file",
+              "path": "src/ta_lab2.egg-info/requires.txt",
+              "size": 66,
+              "mtime": "2025-11-01T04:46:59+00:00",
+              "children": null
+            },
+            {
+              "name": "top_level.txt",
+              "type": "file",
+              "path": "src/ta_lab2.egg-info/top_level.txt",
+              "size": 15,
+              "mtime": "2025-11-01T04:46:59+00:00",
+              "children": null
+            }
+          ]
+        }
+      ]
+    },
+    {
+      "name": "src_structure.json",
+      "type": "file",
+      "path": "src_structure.json",
+      "size": 5201,
+      "mtime": "2025-11-01T18:17:49+00:00",
+      "children": null
+    },
+    {
+      "name": "structure.md",
+      "type": "file",
+      "path": "structure.md",
+      "size": 24265,
+      "mtime": "2025-11-01T18:21:42+00:00",
+      "children": null
+    },
+    {
+      "name": "structure.txt",
+      "type": "file",
+      "path": "structure.txt",
+      "size": 24251,
+      "mtime": "2025-11-01T18:21:42+00:00",
+      "children": null
+    },
+    {
+      "name": "tests",
+      "type": "dir",
+      "path": "tests",
+      "size": 0,
+      "mtime": "2025-11-01T15:47:19+00:00",
+      "children": [
+        {
+          "name": ".benchmarks",
+          "type": "dir",
+          "path": "tests/.benchmarks",
+          "size": 0,
+          "mtime": "2025-11-01T15:47:19+00:00",
+          "children": []
+        },
+        {
+          "name": "__pycache__",
+          "type": "dir",
+          "path": "tests/__pycache__",
+          "size": 0,
+          "mtime": "2025-11-01T15:47:20+00:00",
+          "children": [
+            {
+              "name": "conftest.cpython-312-pytest-8.4.2.pyc",
+              "type": "file",
+              "path": "tests/__pycache__/conftest.cpython-312-pytest-8.4.2.pyc",
+              "size": 1018,
+              "mtime": "2025-11-01T15:47:16+00:00",
+              "children": null
+            },
+            {
+              "name": "test_calendar.cpython-312-pytest-8.4.2.pyc",
+              "type": "file",
+              "path": "tests/__pycache__/test_calendar.cpython-312-pytest-8.4.2.pyc",
+              "size": 1885,
+              "mtime": "2025-11-01T15:47:19+00:00",
+              "children": null
+            },
+            {
+              "name": "test_cli_paths.cpython-312-pytest-8.4.2.pyc",
+              "type": "file",
+              "path": "tests/__pycache__/test_cli_paths.cpython-312-pytest-8.4.2.pyc",
+              "size": 1757,
+              "mtime": "2025-11-01T15:47:20+00:00",
+              "children": null
+            },
+            {
+              "name": "test_features_ema.cpython-312-pytest-8.4.2.pyc",
+              "type": "file",
+              "path": "tests/__pycache__/test_features_ema.cpython-312-pytest-8.4.2.pyc",
+              "size": 2307,
+              "mtime": "2025-11-01T15:47:20+00:00",
+              "children": null
+            },
+            {
+              "name": "test_pipeline.cpython-312-pytest-8.4.2.pyc",
+              "type": "file",
+              "path": "tests/__pycache__/test_pipeline.cpython-312-pytest-8.4.2.pyc",
+              "size": 1539,
+              "mtime": "2025-11-01T15:47:20+00:00",
+              "children": null
+            }
+          ]
+        },
+        {
+          "name": "conftest.py",
+          "type": "file",
+          "path": "tests/conftest.py",
+          "size": 515,
+          "mtime": "2025-11-01T00:53:04+00:00",
+          "children": null
+        },
+        {
+          "name": "test_calendar.py",
+          "type": "file",
+          "path": "tests/test_calendar.py",
+          "size": 386,
+          "mtime": "2025-11-01T15:23:15+00:00",
+          "children": null
+        },
+        {
+          "name": "test_cli_paths.py",
+          "type": "file",
+          "path": "tests/test_cli_paths.py",
+          "size": 283,
+          "mtime": "2025-11-01T00:19:51+00:00",
+          "children": null
+        },
+        {
+          "name": "test_features_ema.py",
+          "type": "file",
+          "path": "tests/test_features_ema.py",
+          "size": 293,
+          "mtime": "2025-11-01T00:20:39+00:00",
+          "children": null
+        },
+        {
+          "name": "test_pipeline.py",
+          "type": "file",
+          "path": "tests/test_pipeline.py",
+          "size": 469,
+          "mtime": "2025-11-01T15:23:48+00:00",
+          "children": null
+        }
+      ]
+    }
+  ]
+}
\ No newline at end of file
diff --git a/tests/test_calendar.py b/tests/test_calendar.py
new file mode 100644
index 0000000..4688f6e
--- /dev/null
+++ b/tests/test_calendar.py
@@ -0,0 +1,7 @@
+# tests/test_calendar.py
+import pandas as pd
+from ta_lab2.features.calendar import expand_datetime_features_inplace
+def test_calendar_expands():
+    df = pd.DataFrame({"ts":["2025-01-01T00:00:00Z","2025-01-02T00:00:00Z"]})
+    expand_datetime_features_inplace(df, "ts", prefix="ts", add_moon=False)
+    assert {"ts_quarter","ts_week_of_year","ts_day_of_year"} <= set(df.columns)
diff --git a/tests/test_pipeline.py b/tests/test_pipeline.py
new file mode 100644
index 0000000..4d7089c
--- /dev/null
+++ b/tests/test_pipeline.py
@@ -0,0 +1,11 @@
+# tests/test_pipeline.py
+import pandas as pd
+from ta_lab2.pipelines.btc_pipeline import run_btc_pipeline
+def test_pipeline_minimal(tmp_path):
+    p = tmp_path / "btc.csv"
+    pd.DataFrame({
+        "timestamp":["2025-01-01T00:00:00Z","2025-01-02T00:00:00Z"],
+        "open":[1,1.1],"high":[1.1,1.2],"low":[0.9,1.0],"close":[1.05,1.15],"volume":[10,12]
+    }).to_csv(p, index=False)
+    res = run_btc_pipeline(str(p))
+    assert res["summary"]["n_rows"] == 2
