---
phase: 16-repository-cleanup
plan: 06
type: execute
wave: 3
depends_on: [16-01, 16-02, 16-03, 16-04, 16-05]
files_modified: []
autonomous: true

must_haves:
  truths:
    - "Memory updated with moved_to relationships for all archived files"
    - "Memory updated with moved_to relationships for organized docs"
    - "Phase 16 completion snapshot created in memory"
    - "Memory queries can answer 'where did file X move to?'"
  artifacts:
    - path: ".planning/phases/16-repository-cleanup/16-06-SUMMARY.md"
      provides: "Phase 16 memory update summary"
      contains: "memories created"
  key_links:
    - from: "archived files"
      to: "memory entries"
      via: "moved_to relationships"
      pattern: "relationship.*moved_to"
---

<objective>
Update memory with all file movements and create phase 16 completion snapshot

Purpose: Track all Phase 16 file movements in memory per MEMO-13 and MEMO-14 requirements
Output: Memory relationships for all archived/moved files, phase snapshot for auditing
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-repository-cleanup/16-CONTEXT.md

# Memory update patterns from Phase 14
@.planning/phases/14-tools-integration/14-10-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create memory entries for archived temp files and scripts</name>
  <files>None (memory operations)</files>
  <action>
Create memory entries for all files archived in Plans 01 and 02:

**Load manifests:**
```python
import json
from pathlib import Path

temp_manifest = json.load(open('.archive/temp/manifest.json'))
scripts_manifest = json.load(open('.archive/scripts/manifest.json'))
refactored_manifest = json.load(open('.archive/refactored/manifest.json'))
originals_manifest = json.load(open('.archive/originals/manifest.json'))
```

**For each archived file, create memory with moved_to relationship:**

Memory format (following Phase 14 patterns):
```python
from mem0 import MemoryClient
from dotenv import load_dotenv
import os

# Load API key
load_dotenv('openai_config.env')
client = MemoryClient(api_key=os.environ['OPENAI_API_KEY'])

# Archive memory template
def create_archive_memory(original_path: str, archive_path: str, category: str, reason: str):
    memory_text = f"""File archived during Phase 16 repository cleanup:
- Original path: {original_path}
- Archive path: {archive_path}
- Category: {category}
- Reason: {reason}
- Relationship: moved_to (archived)
- Phase: 16-repository-cleanup
"""
    client.add(
        memory_text,
        user_id="ta_lab2",
        metadata={
            "type": "file_archive",
            "relationship": "moved_to",
            "original_path": original_path,
            "archive_path": archive_path,
            "category": category,
            "phase": "16",
            "timestamp": "2026-02-03",
        },
        infer=False  # Disable LLM conflict detection for batch performance
    )
```

**Categories to process:**
1. temp/ archives (from Plan 01 Task 1) - CSV, text, patch files
2. scripts/ archives (from Plan 01 Task 2) - Loose Python scripts
3. refactored/ archives (from Plan 02) - Refactored file decisions
4. originals/ archives (from Plan 02) - *.original backup files

Log count of memories created for each category.
  </action>
  <verify>
- Memory search for "Phase 16 repository cleanup" returns results
- Memory search for specific archived file returns moved_to relationship
- Memory count logged for verification
  </verify>
  <done>
Memory entries created for all archived temp files and scripts with moved_to relationships.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create memory entries for organized documentation</name>
  <files>None (memory operations)</files>
  <action>
Create memory entries for documentation files moved in Plan 03:

**Moved files to track:**
- API_MAP.md -> docs/architecture/api-map.md
- ARCHITECTURE.md -> docs/architecture/architecture.md
- structure.md -> docs/architecture/structure.md
- lab2_analysis_gemini.md -> docs/analysis/lab2-analysis-gemini.md
- EMA_FEATURE_MIGRATION_PLAN.md -> docs/features/emas/ema-feature-migration-plan.md
- EMA_MIGRATION_SESSION_SUMMARY.md -> docs/features/emas/ema-migration-session-summary.md
- CI_DEPENDENCY_FIXES.md -> docs/guides/ci-dependency-fixes.md

**Also track archived conversion artifacts:**
- docs/conversion_checkpoint.json -> .archive/documentation/2026-02-03/conversion/
- docs/conversion_errors.json -> .archive/documentation/2026-02-03/conversion/
- docs/conversion_notes.md -> .archive/documentation/2026-02-03/conversion/

**Memory format for doc moves:**
```python
def create_doc_move_memory(original_path: str, new_path: str, doc_type: str):
    memory_text = f"""Documentation organized during Phase 16 repository cleanup:
- Original path: {original_path}
- New path: {new_path}
- Document type: {doc_type}
- Relationship: moved_to (reorganized)
- Phase: 16-repository-cleanup
"""
    client.add(
        memory_text,
        user_id="ta_lab2",
        metadata={
            "type": "doc_reorganization",
            "relationship": "moved_to",
            "original_path": original_path,
            "new_path": new_path,
            "doc_type": doc_type,
            "phase": "16",
            "timestamp": "2026-02-03",
        },
        infer=False
    )
```

Log count of doc move memories created.
  </action>
  <verify>
- Memory search for "API_MAP.md" returns moved_to relationship with new location
- Memory search for "docs reorganization" returns Phase 16 entries
  </verify>
  <done>
Memory entries created for all documentation file movements with moved_to relationships.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create Phase 16 completion snapshot</name>
  <files>None (memory operations)</files>
  <action>
Create Phase 16 completion snapshot memory:

**Gather statistics from all manifests:**
```python
import json
from pathlib import Path

# Count archived files by category
temp_count = len(json.load(open('.archive/temp/manifest.json')).get('files', []))
scripts_count = len(json.load(open('.archive/scripts/manifest.json')).get('files', []))
refactored_count = len(json.load(open('.archive/refactored/manifest.json')).get('files', []))
originals_count = len(json.load(open('.archive/originals/manifest.json')).get('files', []))
duplicates_count = len(json.load(open('.archive/duplicates/manifest.json')).get('files', []))

# Load duplicate and similarity reports
dup_report = json.load(open('.planning/phases/16-repository-cleanup/duplicates_report.json'))
sim_report = json.load(open('.planning/phases/16-repository-cleanup/similarity_report.json'))

total_archived = temp_count + scripts_count + refactored_count + originals_count + duplicates_count
```

**Create snapshot memory:**
```python
snapshot_text = f"""Phase 16 Repository Cleanup completed:

**Archived Files:**
- Temp files: {temp_count}
- Scripts: {scripts_count}
- Refactored decisions: {refactored_count}
- Original backups: {originals_count}
- Duplicates: {duplicates_count}
- Total archived: {total_archived}

**Duplicate Detection:**
- Duplicate groups found: {dup_report['summary']['total_duplicate_groups']}
- Wasted space eliminated: {dup_report['summary']['total_wasted_bytes']:,} bytes

**Similarity Analysis:**
- Near-exact function pairs (95%+): {sim_report['summary']['near_exact']}
- Similar function pairs (85-95%): {sim_report['summary']['similar']}
- Related function pairs (70-85%): {sim_report['summary']['related']}

**Requirements Satisfied:**
- CLEAN-01: Root directory cleaned (temp files, scripts archived)
- CLEAN-02: Loose .md files organized into docs/ structure
- CLEAN-03: Exact duplicates identified and archived
- CLEAN-04: Similar functions flagged for manual review
- MEMO-13: File-level memory updates with moved_to relationships
- MEMO-14: Phase snapshot created

**Root Directory Status:**
- Only essential files remain (README, pyproject.toml, configs)
- No loose Python scripts
- No temp files (*.csv, *.txt, *.patch)
- No *_refactored.py or *.original files

Phase: 16-repository-cleanup
Completed: 2026-02-03
Plans: 6 (01-06)
"""

client.add(
    snapshot_text,
    user_id="ta_lab2",
    metadata={
        "type": "phase_snapshot",
        "phase": "16",
        "phase_name": "repository-cleanup",
        "total_archived": total_archived,
        "duplicate_groups": dup_report['summary']['total_duplicate_groups'],
        "similar_functions": sim_report['summary']['total_matches'],
        "requirements_satisfied": ["CLEAN-01", "CLEAN-02", "CLEAN-03", "CLEAN-04", "MEMO-13", "MEMO-14"],
        "timestamp": "2026-02-03",
    },
    infer=False
)
```
  </action>
  <verify>
- Memory search for "Phase 16 repository cleanup completed" returns snapshot
- Memory search for "CLEAN-01" returns Phase 16 reference
- Snapshot contains all category counts
  </verify>
  <done>
Phase 16 completion snapshot created in memory with comprehensive statistics and requirements satisfied.
  </done>
</task>

</tasks>

<verification>
Phase 16 Plan 06 verification:

1. Archive memories queryable:
   ```python
   from mem0 import MemoryClient
   from dotenv import load_dotenv
   import os

   load_dotenv('openai_config.env')
   client = MemoryClient(api_key=os.environ['OPENAI_API_KEY'])

   # Test archive query
   results = client.search("Phase 16 temp files archived", user_id="ta_lab2")
   print(f"Archive memories found: {len(results)}")
   ```

2. Doc reorganization memories queryable:
   ```python
   results = client.search("API_MAP.md moved to", user_id="ta_lab2")
   print(f"Doc move memories found: {len(results)}")
   ```

3. Phase snapshot queryable:
   ```python
   results = client.search("Phase 16 repository cleanup completed", user_id="ta_lab2")
   print(f"Phase snapshot found: {len(results) > 0}")
   ```
</verification>

<success_criteria>
- All archived files have corresponding memory entries with moved_to relationships
- All doc reorganizations tracked in memory
- Phase 16 completion snapshot exists with:
  - Archive counts by category
  - Duplicate detection statistics
  - Similarity analysis statistics
  - Requirements satisfied list
- Memory queries successfully return:
  - "Where did file X move to?" - Returns archive/new location
  - "What was archived in Phase 16?" - Returns category breakdown
  - "Phase 16 cleanup summary" - Returns snapshot
</success_criteria>

<output>
After completion, create `.planning/phases/16-repository-cleanup/16-06-SUMMARY.md`
</output>
