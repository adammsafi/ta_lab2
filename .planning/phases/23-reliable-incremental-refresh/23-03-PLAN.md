---
phase: 23-reliable-incremental-refresh
plan: 03
type: execute
wave: 2
depends_on: []
files_modified:
  - Makefile
  - src/ta_lab2/scripts/emas/logging_config.py
  - src/ta_lab2/notifications/telegram.py
autonomous: true

must_haves:
  truths:
    - "User can run make bars, make emas, make daily-refresh for convenience"
    - "Logs are written to .logs/refresh-YYYY-MM-DD.log for audit trail"
    - "Telegram alerts fire on critical errors (database connection, validation failures)"
  artifacts:
    - path: "Makefile"
      provides: "Convenience targets for daily refresh workflow"
      contains: "daily-refresh"
  key_links:
    - from: "Makefile"
      to: "run_daily_refresh.py"
      via: "make target"
      pattern: "daily-refresh:.*run_daily_refresh"
    - from: "logging_config.py"
      to: ".logs/"
      via: "log file creation"
      pattern: "refresh-.*\\.log"
---

<objective>
Create Makefile convenience layer and enhance logging infrastructure

Purpose: Users need easy-to-remember commands for common operations (make daily-refresh) and persistent log files for audit trail. Telegram alerting should extend to critical errors beyond just validation.

Output: Makefile with convenience targets, enhanced logging with daily log files, and extended Telegram alerting.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Source files to reference
@src/ta_lab2/scripts/emas/logging_config.py
@src/ta_lab2/notifications/telegram.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Makefile with refresh targets</name>
  <files>Makefile</files>
  <action>
Create or update Makefile with convenience targets for daily refresh workflow:

```makefile
# Data Refresh Targets
# ====================

.PHONY: bars emas daily-refresh validate dry-run clean-logs

# Run all bar builders
bars:
	python src/ta_lab2/scripts/bars/run_all_bar_builders.py --ids all --verbose

# Run all EMA refreshers
emas:
	python src/ta_lab2/scripts/emas/run_all_ema_refreshes.py --verbose

# Full daily refresh (bars + EMAs)
daily-refresh:
	python src/ta_lab2/scripts/run_daily_refresh.py --all --verbose \
		--log-file .logs/refresh-$$(date +%Y-%m-%d).log

# Run with validation and alerts
daily-refresh-validate:
	python src/ta_lab2/scripts/run_daily_refresh.py --all --verbose --validate \
		--alert-on-error --log-file .logs/refresh-$$(date +%Y-%m-%d).log

# Show what would execute without running
dry-run:
	python src/ta_lab2/scripts/run_daily_refresh.py --all --dry-run

# Run validation only (no refresh)
validate:
	python src/ta_lab2/scripts/emas/run_all_ema_refreshes.py --only "" --validate

# Clean old log files (keep last 30 days)
clean-logs:
	@echo "Cleaning log files older than 30 days..."
	find .logs -name "refresh-*.log" -mtime +30 -delete 2>/dev/null || true

# Help target
help-refresh:
	@echo "Data Refresh Targets:"
	@echo "  make bars              - Run all bar builders"
	@echo "  make emas              - Run all EMA refreshers"
	@echo "  make daily-refresh     - Full bars + EMAs refresh with logging"
	@echo "  make dry-run           - Show what would execute"
	@echo "  make validate          - Run EMA validation only"
	@echo "  make clean-logs        - Remove logs older than 30 days"
```

**Notes:**
- If Makefile already exists, ADD these targets (don't replace existing content)
- Use $(date +%Y-%m-%d) for log file naming on Unix, or detect platform
- The .logs/ directory will be created by logging_config.py
  </action>
  <verify>
Run `make help-refresh` and verify the target list appears.
Run `make dry-run` and verify it shows the dry-run output.
  </verify>
  <done>Makefile has convenience targets for bars, emas, daily-refresh, dry-run, validate</done>
</task>

<task type="auto">
  <name>Task 2: Enhance logging with daily log files</name>
  <files>src/ta_lab2/scripts/emas/logging_config.py</files>
  <action>
Enhance logging_config.py to support daily log files with rotation:

1. **Add get_daily_log_path() function**:
   ```python
   def get_daily_log_path(prefix: str = "refresh") -> Path:
       """
       Get path for today's log file.

       Args:
           prefix: Log file prefix (e.g., "refresh", "bars", "emas")

       Returns:
           Path to log file: .logs/{prefix}-YYYY-MM-DD.log
       """
       from datetime import date

       log_dir = Path.cwd() / ".logs"
       log_dir.mkdir(exist_ok=True)

       today = date.today().isoformat()
       return log_dir / f"{prefix}-{today}.log"
   ```

2. **Add rotate_logs() function**:
   ```python
   def rotate_logs(log_dir: Path | str = ".logs", keep_days: int = 30) -> int:
       """
       Remove log files older than keep_days.

       Args:
           log_dir: Directory containing log files
           keep_days: Number of days to keep logs

       Returns:
           Number of files deleted
       """
       from datetime import datetime, timedelta

       log_path = Path(log_dir)
       if not log_path.exists():
           return 0

       cutoff = datetime.now() - timedelta(days=keep_days)
       deleted = 0

       for log_file in log_path.glob("refresh-*.log"):
           if log_file.stat().st_mtime < cutoff.timestamp():
               log_file.unlink()
               deleted += 1

       return deleted
   ```

3. **Update add_logging_args()** to include daily log option:
   ```python
   log_group.add_argument(
       "--log-to-daily-file",
       action="store_true",
       help="Log to .logs/refresh-YYYY-MM-DD.log in addition to console",
   )
   ```

4. **Update setup_logging()** to handle daily log path:
   ```python
   def setup_logging(
       *,
       name: str,
       level: str = "INFO",
       log_file: Optional[str] = None,
       log_to_daily_file: bool = False,  # New parameter
       quiet: bool = False,
       debug: bool = False,
   ) -> logging.Logger:
       # ... existing setup ...

       # Handle daily log file
       if log_to_daily_file and not log_file:
           log_file = str(get_daily_log_path(name))

       # ... rest of function ...
   ```

5. **Ensure .logs/ is in .gitignore** - check and add if missing
  </action>
  <verify>
Run `python -c "from ta_lab2.scripts.emas.logging_config import get_daily_log_path, rotate_logs; print(get_daily_log_path())"` and verify it returns a path like `.logs/refresh-YYYY-MM-DD.log`.
  </verify>
  <done>Logging supports daily log files with rotation helpers</done>
</task>

<task type="auto">
  <name>Task 3: Extend Telegram alerting for critical errors</name>
  <files>src/ta_lab2/notifications/telegram.py</files>
  <action>
Extend Telegram alerting to handle critical errors beyond validation:

1. **Check existing telegram.py** and understand current implementation (send_validation_alert, is_configured)

2. **Add send_critical_alert() function**:
   ```python
   def send_critical_alert(
       error_type: str,
       error_message: str,
       context: dict | None = None,
   ) -> bool:
       """
       Send alert for critical errors (database connection, OHLC corruption, etc.).

       Args:
           error_type: Category of error ("database", "corruption", "validation")
           error_message: Human-readable error message
           context: Additional context (e.g., {"ids": [1, 52], "component": "bars"})

       Returns:
           True if alert sent successfully, False otherwise
       """
       if not is_configured():
           return False

       # Format message
       msg_lines = [
           f"CRITICAL: {error_type.upper()}",
           "",
           error_message,
       ]

       if context:
           msg_lines.append("")
           msg_lines.append("Context:")
           for key, value in context.items():
               msg_lines.append(f"  {key}: {value}")

       message = "\n".join(msg_lines)

       # Send using existing mechanism
       return _send_message(message)
   ```

3. **Add severity levels**:
   ```python
   class AlertSeverity(Enum):
       INFO = "info"
       WARNING = "warning"
       ERROR = "error"
       CRITICAL = "critical"

   def send_alert(
       message: str,
       severity: AlertSeverity = AlertSeverity.INFO,
       context: dict | None = None,
   ) -> bool:
       """
       Generic alert function with severity level.

       Only sends CRITICAL and ERROR by default.
       Set TELEGRAM_ALERT_LEVEL env var to "warning" or "info" for more.
       """
       min_level = os.getenv("TELEGRAM_ALERT_LEVEL", "error").lower()
       # ... filter by severity ...
   ```

4. **Preserve existing functions** - don't break send_validation_alert or is_configured.

5. **Add --alert-on-error flag support** to orchestrators:
   - This flag should trigger send_critical_alert on database errors, subprocess failures, etc.
   - Existing --alert-on-validation-error remains for validation-specific alerts
  </action>
  <verify>
Run `python -c "from ta_lab2.notifications.telegram import send_critical_alert, is_configured; print('OK')"` to verify import works.
Verify existing functions still work: `python -c "from ta_lab2.notifications.telegram import send_validation_alert, is_configured; print('OK')"`
  </verify>
  <done>Telegram alerting extended with send_critical_alert for database and corruption errors</done>
</task>

</tasks>

<verification>
1. `make help-refresh` shows all refresh-related targets
2. `make dry-run` executes successfully
3. `.logs/` directory creation works (test via logging function)
4. Telegram module has send_critical_alert function
5. Existing send_validation_alert still works
</verification>

<success_criteria>
- Makefile provides bars, emas, daily-refresh, dry-run, validate targets
- Logging writes to .logs/refresh-YYYY-MM-DD.log when requested
- Log rotation helper removes files older than 30 days
- Telegram can alert on critical errors (database, corruption)
- All existing functionality preserved
</success_criteria>

<output>
After completion, create `.planning/phases/23-reliable-incremental-refresh/23-03-SUMMARY.md`
</output>
