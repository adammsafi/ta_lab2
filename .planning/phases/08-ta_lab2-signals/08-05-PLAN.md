---
phase: 08-ta_lab2-signals
plan: 05
type: execute
wave: 3
depends_on: [08-02, 08-03, 08-04]
files_modified:
  - sql/backtests/070_cmc_backtest_runs.sql
  - sql/backtests/071_cmc_backtest_trades.sql
  - sql/backtests/072_cmc_backtest_metrics.sql
  - src/ta_lab2/scripts/backtests/__init__.py
  - src/ta_lab2/scripts/backtests/backtest_from_signals.py
  - src/ta_lab2/scripts/backtests/run_backtest_signals.py
  - tests/backtests/test_backtest_from_signals.py
autonomous: true

must_haves:
  truths:
    - "Backtest reads signals from signal tables (not generated on-the-fly)"
    - "Backtest produces PnL using vectorbt via existing vbt_runner.py"
    - "Backtest results (runs, trades, metrics) stored in database tables"
    - "CLI supports both clean mode (no fees) and realistic mode (with fees/slippage)"
  artifacts:
    - path: "src/ta_lab2/scripts/backtests/backtest_from_signals.py"
      provides: "Backtest engine reading from signal tables"
      exports: ["SignalBacktester", "BacktestResult"]
    - path: "src/ta_lab2/scripts/backtests/run_backtest_signals.py"
      provides: "CLI for running backtests"
      min_lines: 100
    - path: "sql/backtests/070_cmc_backtest_runs.sql"
      provides: "Backtest run metadata table"
      contains: "CREATE TABLE"
  key_links:
    - from: "src/ta_lab2/scripts/backtests/backtest_from_signals.py"
      to: "src/ta_lab2/backtests/vbt_runner.py"
      via: "uses run_vbt_on_split for backtest execution"
      pattern: "from.*backtests.*vbt_runner.*import"
    - from: "src/ta_lab2/scripts/backtests/backtest_from_signals.py"
      to: "src/ta_lab2/backtests/costs.py"
      via: "uses CostModel for fees/slippage"
      pattern: "from.*backtests.*costs.*import.*CostModel"
---

<objective>
Create backtest integration that reads signals from database tables, runs backtests using existing vbt_runner.py infrastructure, and stores results (runs, trades, metrics) for reproducibility tracking.

Purpose: Connect signal generation (Plans 02-04) to PnL calculation. Backtest results cached in database enable historical comparison and reproducibility validation.

Output: SignalBacktester class, backtest result tables, CLI script, 15+ tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-ta_lab2-signals/08-CONTEXT.md
@.planning/phases/08-ta_lab2-signals/08-RESEARCH.md
@.planning/phases/08-ta_lab2-signals/08-02-SUMMARY.md

# Existing backtest infrastructure to leverage
@src/ta_lab2/backtests/vbt_runner.py
@src/ta_lab2/backtests/costs.py
@src/ta_lab2/backtests/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create backtest result DDLs</name>
  <files>
    sql/backtests/070_cmc_backtest_runs.sql
    sql/backtests/071_cmc_backtest_trades.sql
    sql/backtests/072_cmc_backtest_metrics.sql
  </files>
  <action>
    Create DDL files for backtest result storage:

    **070_cmc_backtest_runs.sql:**
    ```sql
    CREATE TABLE IF NOT EXISTS public.cmc_backtest_runs (
        run_id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        signal_type         TEXT NOT NULL,          -- 'ema_crossover', 'rsi_mean_revert', 'atr_breakout'
        signal_id           INTEGER NOT NULL,       -- FK to dim_signals
        asset_id            INTEGER NOT NULL,       -- Asset backtested

        -- Date range
        start_ts            TIMESTAMPTZ NOT NULL,
        end_ts              TIMESTAMPTZ NOT NULL,

        -- Configuration
        cost_model          JSONB NOT NULL,         -- {fee_bps, slippage_bps, funding_bps_day}
        signal_params_hash  TEXT NOT NULL,          -- Hash of signal params for caching
        feature_hash        TEXT,                   -- Hash of features at run time

        -- Versioning for reproducibility
        signal_version      TEXT NOT NULL,
        vbt_version         TEXT NOT NULL,
        run_timestamp       TIMESTAMPTZ NOT NULL DEFAULT now(),

        -- Results summary
        total_return        NUMERIC,
        sharpe_ratio        NUMERIC,
        max_drawdown        NUMERIC,
        trade_count         INTEGER,

        created_at          TIMESTAMPTZ DEFAULT now()
    );

    CREATE INDEX idx_backtest_runs_signal ON public.cmc_backtest_runs(signal_type, signal_id);
    CREATE INDEX idx_backtest_runs_asset ON public.cmc_backtest_runs(asset_id);
    CREATE INDEX idx_backtest_runs_params_hash ON public.cmc_backtest_runs(signal_params_hash);
    ```

    **071_cmc_backtest_trades.sql:**
    ```sql
    CREATE TABLE IF NOT EXISTS public.cmc_backtest_trades (
        trade_id            UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        run_id              UUID NOT NULL REFERENCES public.cmc_backtest_runs(run_id),

        -- Trade details
        entry_ts            TIMESTAMPTZ NOT NULL,
        entry_price         NUMERIC NOT NULL,
        exit_ts             TIMESTAMPTZ,
        exit_price          NUMERIC,
        direction           TEXT NOT NULL,          -- 'long', 'short'
        size                NUMERIC,                -- Position size

        -- Results
        pnl_pct             NUMERIC,
        pnl_dollars         NUMERIC,

        -- Costs
        fees_paid           NUMERIC,
        slippage_cost       NUMERIC,

        created_at          TIMESTAMPTZ DEFAULT now()
    );

    CREATE INDEX idx_backtest_trades_run ON public.cmc_backtest_trades(run_id);
    ```

    **072_cmc_backtest_metrics.sql:**
    ```sql
    CREATE TABLE IF NOT EXISTS public.cmc_backtest_metrics (
        metric_id           UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        run_id              UUID NOT NULL REFERENCES public.cmc_backtest_runs(run_id),

        -- Comprehensive metrics
        total_return        NUMERIC,
        cagr                NUMERIC,
        sharpe_ratio        NUMERIC,
        sortino_ratio       NUMERIC,
        calmar_ratio        NUMERIC,
        max_drawdown        NUMERIC,
        max_drawdown_duration_days INTEGER,

        -- Trade statistics
        trade_count         INTEGER,
        win_rate            NUMERIC,
        profit_factor       NUMERIC,
        avg_win             NUMERIC,
        avg_loss            NUMERIC,
        avg_holding_period_days NUMERIC,

        -- Risk metrics
        var_95              NUMERIC,                -- Value at Risk 95%
        expected_shortfall  NUMERIC,                -- CVaR

        created_at          TIMESTAMPTZ DEFAULT now()
    );

    CREATE INDEX idx_backtest_metrics_run ON public.cmc_backtest_metrics(run_id);
    ```
  </action>
  <verify>
    Run: `psql $TARGET_DB_URL -f sql/backtests/070_cmc_backtest_runs.sql`
    (etc. for each file)
    Verify tables created with: `\dt public.cmc_backtest_*`
  </verify>
  <done>
    cmc_backtest_runs, cmc_backtest_trades, cmc_backtest_metrics tables created with indexes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create SignalBacktester class</name>
  <files>
    src/ta_lab2/scripts/backtests/__init__.py
    src/ta_lab2/scripts/backtests/backtest_from_signals.py
  </files>
  <action>
    Create SignalBacktester that reads signals from DB and runs vectorbt backtest:

    ```python
    from dataclasses import dataclass
    from typing import Optional
    import uuid
    import pandas as pd
    import vectorbt as vbt
    from sqlalchemy import Engine, text
    from ta_lab2.backtests.vbt_runner import run_vbt_on_split, CostModel
    from ta_lab2.backtests.splitters import Split
    from ta_lab2.scripts.signals.signal_utils import compute_feature_hash

    @dataclass
    class BacktestResult:
        run_id: str
        signal_type: str
        signal_id: int
        asset_id: int
        total_return: float
        sharpe_ratio: float
        max_drawdown: float
        trade_count: int
        trades_df: pd.DataFrame
        metrics: dict

    @dataclass
    class SignalBacktester:
        engine: Engine
        cost_model: CostModel

        def load_signals_as_series(
            self,
            signal_type: str,
            signal_id: int,
            asset_id: int,
            start_ts: pd.Timestamp,
            end_ts: pd.Timestamp,
        ) -> tuple[pd.Series, pd.Series]:
            """
            Load signals from DB and convert to entries/exits Series.

            Queries closed positions from cmc_signals_{signal_type} table.
            Returns (entries, exits) aligned to price timestamps.
            """
            table = f"cmc_signals_{signal_type}"
            sql = text(f"""
                SELECT entry_ts, exit_ts, direction
                FROM {table}
                WHERE id = :asset_id
                  AND signal_id = :signal_id
                  AND entry_ts >= :start_ts
                  AND entry_ts <= :end_ts
                  AND position_state = 'closed'
                ORDER BY entry_ts
            """)
            # Convert to boolean Series indexed by timestamp
            # entries[ts] = True where entry occurred
            # exits[ts] = True where exit occurred

        def load_prices(
            self,
            asset_id: int,
            start_ts: pd.Timestamp,
            end_ts: pd.Timestamp,
        ) -> pd.DataFrame:
            """Load price data from cmc_daily_features."""
            sql = text("""
                SELECT ts, close
                FROM cmc_daily_features
                WHERE id = :asset_id
                  AND ts >= :start_ts
                  AND ts <= :end_ts
                ORDER BY ts
            """)
            # Return DataFrame indexed by ts

        def run_backtest(
            self,
            signal_type: str,
            signal_id: int,
            asset_id: int,
            start_ts: pd.Timestamp,
            end_ts: pd.Timestamp,
            clean_mode: bool = False,
        ) -> BacktestResult:
            """
            Run backtest for a single asset and signal configuration.

            Args:
                signal_type: 'ema_crossover', 'rsi_mean_revert', 'atr_breakout'
                signal_id: ID from dim_signals
                asset_id: Asset to backtest
                start_ts, end_ts: Date range
                clean_mode: If True, ignore fees/slippage (cost_model zeroed)

            Returns:
                BacktestResult with metrics and trades
            """
            # 1. Load signals from DB
            entries, exits = self.load_signals_as_series(...)

            # 2. Load prices
            prices = self.load_prices(...)

            # 3. Run vectorbt
            cost = CostModel() if clean_mode else self.cost_model
            split = Split("backtest", start_ts, end_ts)
            result_row = run_vbt_on_split(
                prices, entries, exits, size=None, cost=cost, split=split
            )

            # 4. Extract trades from vectorbt portfolio
            # pf.trades.records provides entry/exit details

            # 5. Compute comprehensive metrics
            metrics = self._compute_comprehensive_metrics(pf)

            # 6. Create result
            return BacktestResult(...)

        def save_backtest_results(self, result: BacktestResult) -> str:
            """
            Save backtest run, trades, and metrics to database.

            Returns: run_id
            """
            # INSERT into cmc_backtest_runs
            # INSERT into cmc_backtest_trades (batch)
            # INSERT into cmc_backtest_metrics

        def _compute_comprehensive_metrics(self, pf) -> dict:
            """
            Extract all metrics from vectorbt Portfolio.

            Uses vbt Portfolio methods:
            - pf.total_return(), pf.sharpe_ratio(), pf.max_drawdown()
            - pf.trades.count(), pf.trades.win_rate()
            - pf.trades.profit_factor()
            """
    ```

    **__init__.py:**
    Export: SignalBacktester, BacktestResult
  </action>
  <verify>
    Run: `python -c "from ta_lab2.scripts.backtests import SignalBacktester, BacktestResult; print('OK')"`
    Verify imports work.
  </verify>
  <done>
    SignalBacktester class created with run_backtest, save_backtest_results, and comprehensive metric extraction.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create CLI script and tests</name>
  <files>
    src/ta_lab2/scripts/backtests/run_backtest_signals.py
    tests/backtests/test_backtest_from_signals.py
  </files>
  <action>
    **run_backtest_signals.py:**
    ```python
    #!/usr/bin/env python
    """Run backtests from stored signals in database."""

    import argparse
    import logging
    import os
    from datetime import datetime
    from sqlalchemy import create_engine
    from ta_lab2.backtests.costs import CostModel
    from ta_lab2.scripts.backtests import SignalBacktester

    def main():
        parser = argparse.ArgumentParser()
        parser.add_argument('--signal-type', required=True,
                            choices=['ema_crossover', 'rsi_mean_revert', 'atr_breakout'])
        parser.add_argument('--signal-id', type=int, required=True)
        parser.add_argument('--asset-id', type=int, required=True)
        parser.add_argument('--start', type=str, required=True, help='YYYY-MM-DD')
        parser.add_argument('--end', type=str, required=True, help='YYYY-MM-DD')

        # Cost model options
        parser.add_argument('--clean-pnl', action='store_true',
                            help='Ignore fees/slippage (clean mode)')
        parser.add_argument('--fee-bps', type=float, default=10.0,
                            help='Commission in basis points')
        parser.add_argument('--slippage-bps', type=float, default=5.0,
                            help='Slippage in basis points')

        # Output options
        parser.add_argument('--save-results', action='store_true',
                            help='Store results in database')
        parser.add_argument('--output-json', type=str,
                            help='Write results to JSON file')
        parser.add_argument('--verbose', '-v', action='store_true')

        args = parser.parse_args()

        logging.basicConfig(level=logging.DEBUG if args.verbose else logging.INFO)
        logger = logging.getLogger(__name__)

        engine = create_engine(os.environ['TARGET_DB_URL'])

        cost_model = CostModel(
            fee_bps=args.fee_bps,
            slippage_bps=args.slippage_bps,
        )

        backtester = SignalBacktester(engine, cost_model)

        start_ts = pd.Timestamp(args.start, tz='UTC')
        end_ts = pd.Timestamp(args.end, tz='UTC')

        result = backtester.run_backtest(
            signal_type=args.signal_type,
            signal_id=args.signal_id,
            asset_id=args.asset_id,
            start_ts=start_ts,
            end_ts=end_ts,
            clean_mode=args.clean_pnl,
        )

        # Output results
        logger.info(f"Backtest Results for {args.signal_type}/{args.signal_id}")
        logger.info(f"  Total Return: {result.total_return:.2%}")
        logger.info(f"  Sharpe Ratio: {result.sharpe_ratio:.2f}")
        logger.info(f"  Max Drawdown: {result.max_drawdown:.2%}")
        logger.info(f"  Trade Count:  {result.trade_count}")

        if args.save_results:
            run_id = backtester.save_backtest_results(result)
            logger.info(f"Results saved with run_id: {run_id}")

        if args.output_json:
            # Write JSON
            ...

    if __name__ == '__main__':
        main()
    ```

    **test_backtest_from_signals.py:**
    Unit tests with mocks:
    - test_load_signals_as_series_returns_entries_exits: Verify bool Series
    - test_load_signals_filters_by_date_range: start_ts/end_ts honored
    - test_load_signals_filters_closed_positions: position_state='closed' only
    - test_run_backtest_clean_mode_zeros_costs: clean_mode=True ignores fees
    - test_run_backtest_realistic_mode_uses_cost_model: Fees applied
    - test_compute_comprehensive_metrics_all_fields: Verify all metrics extracted
    - test_save_backtest_results_inserts_three_tables: runs, trades, metrics
    - test_backtest_result_dataclass_fields: Verify structure

    Integration tests (skipif not TARGET_DB_URL):
    - test_roundtrip_backtest_save_load: Save and query back
    - test_backtest_with_real_signals: Generate signals, run backtest
    - test_backtest_produces_nonzero_return: Verify PnL calculated
    - test_backtest_trades_match_signals: Trade count matches signal count
    - test_metrics_consistency: Verify metric calculations
  </action>
  <verify>
    Run: `pytest tests/backtests/test_backtest_from_signals.py -v`
    All tests pass.
    Run: `python src/ta_lab2/scripts/backtests/run_backtest_signals.py --help`
    Verify help text.
  </verify>
  <done>
    CLI script with --clean-pnl, --fee-bps, --save-results flags.
    15+ tests passing for backtest integration.
  </done>
</task>

</tasks>

<verification>
Phase verification checklist:
- [ ] cmc_backtest_runs, cmc_backtest_trades, cmc_backtest_metrics tables exist
- [ ] SignalBacktester.run_backtest produces BacktestResult
- [ ] Backtest reads signals from signal tables (not on-the-fly generation)
- [ ] Clean mode produces PnL without fees
- [ ] Realistic mode applies CostModel fees/slippage
- [ ] Results can be saved to database
- [ ] CLI supports required flags
- [ ] All tests pass (15+ tests)
</verification>

<success_criteria>
1. Backtest reads from signal tables and produces PnL
2. Results stored in cmc_backtest_* tables
3. Clean and realistic cost modes work correctly
4. Comprehensive metrics (Sharpe, Sortino, Calmar, etc.) computed
</success_criteria>

<output>
After completion, create `.planning/phases/08-ta_lab2-signals/08-05-SUMMARY.md`
</output>
