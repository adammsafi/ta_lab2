---
phase: 28-backtest-pipeline-fix
plan: 03
type: execute
wave: 2
depends_on: ["28-01", "28-02"]
files_modified: []
autonomous: false

must_haves:
  truths:
    - "At least one signal generator (EMA, ATR, or RSI) writes signals to DB without errors"
    - "Backtest runner reads signals from DB and produces a BacktestResult with trades and metrics"
    - "End-to-end pipeline works: cmc_features -> signal generator -> signal table -> backtest -> PnL summary"
    - "save_backtest_results writes run, trades, and metrics to cmc_backtest_* tables without errors"
  artifacts: []
  key_links:
    - from: "signal generators"
      to: "cmc_signals_* tables"
      via: "generate_for_ids -> _write_signals"
      pattern: "to_sql.*cmc_signals"
    - from: "backtest_from_signals"
      to: "cmc_backtest_runs"
      via: "save_backtest_results"
      pattern: "cmc_backtest_runs"
---

<objective>
Verify the full signal-to-backtest pipeline works end-to-end by running signal generators and backtest runner against live database.

Purpose: Plans 01 and 02 fixed the individual bugs. This plan verifies that the fixes work together in the real pipeline: signal generation populates signal tables, and the backtest runner reads those signals and produces PnL results. This is the Phase 28 success gate.

Output: Verified end-to-end pipeline with at least one signal type producing a complete backtest report.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-backtest-pipeline-fix/28-RESEARCH.md
@.planning/phases/28-backtest-pipeline-fix/28-01-SUMMARY.md
@.planning/phases/28-backtest-pipeline-fix/28-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Ensure dim_signals is seeded, then run signal generators</name>
  <files></files>
  <action>
Run each signal generator against the live database and verify signals are written successfully.

**Step 0 (MANDATORY): Ensure dim_signals has active signal configurations.**

This is a hard pre-flight check. If dim_signals is empty, signal generators will silently produce nothing and SC-2 cannot be verified.

Run the idempotent seed script first:
```bash
python -m ta_lab2.scripts.setup.ensure_dim_signals
```

Then verify active configs exist:
```bash
python -c "
from sqlalchemy import create_engine, text
import os
engine = create_engine(os.environ['TARGET_DB_URL'])
with engine.connect() as conn:
    rows = conn.execute(text('SELECT signal_id, signal_name, signal_type, is_active FROM public.dim_signals ORDER BY signal_id')).fetchall()
    if not rows:
        raise RuntimeError('BLOCKER: dim_signals is empty even after running ensure_dim_signals. Cannot proceed -- signal pipeline requires at least one active config. Check sql/lookups/030_dim_signals.sql and re-run ensure_dim_signals.')
    active = [r for r in rows if r[3]]
    if not active:
        raise RuntimeError('BLOCKER: dim_signals has rows but none are active (is_active=True). Update at least one row to is_active=True before proceeding.')
    for r in rows:
        print(f'  signal_id={r[0]}, name={r[1]}, type={r[2]}, active={r[3]}')
    print(f'Total: {len(rows)} configs, {len(active)} active')
"
```

If either check raises RuntimeError, STOP this plan and report the error. Do NOT continue to signal generation with an empty dim_signals.

Step 1: Run the RSI signal generator (already working, confirms baseline):
```bash
python -m ta_lab2.scripts.signals.refresh_cmc_signals_rsi_mean_revert --ids 1 --full-refresh
```

Step 2: Run the EMA signal generator (was broken, should now work):
```bash
python -m ta_lab2.scripts.signals.refresh_cmc_signals_ema_crossover --ids 1 --full-refresh
```

Step 3: Run the ATR signal generator (was broken, should now work):
```bash
python -m ta_lab2.scripts.signals.refresh_cmc_signals_atr_breakout --ids 1 --full-refresh
```

Step 4: Verify signal tables have rows:
```bash
python -c "
from sqlalchemy import create_engine, text
import os
engine = create_engine(os.environ['TARGET_DB_URL'])
with engine.connect() as conn:
    for table in ['cmc_signals_rsi_mean_revert', 'cmc_signals_ema_crossover', 'cmc_signals_atr_breakout']:
        count = conn.execute(text(f'SELECT count(*) FROM public.{table}')).scalar()
        closed = conn.execute(text(f\"SELECT count(*) FROM public.{table} WHERE position_state = 'closed'\")).scalar()
        print(f'{table}: {count} total, {closed} closed positions')
"
```

If any generator fails, log the error but continue with the others. At least one must succeed for the pipeline to be considered working.
  </action>
  <verify>
dim_signals has at least one active config (Step 0 passed without RuntimeError).
At least one signal generator completes without errors.
At least one signal table has closed positions (needed for backtesting).
  </verify>
  <done>dim_signals confirmed populated with active configs. Signal generators write to database without serialization errors. At least one signal table has closed positions ready for backtesting.</done>
</task>

<task type="auto">
  <name>Task 2: Run backtest and verify end-to-end PnL output</name>
  <files></files>
  <action>
Run the backtest CLI against whichever signal type has closed positions from Task 1.

Step 1: Find date range and signal info for backtesting:
```bash
python -c "
from sqlalchemy import create_engine, text
import os
engine = create_engine(os.environ['TARGET_DB_URL'])
with engine.connect() as conn:
    for table in ['cmc_signals_rsi_mean_revert', 'cmc_signals_ema_crossover', 'cmc_signals_atr_breakout']:
        sig_type = table.replace('cmc_signals_', '')
        row = conn.execute(text(f\"\"\"
            SELECT signal_id, id, min(entry_ts), max(exit_ts), count(*)
            FROM public.{table}
            WHERE position_state = 'closed' AND exit_ts IS NOT NULL
            GROUP BY signal_id, id
            ORDER BY count(*) DESC
            LIMIT 1
        \"\"\")).fetchone()
        if row:
            print(f'{sig_type}: signal_id={row[0]}, asset_id={row[1]}, start={row[2]}, end={row[3]}, trades={row[4]}')
"
```

Step 2: Run backtest in clean mode (no fees) using the signal type with the most closed trades:
```bash
python -m ta_lab2.scripts.backtests.run_backtest_signals \
    --signal-type <SIGNAL_TYPE> \
    --signal-id <SIGNAL_ID> \
    --asset-id <ASSET_ID> \
    --start <START_DATE> \
    --end <END_DATE> \
    --clean-pnl \
    --verbose
```

Replace placeholders with actual values from Step 1.

Step 3: If clean mode works, run with realistic costs and save to database:
```bash
python -m ta_lab2.scripts.backtests.run_backtest_signals \
    --signal-type <SIGNAL_TYPE> \
    --signal-id <SIGNAL_ID> \
    --asset-id <ASSET_ID> \
    --start <START_DATE> \
    --end <END_DATE> \
    --fee-bps 10 \
    --slippage-bps 5 \
    --save-results \
    --verbose
```

Step 4: Verify backtest results were saved to database:
```bash
python -c "
from sqlalchemy import create_engine, text
import os
engine = create_engine(os.environ['TARGET_DB_URL'])
with engine.connect() as conn:
    runs = conn.execute(text('SELECT run_id, signal_type, total_return, sharpe_ratio, trade_count FROM public.cmc_backtest_runs ORDER BY run_timestamp DESC LIMIT 3')).fetchall()
    print('=== Backtest Runs ===')
    for r in runs:
        print(f'  run_id={r[0][:8]}..., type={r[1]}, return={r[2]:.2%}, sharpe={r[3]:.2f}, trades={r[4]}')

    trades = conn.execute(text('SELECT count(*) FROM public.cmc_backtest_trades')).scalar()
    print(f'Total trade records: {trades}')

    metrics = conn.execute(text('SELECT count(*) FROM public.cmc_backtest_metrics')).scalar()
    print(f'Total metrics records: {metrics}')
"
```

If any step fails with a NEW error (not the bugs fixed in plans 01-02), document it for future gap closure but do not attempt to fix it in this plan.
  </action>
  <verify>
Backtest CLI produces PnL output to console without crashes.
If --save-results used: cmc_backtest_runs, cmc_backtest_trades, cmc_backtest_metrics all have at least 1 row.
  </verify>
  <done>End-to-end pipeline verified: cmc_features -> signal generator -> signal table -> backtest -> PnL summary. At least one signal type produces a complete backtest report with metrics.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete signal-to-backtest pipeline fix:
1. Fixed EMA generator feature_snapshot serialization (json.dumps)
2. Fixed ATR generator feature_snapshot serialization (json.dumps replacing pd.io.json.dumps)
3. Fixed vectorbt _extract_trades: tz-aware timestamps, Direction mapping, Fees column
4. Fixed save_backtest_results: cost_model JSON serialization
5. Added tz-strip in run_backtest() before vectorbt receives prices/entries/exits
6. Ensured dim_signals is seeded before signal generation

End-to-end pipeline tested: features -> signals -> backtest -> PnL.
  </what-built>
  <how-to-verify>
1. Review the console output from Task 2 -- does the backtest report show reasonable metrics?
   - Total return, Sharpe ratio, trade count should be populated (not NaN or zero for all)
   - Trade statistics (win rate, profit factor) should show values
2. Check database tables have data:
   ```bash
   python -c "
   from sqlalchemy import create_engine, text; import os
   engine = create_engine(os.environ['TARGET_DB_URL'])
   with engine.connect() as conn:
       for t in ['cmc_backtest_runs','cmc_backtest_trades','cmc_backtest_metrics']:
           c = conn.execute(text(f'SELECT count(*) FROM public.{t}')).scalar()
           print(f'{t}: {c} rows')
   "
   ```
3. Confirm no errors in the task output logs
  </how-to-verify>
  <resume-signal>Type "approved" if pipeline works end-to-end, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
Phase 28 success criteria check:
1. Signal generators write to DB without errors (feature_snapshot serialized correctly) -- verified by Task 1
2. All 3 signal refreshers complete without crashes -- verified by Task 1
3. Backtest runner reads signals and produces PnL results without vectorbt timestamp errors -- verified by Task 2
4. End-to-end pipeline works: cmc_features -> signals -> backtest -> PnL summary -- verified by Task 2
5. At least one signal type produces a complete backtest report -- verified by Task 2
6. dim_signals has active configs (pre-flight in Task 1 Step 0) -- verified by Task 1
</verification>

<success_criteria>
- dim_signals has active signal configurations (seeded if needed)
- At least one signal generator writes signals to its database table without errors
- Backtest runner produces a BacktestResult with non-empty trades_df and populated metrics
- End-to-end pipeline completes: features -> signals -> backtest -> console report
- Backtest results saved to cmc_backtest_* tables (if --save-results used)
- Human approves the pipeline output
</success_criteria>

<output>
After completion, create `.planning/phases/28-backtest-pipeline-fix/28-03-SUMMARY.md`
</output>
