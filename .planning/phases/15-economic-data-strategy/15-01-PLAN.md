---
phase: 15-economic-data-strategy
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .archive/external-packages/2026-02-03/fredtools2/
  - .archive/external-packages/2026-02-03/fedtools2/
  - .archive/external-packages/2026-02-03/manifest.json
  - .archive/external-packages/2026-02-03/README.md
  - .archive/external-packages/2026-02-03/ALTERNATIVES.md
  - .archive/external-packages/2026-02-03/dependencies_snapshot.txt
autonomous: true
user_setup: []

must_haves:
  truths:
    - "fredtools2 and fedtools2 packages preserved in archive with all source files"
    - "ALTERNATIVES.md covers all 4 dimensions: feature mapping, API comparison, migration effort, ecosystem maturity"
    - "Manifest tracks files with SHA256 checksums and full provenance"
    - "Dependency snapshot captures complete reproducibility information"
  artifacts:
    - path: ".archive/external-packages/2026-02-03/fredtools2/"
      provides: "Preserved fredtools2 source code"
    - path: ".archive/external-packages/2026-02-03/fedtools2/"
      provides: "Preserved fedtools2 source code"
    - path: ".archive/external-packages/2026-02-03/manifest.json"
      provides: "Archive manifest with checksums and provenance"
      contains: "$schema"
    - path: ".archive/external-packages/2026-02-03/ALTERNATIVES.md"
      provides: "Comprehensive ecosystem alternatives documentation"
    - path: ".archive/external-packages/2026-02-03/dependencies_snapshot.txt"
      provides: "Full dependency tree for reproducibility"
  key_links:
    - from: "manifest.json"
      to: "archived files"
      via: "SHA256 checksums"
      pattern: "checksum_sha256"
---

<objective>
Archive fredtools2 and fedtools2 packages with comprehensive documentation

Purpose: Preserve specialized economic data packages while removing maintenance burden. Create comprehensive archive with manifest (SHA256 checksums, provenance), README (restoration guide), ALTERNATIVES.md (4-dimensional comparison), and dependency snapshot (pip freeze style). Research confirmed zero usage in ta_lab2 and ecosystem alternatives (fredapi, fedfred) are superior.

Output: Both packages in .archive/external-packages/2026-02-03/ with full documentation meeting context requirements.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-economic-data-strategy/15-CONTEXT.md
@.planning/phases/15-economic-data-strategy/15-RESEARCH.md

# Archive patterns
@src/ta_lab2/tools/archive/manifest.py
@.archive/data_tools/2026-02-03/manifest.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create archive structure and copy packages</name>
  <files>
.archive/external-packages/2026-02-03/fredtools2/
.archive/external-packages/2026-02-03/fedtools2/
  </files>
  <action>
Create archive directory and copy both external packages:

1. Create directory structure:
   ```
   .archive/external-packages/2026-02-03/
   ├── fredtools2/
   └── fedtools2/
   ```

2. Copy fredtools2 from C:/Users/asafi/Downloads/fredtools2/:
   - Include: src/, tests/, sql/, ops/, pyproject.toml
   - Exclude: __pycache__, .egg-info, .venv, .git

3. Copy fedtools2 from C:/Users/asafi/Downloads/fedtools2/:
   - Include: src/, tests/, pyproject.toml, README.md, setup.py, db_config.example.env, structure.* files
   - Exclude: __pycache__, .egg-info, .venv, .git, .pytest_cache, .benchmarks, fedtools2.egg-info

Use robocopy or xcopy with exclusion patterns (Windows), or rsync --exclude on Unix. These are EXTERNAL files (not in ta_lab2 repo) so use copy, not git mv.

Verify file counts:
- fredtools2: ~6 Python files + config
- fedtools2: ~11 Python files + config + structure docs
  </action>
  <verify>
Run: `dir /s /b .archive\external-packages\2026-02-03\fredtools2\*.py 2>nul | find /c /v ""` shows ~6 Python files
Run: `dir /s /b .archive\external-packages\2026-02-03\fedtools2\*.py 2>nul | find /c /v ""` shows ~11 Python files
Both pyproject.toml files exist in archive
  </verify>
  <done>Both packages copied to archive with source files preserved, excluding caches and build artifacts</done>
</task>

<task type="auto">
  <name>Task 2: Create comprehensive ALTERNATIVES.md</name>
  <files>.archive/external-packages/2026-02-03/ALTERNATIVES.md</files>
  <action>
Create ALTERNATIVES.md covering all 4 context-required dimensions:

```markdown
# Economic Data Package Alternatives Guide

**Archived:** 2026-02-03
**Applies to:** fredtools2, fedtools2
**Recommended replacements:** fredapi, fedfred

## 1. Feature Mapping

| fredtools2/fedtools2 Feature | Modern Equivalent | Package | Notes |
|------------------------------|-------------------|---------|-------|
| `fred_api.get_releases(api_key)` | `fred.get_releases()` | fredapi | Returns DataFrame, handles pagination |
| `fred_api.get_series_observations(api_key, series_id)` | `fred.get_series(series_id)` | fredapi | Returns pandas Series with datetime index |
| `jobs.releases.pull_releases()` | `fred.search(text)` + custom DB insert | fredapi | Search replaces release browsing |
| `jobs.series.pull_series()` | `fred.get_series()` + `df.to_sql()` | fredapi + pandas | More flexible storage options |
| `etl.build_dataset()` (Fed targets consolidation) | Custom logic + `fred.get_series()` | fredapi | TARGET_MID logic must be replicated |
| `utils.consolidation.combine_timeframes()` | `pd.merge()` + `ffill()` | pandas | Standard pandas operations |
| `sql_sink_example.write_dataframe_and_log()` | `df.to_sql()` + manual log | pandas + SQLAlchemy | Standard pattern |
| PostgreSQL schema management | Alembic migrations | alembic | Industry standard |
| Rate limiting (none) | Built-in (120/min) | fedfred | Major improvement |
| Caching (none) | Built-in TTL cache | fedfred | Major improvement |
| Data revisions (none) | ALFRED support | fredapi | Access historical vintages |

## 2. API Comparison

### Fetching Series Data

**fredtools2 (archived):**
```python
from fredtools2.config import fred_api_key
from fredtools2 import fred_api as client

api = fred_api_key()
obs = client.get_series_observations(api, "FEDFUNDS")
# Returns list of dicts: [{"date": "2024-01-01", "value": "5.33"}, ...]
```

**fredapi (recommended):**
```python
from fredapi import Fred
import os

fred = Fred(api_key=os.getenv("FRED_API_KEY"))
series = fred.get_series("FEDFUNDS")
# Returns pandas Series with DatetimeIndex, float values
```

**fedfred (async alternative):**
```python
from fedfred import Fred
import asyncio

fred = Fred(api_key=os.getenv("FRED_API_KEY"))
# Sync
series = fred.get_series("FEDFUNDS")
# Async (high-volume)
series = asyncio.run(fred.get_series_async("FEDFUNDS"))
```

### Storing to Database

**fredtools2 (archived):**
```python
from fredtools2.db import connect
from psycopg2.extras import execute_values

conn = connect()
with conn.cursor() as cur:
    execute_values(cur, "INSERT INTO fred_series_values ...", rows)
conn.commit()
```

**Modern approach:**
```python
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine("postgresql://user:pass@host/db")
series.to_frame("value").to_sql("fred_series_values", engine, if_exists="append")
```

### Fed Targets Consolidation (fedtools2 unique logic)

**fedtools2 (archived):**
```python
from fedtools2.etl import build_dataset

df = build_dataset(cfg)
# Merges FEDFUNDS, DFEDTAR, DFEDTARL, DFEDTARU
# Computes TARGET_MID, TARGET_SPREAD, regime labels
```

**Modern equivalent (must replicate logic):**
```python
from fredapi import Fred
import pandas as pd
import numpy as np

fred = Fred(api_key=os.getenv("FRED_API_KEY"))

# Fetch all series
fedfunds = fred.get_series("FEDFUNDS")
dfedtar = fred.get_series("DFEDTAR")
dfedtarl = fred.get_series("DFEDTARL")
dfedtaru = fred.get_series("DFEDTARU")

# Merge and compute TARGET_MID
df = pd.DataFrame({
    "FEDFUNDS": fedfunds,
    "DFEDTAR": dfedtar,
    "DFEDTARL": dfedtarl,
    "DFEDTARU": dfedtaru
})
df["TARGET_MID"] = df["DFEDTAR"].where(
    df["DFEDTAR"].notna(),
    (df["DFEDTARL"] + df["DFEDTARU"]) / 2
)
df["TARGET_SPREAD"] = df["DFEDTARU"] - df["DFEDTARL"]
```

## 3. Migration Effort Estimates

| Migration Scenario | Effort | Notes |
|--------------------|--------|-------|
| Basic FRED series fetch | 5 min | Direct fredapi replacement |
| Series with DB storage | 30 min | Replace custom schema with pandas to_sql |
| Full fredtools2 workflow | 2 hours | Replace PostgreSQL schema, update all queries |
| Full fedtools2 workflow | 4 hours | Replicate TARGET_MID logic, regime labels, SQL sink |
| High-volume async | 1 hour | Switch to fedfred, add asyncio |
| Add caching/rate limiting | 0 min | Built into fedfred |

**Complexity factors:**
- Schema migration: If using fredtools2's PostgreSQL schema (fred_series_values, releases, pull_log), need to either keep schema or migrate to new structure
- TARGET_MID logic: fedtools2's TARGET_MID calculation handles pre-2008 (single target) vs post-2008 (target range) - must preserve this logic
- Regime labels: fedtools2 assigns "pre-target", "single-target", "target-range" labels based on date ranges

## 4. Ecosystem Maturity

| Package | First Release | Last Update | GitHub Stars | Maintenance | Production Ready |
|---------|---------------|-------------|--------------|-------------|------------------|
| **fredapi** | 2014 | 2024 | 700+ | Active | Yes (10+ years) |
| **fedfred** | 2024 | 2025 | 50+ | Active | Yes (modern) |
| fredtools2 | 2024 | 2024 | 0 | Archived | No (custom, unmaintained) |
| fedtools2 | 2024 | 2024 | 0 | Archived | No (custom, unmaintained) |

### fredapi Stability
- Maintained by original author (mortada)
- Handles all FRED API edge cases (pagination, file_type, revision dates)
- ALFRED support for historical data vintages
- Used by quantitative finance community
- No breaking changes in 5+ years

### fedfred Modernity
- Async support for concurrent requests
- Built-in rate limiting (120 calls/min FRED limit)
- Automatic caching with configurable TTL
- Pandas, Polars, Dask, GeoPandas output formats
- Modern Python 3.10+ design

### Why Archive Custom Packages?
1. **Zero usage:** No imports in ta_lab2 codebase
2. **Maintenance burden:** Custom wrappers require updates for FRED API changes
3. **Missing features:** No caching, rate limiting, revision handling
4. **Ecosystem coverage:** fredapi/fedfred handle 99% of use cases
5. **Single maintainer:** Custom packages have bus factor of 1

## Decision Summary

**For ta_lab2 economic data needs:**
- Use **fredapi** for standard FRED access (most mature, battle-tested)
- Use **fedfred** for high-volume/async workflows (modern, performant)
- Replicate **fedtools2 TARGET_MID logic** in ta_lab2.utils.economic if needed

**Do not restore archived packages unless:**
- Ecosystem alternatives cannot handle a specific edge case
- Domain-specific logic (TARGET_MID, regime labels) is needed AND cannot be replicated
```
  </action>
  <verify>
Run: `Select-String -Path ".archive\external-packages\2026-02-03\ALTERNATIVES.md" -Pattern "Feature Mapping|API Comparison|Migration Effort|Ecosystem Maturity" | Measure-Object | Select-Object -ExpandProperty Count` shows 4 (all sections present)
  </verify>
  <done>ALTERNATIVES.md created with all 4 required dimensions: feature mapping, API comparison, migration effort, ecosystem maturity</done>
</task>

<task type="auto">
  <name>Task 3: Generate manifest and supporting documentation</name>
  <files>
.archive/external-packages/2026-02-03/manifest.json
.archive/external-packages/2026-02-03/README.md
.archive/external-packages/2026-02-03/dependencies_snapshot.txt
  </files>
  <action>
Create manifest.json, README.md, and dependencies_snapshot.txt:

**1. manifest.json** - Follow Phase 12/14 patterns with $schema versioning:

```python
import hashlib
import json
from datetime import datetime, timezone
from pathlib import Path

def compute_checksum(path):
    with open(path, "rb") as f:
        return hashlib.file_digest(f, "sha256").hexdigest()

archive_dir = Path(".archive/external-packages/2026-02-03")
files = []

# Process all Python files in both packages
for pkg_name in ["fredtools2", "fedtools2"]:
    pkg_dir = archive_dir / pkg_name
    for py_file in pkg_dir.rglob("*.py"):
        rel_path = py_file.relative_to(archive_dir)
        files.append({
            "original_path": f"C:/Users/asafi/Downloads/{pkg_name}/{py_file.relative_to(pkg_dir)}",
            "archive_path": str(rel_path),
            "checksum_sha256": compute_checksum(py_file),
            "size_bytes": py_file.stat().st_size,
            "action": "archived",
            "reason": "Zero usage in ta_lab2, ecosystem alternatives superior",
            "archived_at": datetime.now(timezone.utc).isoformat()
        })

manifest = {
    "$schema": "https://ta-lab2.example.com/schemas/archive-manifest-1.0.0.json",
    "version": "1.0.0",
    "created": datetime.now(timezone.utc).isoformat(),
    "phase": "15-economic-data-strategy",
    "category": "external-packages",
    "decision": "archive",
    "rationale": "Specialized packages with zero usage in ta_lab2. Ecosystem alternatives (fredapi, fedfred) provide superior functionality with active maintenance.",
    "packages": [
        {
            "name": "fredtools2",
            "version": "0.1.0",
            "description": "PostgreSQL-backed FRED data ingestion with CLI",
            "entry_point": "fred [init|releases|series]",
            "source_location": "C:/Users/asafi/Downloads/fredtools2",
            "total_lines": 167,
            "provenance": {
                "origin": "Custom development",
                "author": "Adam Safi",
                "purpose": "FRED API wrapper for PostgreSQL storage"
            }
        },
        {
            "name": "fedtools2",
            "version": "0.1.0",
            "description": "ETL consolidation of Federal Reserve policy target datasets",
            "entry_point": "fedtools2 [--config] [--plot]",
            "source_location": "C:/Users/asafi/Downloads/fedtools2",
            "total_lines": 659,
            "provenance": {
                "origin": "Custom development",
                "author": "Adam Safi",
                "purpose": "Consolidate FEDFUNDS, DFEDTAR* into unified daily dataset"
            }
        }
    ],
    "files": files,
    "ecosystem_alternatives": [
        {"name": "fredapi", "version": "0.5.2+", "pypi": "https://pypi.org/project/fredapi/", "replaces": ["fredtools2"]},
        {"name": "fedfred", "version": "1.0+", "pypi": "https://pypi.org/project/fedfred/", "replaces": ["fredtools2"]}
    ],
    "summary": {
        "total_packages": 2,
        "total_files": len(files),
        "total_lines": 826
    }
}

with open(archive_dir / "manifest.json", "w") as f:
    json.dump(manifest, f, indent=2)
```

**2. README.md** - Archive documentation with restoration guide:

```markdown
# External Packages Archive

**Archived:** 2026-02-03
**Phase:** 15-economic-data-strategy
**Decision:** Archive (not integrate)

## Contents

### fredtools2 (167 lines)
PostgreSQL-backed FRED data ingestion with CLI.
- **Entry point:** `fred [init|releases|series]`
- **Dependencies:** requests, psycopg2-binary, python-dotenv

### fedtools2 (659 lines)
ETL consolidation of Federal Reserve policy target datasets.
- **Entry point:** `fedtools2 [--config] [--plot]`
- **Dependencies:** pandas, numpy, pyyaml, matplotlib, sqlalchemy, python-dotenv
- **Unique logic:** TARGET_MID, TARGET_SPREAD, regime labels

## Archive Rationale

1. **Zero usage:** No imports from either package in ta_lab2 codebase
2. **Ecosystem alternatives:** fredapi and fedfred are superior (see ALTERNATIVES.md)
3. **Maintenance burden:** Custom wrappers add technical debt
4. **Preservation:** Archive preserves code for reference without cost

## Restoration

To restore for use:

1. Copy package directory: `cp -r .archive/external-packages/2026-02-03/fredtools2 ./lib/`
2. Install: `pip install -e ./lib/fredtools2`
3. Configure environment variables (see package README or dependencies_snapshot.txt)
4. Run: `fred init` or `fedtools2`

## Files

- `manifest.json` - Complete file listing with SHA256 checksums
- `ALTERNATIVES.md` - Ecosystem alternatives comparison (4 dimensions)
- `dependencies_snapshot.txt` - Full dependency tree for reproducibility
- `fredtools2/` - Preserved package source
- `fedtools2/` - Preserved package source

## Ecosystem Alternatives

For new economic data integration, use:
- **fredapi** (https://pypi.org/project/fredapi/) - Most established FRED client
- **fedfred** (https://pypi.org/project/fedfred/) - Modern alternative with async/caching

See ALTERNATIVES.md for detailed comparison.
```

**3. dependencies_snapshot.txt** - Capture full dependency tree:

```
# Dependencies Snapshot for Archived Economic Data Packages
# Generated: 2026-02-03
# Purpose: Enable reproducible restoration if needed

## fredtools2 Dependencies (from pyproject.toml)
requests>=2.32
psycopg2-binary>=2.9
python-dotenv>=1.0

## fedtools2 Dependencies (from pyproject.toml)
pandas>=2.2
numpy>=1.26
pyyaml>=6.0
matplotlib>=3.8
sqlalchemy>=2.0
python-dotenv>=1.0

## Combined Unique Dependencies
matplotlib>=3.8
numpy>=1.26
pandas>=2.2
psycopg2-binary>=2.9
python-dotenv>=1.0
pyyaml>=6.0
requests>=2.32
sqlalchemy>=2.0

## Ecosystem Alternative Dependencies
# For fredapi (recommended replacement):
fredapi>=0.5.2

# For fedfred (async alternative):
fedfred>=1.0

## Notes
- fredtools2 requires PostgreSQL server running
- fedtools2 requires FRED CSV files in FEDTOOLS2_FED_DATA_DIR
- Both packages expect FRED_API_KEY environment variable
```
  </action>
  <verify>
Run: `python -c "import json; m=json.load(open('.archive/external-packages/2026-02-03/manifest.json')); print(f'Files: {len(m.get(\"files\", []))}'); print(f'Schema: {m.get(\"$schema\", \"MISSING\")}')"` shows files > 0 and schema present
Run: `Test-Path .archive/external-packages/2026-02-03/README.md` returns True
Run: `Test-Path .archive/external-packages/2026-02-03/dependencies_snapshot.txt` returns True
  </verify>
  <done>manifest.json with checksums and provenance, README.md with restoration guide, and dependencies_snapshot.txt created</done>
</task>

</tasks>

<verification>
1. Archive directory exists: .archive/external-packages/2026-02-03/
2. fredtools2 package copied with src/, pyproject.toml (~6 Python files)
3. fedtools2 package copied with src/, pyproject.toml (~11 Python files)
4. ALTERNATIVES.md covers all 4 dimensions (feature mapping, API comparison, migration effort, ecosystem maturity)
5. manifest.json has $schema versioning and SHA256 checksums
6. README.md documents archive rationale and restoration
7. dependencies_snapshot.txt captures full dependency tree
8. No __pycache__ or .git directories in archive
</verification>

<success_criteria>
- fredtools2 and fedtools2 packages preserved in .archive/external-packages/2026-02-03/
- ALTERNATIVES.md contains all 4 context-required dimensions with code examples
- manifest.json validates with $schema, checksums, and full provenance
- README.md provides clear restoration path
- dependencies_snapshot.txt enables reproducible restoration
- Archive follows established Phase 12/14 patterns
</success_criteria>

<output>
After completion, create `.planning/phases/15-economic-data-strategy/15-01-SUMMARY.md`
</output>
