---
phase: 09-integration-observability
plan: 03
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - tests/observability/test_tracing.py
  - tests/observability/test_metrics_collection.py
  - tests/observability/test_health_checks.py
  - tests/observability/test_workflow_state.py
autonomous: true

must_haves:
  truths:
    - "Tracing tests verify correlation ID generation and span creation"
    - "Metrics tests verify counter/gauge/histogram recording and querying"
    - "Health check tests verify liveness, readiness, startup probes"
    - "Workflow state tests verify state transitions and persistence"
  artifacts:
    - path: "tests/observability/test_tracing.py"
      provides: "Tests for tracing module"
      contains: "test_correlation_id_format"
    - path: "tests/observability/test_metrics_collection.py"
      provides: "Tests for metrics collection"
      contains: "test_counter_increment"
    - path: "tests/observability/test_health_checks.py"
      provides: "Tests for health check probes"
      contains: "test_liveness_always_healthy"
    - path: "tests/observability/test_workflow_state.py"
      provides: "Tests for workflow state tracking"
      contains: "test_workflow_transitions"
  key_links:
    - from: "tests/observability/test_tracing.py"
      to: "src/ta_lab2/observability/tracing.py"
      via: "imports and tests"
      pattern: "from ta_lab2.observability.tracing import"
---

<objective>
Create comprehensive tests for observability infrastructure (tracing, metrics, health checks, workflow state).

Purpose: Validate that the observability infrastructure from Plan 09-01 works correctly. These are the "observability infrastructure tests" referenced in success criteria - they test the observability module itself, not gap/validation tests.

Output: tests/observability/ with test files for each observability component.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/09-integration-observability/09-CONTEXT.md
@.planning/phases/09-integration-observability/09-01-PLAN.md

# Pattern reference
@tests/features/test_validate_features.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create tracing and metrics tests</name>
  <files>
    tests/observability/test_tracing.py
    tests/observability/test_metrics_collection.py
  </files>
  <action>
    Create tests for tracing and metrics modules.

    1. Create tests/observability/test_tracing.py:

    ```python
    """Tests for OpenTelemetry tracing integration."""

    import pytest
    from unittest.mock import MagicMock, patch


    @pytest.mark.observability
    @pytest.mark.mocked_deps
    class TestTracingModule:
        """Tests for tracing.py functionality."""

        def test_generate_correlation_id_format(self):
            """Test correlation ID is 32-char hex string."""
            from ta_lab2.observability.tracing import generate_correlation_id

            cid = generate_correlation_id()

            assert len(cid) == 32, f"Expected 32 chars, got {len(cid)}"
            assert all(c in '0123456789abcdef' for c in cid), "Expected hex chars only"

        def test_generate_correlation_id_unique(self):
            """Test correlation IDs are unique."""
            from ta_lab2.observability.tracing import generate_correlation_id

            ids = [generate_correlation_id() for _ in range(100)]
            assert len(set(ids)) == 100, "Expected unique IDs"

        def test_tracing_context_creates_span(self, mocker):
            """Test TracingContext creates and ends span."""
            from ta_lab2.observability.tracing import TracingContext

            with TracingContext("test_operation") as ctx:
                assert ctx.trace_id is not None
                assert len(ctx.trace_id) == 32

        def test_tracing_context_attributes(self, mocker):
            """Test TracingContext can set attributes."""
            from ta_lab2.observability.tracing import TracingContext

            with TracingContext("test_operation") as ctx:
                ctx.set_attribute("test_key", "test_value")
                # Should not raise

        def test_tracing_context_events(self, mocker):
            """Test TracingContext can add events."""
            from ta_lab2.observability.tracing import TracingContext

            with TracingContext("test_operation") as ctx:
                ctx.add_event("test_event", {"key": "value"})
                # Should not raise

        def test_tracing_context_exception_handling(self):
            """Test TracingContext records exceptions."""
            from ta_lab2.observability.tracing import TracingContext

            with pytest.raises(ValueError):
                with TracingContext("failing_operation"):
                    raise ValueError("Test error")

        def test_setup_tracing_returns_tracer(self, mocker):
            """Test setup_tracing returns a tracer."""
            from ta_lab2.observability.tracing import setup_tracing

            mock_engine = mocker.MagicMock()
            tracer = setup_tracing("test_service", engine=mock_engine)

            assert tracer is not None
    ```

    2. Create tests/observability/test_metrics_collection.py:

    ```python
    """Tests for metrics collection module."""

    import pytest
    from unittest.mock import MagicMock, patch
    from datetime import datetime


    @pytest.mark.observability
    @pytest.mark.mocked_deps
    class TestMetricsCollector:
        """Tests for MetricsCollector class."""

        def test_counter_increment(self, mocker):
            """Test counter increments value."""
            from ta_lab2.observability.metrics import MetricsCollector

            mock_engine = mocker.MagicMock()
            collector = MetricsCollector(mock_engine)

            collector.counter("test_counter", value=1, service="test")

            # Verify insert was called
            mock_engine.begin.assert_called()

        def test_gauge_set_value(self, mocker):
            """Test gauge sets absolute value."""
            from ta_lab2.observability.metrics import MetricsCollector

            mock_engine = mocker.MagicMock()
            collector = MetricsCollector(mock_engine)

            collector.gauge("test_gauge", value=42.5, service="test")

            mock_engine.begin.assert_called()

        def test_histogram_with_labels(self, mocker):
            """Test histogram records with labels."""
            from ta_lab2.observability.metrics import MetricsCollector

            mock_engine = mocker.MagicMock()
            collector = MetricsCollector(mock_engine)

            collector.histogram("request_duration", value=0.125, endpoint="/api/test")

            mock_engine.begin.assert_called()

        def test_metric_dataclass(self):
            """Test Metric dataclass structure."""
            from ta_lab2.observability.metrics import Metric

            metric = Metric(
                name="test_metric",
                value=1.0,
                metric_type="counter",
                timestamp=datetime.utcnow(),
                labels={"env": "test"}
            )

            assert metric.name == "test_metric"
            assert metric.metric_type == "counter"
            assert "env" in metric.labels

        def test_record_metric(self, mocker):
            """Test record() stores metric to database."""
            from ta_lab2.observability.metrics import MetricsCollector, Metric

            mock_engine = mocker.MagicMock()
            collector = MetricsCollector(mock_engine)

            metric = Metric(
                name="test",
                value=1.0,
                metric_type="counter",
                timestamp=datetime.utcnow(),
                labels={}
            )

            collector.record(metric)
            mock_engine.begin.assert_called()
    ```
  </action>
  <verify>
    pytest tests/observability/test_tracing.py tests/observability/test_metrics_collection.py -v -m mocked_deps
  </verify>
  <done>
    Tracing tests verify correlation ID format, uniqueness, context manager, and exception handling. Metrics tests verify counter/gauge/histogram recording.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create health check and workflow state tests</name>
  <files>
    tests/observability/test_health_checks.py
    tests/observability/test_workflow_state.py
  </files>
  <action>
    Create tests for health checks and workflow state tracking.

    1. Create tests/observability/test_health_checks.py:

    ```python
    """Tests for health check probes."""

    import pytest
    from unittest.mock import MagicMock
    from datetime import datetime


    @pytest.mark.observability
    @pytest.mark.mocked_deps
    class TestHealthChecker:
        """Tests for HealthChecker class."""

        def test_liveness_always_healthy(self, mocker):
            """Test liveness probe always returns healthy (process alive)."""
            from ta_lab2.observability.health import HealthChecker

            mock_engine = mocker.MagicMock()
            checker = HealthChecker(mock_engine)

            status = checker.liveness()

            assert status.healthy is True
            assert "alive" in status.message.lower()

        def test_readiness_checks_database(self, mocker):
            """Test readiness probe checks database connection."""
            from ta_lab2.observability.health import HealthChecker

            mock_engine = mocker.MagicMock()
            mock_conn = mocker.MagicMock()
            mock_engine.connect.return_value.__enter__.return_value = mock_conn
            mock_conn.execute.return_value.scalar.return_value = 1

            checker = HealthChecker(mock_engine)
            status = checker.readiness()

            assert status.healthy is True
            assert "database" in status.details

        def test_readiness_fails_on_db_error(self, mocker):
            """Test readiness fails when database unavailable."""
            from ta_lab2.observability.health import HealthChecker

            mock_engine = mocker.MagicMock()
            mock_engine.connect.side_effect = Exception("Connection refused")

            checker = HealthChecker(mock_engine)
            status = checker.readiness()

            assert status.healthy is False
            assert "database" in status.details
            assert status.details["database"] is False

        def test_readiness_checks_memory_if_configured(self, mocker):
            """Test readiness checks memory service when configured."""
            from ta_lab2.observability.health import HealthChecker

            mock_engine = mocker.MagicMock()
            mock_conn = mocker.MagicMock()
            mock_engine.connect.return_value.__enter__.return_value = mock_conn
            mock_conn.execute.return_value.scalar.return_value = 1

            mock_memory = mocker.MagicMock()
            mock_memory.health_check.return_value = {"status": "healthy"}

            checker = HealthChecker(mock_engine, memory_client=mock_memory)
            status = checker.readiness()

            assert status.healthy is True
            assert "memory" in status.details

        def test_startup_checks_data_loaded(self, mocker):
            """Test startup probe checks if initial data loaded."""
            from ta_lab2.observability.health import HealthChecker

            mock_engine = mocker.MagicMock()
            mock_conn = mocker.MagicMock()
            mock_engine.connect.return_value.__enter__.return_value = mock_conn
            # dim_timeframe has rows
            mock_conn.execute.return_value.scalar.return_value = 199

            checker = HealthChecker(mock_engine)
            status = checker.startup()

            assert status.healthy is True
            assert checker.startup_complete is True

        def test_startup_fails_when_no_data(self, mocker):
            """Test startup fails when initial data not loaded."""
            from ta_lab2.observability.health import HealthChecker

            mock_engine = mocker.MagicMock()
            mock_conn = mocker.MagicMock()
            mock_engine.connect.return_value.__enter__.return_value = mock_conn
            # dim_timeframe empty
            mock_conn.execute.return_value.scalar.return_value = 0

            checker = HealthChecker(mock_engine)
            status = checker.startup()

            assert status.healthy is False
            assert checker.startup_complete is False

        def test_health_status_dataclass(self):
            """Test HealthStatus dataclass structure."""
            from ta_lab2.observability.health import HealthStatus

            status = HealthStatus(
                healthy=True,
                message="All systems operational",
                checked_at=datetime.utcnow(),
                details={"db": True, "memory": True}
            )

            assert status.healthy is True
            assert status.details["db"] is True
    ```

    2. Create tests/observability/test_workflow_state.py:

    ```python
    """Tests for workflow state tracking."""

    import pytest
    from unittest.mock import MagicMock, call
    import uuid


    @pytest.mark.observability
    @pytest.mark.mocked_deps
    class TestWorkflowStateTracker:
        """Tests for WorkflowStateTracker class."""

        def test_create_workflow(self, mocker):
            """Test creating new workflow state."""
            from ta_lab2.observability.storage import WorkflowStateTracker

            mock_engine = mocker.MagicMock()
            tracker = WorkflowStateTracker(mock_engine)

            workflow_id = str(uuid.uuid4())
            correlation_id = "a" * 32
            tracker.create_workflow(workflow_id, correlation_id, "orchestrator_task")

            mock_engine.begin.assert_called()

        def test_transition_updates_state(self, mocker):
            """Test transitioning workflow to new phase."""
            from ta_lab2.observability.storage import WorkflowStateTracker

            mock_engine = mocker.MagicMock()
            tracker = WorkflowStateTracker(mock_engine)

            workflow_id = str(uuid.uuid4())
            tracker.transition(workflow_id, "executing", "running")

            mock_engine.begin.assert_called()

        def test_transition_with_metadata(self, mocker):
            """Test transition with metadata."""
            from ta_lab2.observability.storage import WorkflowStateTracker

            mock_engine = mocker.MagicMock()
            tracker = WorkflowStateTracker(mock_engine)

            workflow_id = str(uuid.uuid4())
            metadata = {"task_id": "test-123", "platform": "gemini"}
            tracker.transition(workflow_id, "completed", "completed", metadata=metadata)

            mock_engine.begin.assert_called()

        def test_get_workflow(self, mocker):
            """Test retrieving workflow state."""
            from ta_lab2.observability.storage import WorkflowStateTracker

            mock_engine = mocker.MagicMock()
            mock_conn = mocker.MagicMock()
            mock_engine.connect.return_value.__enter__.return_value = mock_conn
            mock_conn.execute.return_value.fetchone.return_value = (
                "wf-123", "corr-456", "orchestrator_task", "executing", "running"
            )

            tracker = WorkflowStateTracker(mock_engine)
            result = tracker.get_workflow("wf-123")

            assert result is not None

        def test_list_workflows(self, mocker):
            """Test listing workflows by status."""
            from ta_lab2.observability.storage import WorkflowStateTracker

            mock_engine = mocker.MagicMock()
            mock_conn = mocker.MagicMock()
            mock_engine.connect.return_value.__enter__.return_value = mock_conn
            mock_conn.execute.return_value.fetchall.return_value = [
                ("wf-1", "corr-1", "task", "running"),
                ("wf-2", "corr-2", "task", "running"),
            ]

            tracker = WorkflowStateTracker(mock_engine)
            results = tracker.list_workflows(status="running", limit=10)

            assert len(results) == 2

        def test_workflow_lifecycle(self, mocker):
            """Test complete workflow lifecycle: create -> transition -> complete."""
            from ta_lab2.observability.storage import WorkflowStateTracker

            mock_engine = mocker.MagicMock()
            tracker = WorkflowStateTracker(mock_engine)

            workflow_id = str(uuid.uuid4())
            correlation_id = "b" * 32

            # Create
            tracker.create_workflow(workflow_id, correlation_id, "feature_refresh")

            # Transitions
            tracker.transition(workflow_id, "routing", "running")
            tracker.transition(workflow_id, "executing", "running")
            tracker.transition(workflow_id, "completed", "completed")

            # Verify 4 database calls (create + 3 transitions)
            assert mock_engine.begin.call_count == 4
    ```
  </action>
  <verify>
    pytest tests/observability/test_health_checks.py tests/observability/test_workflow_state.py -v -m mocked_deps
  </verify>
  <done>
    Health check tests verify liveness/readiness/startup probes. Workflow state tests verify create/transition/get/list operations.
  </done>
</task>

</tasks>

<verification>
```bash
# Run all observability tests
pytest tests/observability/ -v -m mocked_deps

# Verify test count
pytest tests/observability/ --collect-only -q | tail -1

# Check for failures
pytest tests/observability/ -m mocked_deps --tb=short
```
</verification>

<success_criteria>
- tests/observability/test_tracing.py has tests for correlation ID format, uniqueness, context manager
- tests/observability/test_metrics_collection.py has tests for counter, gauge, histogram
- tests/observability/test_health_checks.py has tests for liveness, readiness, startup probes
- tests/observability/test_workflow_state.py has tests for create, transition, get, list workflows
- All tests pass with pytest -m mocked_deps (no real infrastructure required)
- Test coverage includes error scenarios and edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/09-integration-observability/09-03-SUMMARY.md`
</output>
