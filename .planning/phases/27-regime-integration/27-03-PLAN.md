---
phase: 27-regime-integration
plan: 03
type: execute
wave: 2
depends_on: ["27-01", "27-02"]
files_modified:
  - src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py
autonomous: true

must_haves:
  truths:
    - "refresh_cmc_regimes.py loads bars+EMAs from DB, runs labelers, resolves policy, and writes to cmc_regimes"
    - "Data budget correctly auto-disables layers when bar history is insufficient"
    - "EMA column mapping produces correct labels (not all-Sideways from NaN fallback)"
    - "Scoped DELETE + INSERT write pattern matches feature pipeline conventions"
  artifacts:
    - path: "src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py"
      provides: "Core regime refresh script"
      exports: ["main", "compute_regimes_for_id", "write_regimes_to_db"]
      min_lines: 200
  key_links:
    - from: "src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py"
      to: "src/ta_lab2/scripts/regimes/regime_data_loader.py"
      via: "import load_regime_input_data"
      pattern: "from.*regime_data_loader import"
    - from: "src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py"
      to: "src/ta_lab2/regimes/labels.py"
      via: "import label_layer_monthly, label_layer_weekly, label_layer_daily"
      pattern: "from ta_lab2.regimes.labels import"
    - from: "src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py"
      to: "src/ta_lab2/regimes/resolver.py"
      via: "import resolve_policy_from_table"
      pattern: "from ta_lab2.regimes.resolver import"
    - from: "src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py"
      to: "cmc_regimes table"
      via: "scoped DELETE + INSERT"
      pattern: "DELETE FROM.*cmc_regimes"
---

<objective>
Build the core refresh_cmc_regimes.py script that orchestrates regime labeling from DB data.

Purpose: This is the central script that connects the existing regime module to the DB-backed pipeline. It loads bars+EMAs, runs L0-L2 labeling, resolves policy via tighten-only semantics, and writes results to cmc_regimes.
Output: Working refresh_cmc_regimes.py with CLI, per-asset processing, and DB write.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/27-regime-integration/27-RESEARCH.md
@src/ta_lab2/regimes/labels.py
@src/ta_lab2/regimes/resolver.py
@src/ta_lab2/regimes/data_budget.py
@src/ta_lab2/regimes/policy_loader.py
@src/ta_lab2/scripts/features/base_feature.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build compute_regimes_for_id function</name>
  <files>
    src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py
  </files>
  <action>
Create `refresh_cmc_regimes.py` with the core per-asset computation function.

**compute_regimes_for_id(engine, asset_id, policy_table, cal_scheme="iso", min_bars_overrides=None):**
1. Call `load_regime_input_data(engine, asset_id, cal_scheme)` to get monthly/weekly/daily DataFrames
2. Call `assess_data_budget(monthly=monthly, weekly=weekly, daily=daily)` to get DataBudgetContext
3. Determine mode from context: `ctx.feature_tier` ("full" or "lite")
4. Label each enabled layer:
   - L0: `label_layer_monthly(monthly, mode=mode)` if ctx.enabled_layers["L0"] else None
   - L1: `label_layer_weekly(weekly, mode=mode)` if ctx.enabled_layers["L1"] else None
   - L2: `label_layer_daily(daily, mode=mode)` if ctx.enabled_layers["L2"] else None
   - L3, L4: None (auto-disabled, no intraday data)
5. Forward-fill multi-TF labels to daily index:
   - Use pd.merge_asof to align monthly labels (L0) and weekly labels (L1) onto daily timestamps
   - The daily index is the output timeframe (all regimes expressed as daily rows)
   - L0 labels are sparse (one per month) -> forward-fill to daily
   - L1 labels are sparse (one per week) -> forward-fill to daily
   - L2 labels are already daily
6. For each daily row, resolve policy:
   - Call `resolve_policy_from_table(policy_table, L0=l0_val, L1=l1_val, L2=l2_val)`
   - This returns a TightenOnlyPolicy object with size_mult, stop_mult, orders, gross_cap, pyramids
7. Build regime_key: Use the L2 (daily) label as primary key, or compose from available layers
   - If L2 exists, regime_key = L2 label value (e.g., "Up-Normal-Normal")
   - Fallback to L1 if L2 disabled, then L0
8. Compute version_hash: hashlib.sha256 of sorted(policy_table keys) + code version
9. Build output DataFrame with columns matching cmc_regimes schema:
   - id, ts, tf='1D', l0_label, l1_label, l2_label, l3_label=None, l4_label=None
   - regime_key, size_mult, stop_mult, orders, gross_cap, pyramids
   - feature_tier, l0_enabled, l1_enabled, l2_enabled
   - regime_version_hash, updated_at=pd.Timestamp.now(tz='UTC')
10. Return the output DataFrame (or empty DataFrame if no daily data)

IMPORTANT implementation details:
- For merge_asof alignment: daily["ts"] must be sorted. Monthly/weekly labels need a "ts" column.
  The label Series from labelers is indexed by the original DataFrame index. Build a small DataFrame with (id, ts, label_value) and merge_asof onto the daily ts column.
- Handle case where monthly/weekly DataFrames are empty (young asset with no calendar bars) -- data budget will auto-disable those layers.
- The output is ONE row per daily bar per asset (tf='1D' for now). Multi-TF regime output is deferred.
- Use logging (import logging, logger = logging.getLogger(__name__)) for all info/debug messages.
  </action>
  <verify>
Verify the function imports and basic structure:
```python
python -c "
from ta_lab2.scripts.regimes.refresh_cmc_regimes import compute_regimes_for_id
print('Import OK: compute_regimes_for_id')
"
```
  </verify>
  <done>compute_regimes_for_id loads data, runs labelers with correct column mapping, forward-fills multi-TF labels, resolves policy, and returns DataFrame matching cmc_regimes schema.</done>
</task>

<task type="auto">
  <name>Task 2: Add write_regimes_to_db and CLI entrypoint</name>
  <files>
    src/ta_lab2/scripts/regimes/refresh_cmc_regimes.py
  </files>
  <action>
Add to the same file created in Task 1:

**write_regimes_to_db(engine, df, tf='1D'):**
- Uses scoped DELETE + INSERT pattern (matching BaseFeature.write_to_db):
  ```python
  ids = df["id"].unique().tolist()
  with engine.begin() as conn:
      conn.execute(
          text("DELETE FROM public.cmc_regimes WHERE id = ANY(:ids) AND tf = :tf"),
          {"ids": ids, "tf": tf},
      )
  df.to_sql("cmc_regimes", engine, schema="public", if_exists="append",
            index=False, method="multi", chunksize=5000)
  ```
- Returns number of rows written
- Log rows written per asset

**CLI main() function:**
- argparse with these flags:
  - `--ids` (comma-separated) or `--all` (query dim_assets for all active ids)
  - `--cal-scheme` (default "iso", choices ["iso", "us"])
  - `--policy-file` (optional Path to YAML overlay for policy table)
  - `--dry-run` (compute but don't write)
  - `--verbose` / `-v`
  - `--db-url` (or from TARGET_DB_URL env)
  - `--min-bars-l0`, `--min-bars-l1`, `--min-bars-l2` (override min bar thresholds)
- Flow:
  1. Parse args, resolve DB URL
  2. Load policy table: `load_policy_table(args.policy_file)` if provided, else DEFAULT_POLICY_TABLE
  3. Get asset IDs (from --ids or query all active)
  4. For each asset_id:
     a. Call compute_regimes_for_id(engine, asset_id, policy_table, cal_scheme)
     b. Log summary (layers enabled, regime_key distribution)
     c. If not dry_run: call write_regimes_to_db(engine, df)
  5. Print summary: total assets processed, total rows written, time elapsed
- Module entry: `if __name__ == "__main__": sys.exit(main())`
- Also add: `python -m ta_lab2.scripts.regimes.refresh_cmc_regimes` support

Query for all asset IDs (when --all):
```python
with engine.connect() as conn:
    result = conn.execute(text("SELECT DISTINCT id FROM public.dim_assets WHERE is_active = TRUE ORDER BY id"))
    ids = [row[0] for row in result]
```
If dim_assets doesn't have is_active, fall back to:
```python
with engine.connect() as conn:
    result = conn.execute(text("SELECT DISTINCT id FROM public.cmc_price_bars_multi_tf WHERE tf = '1D' ORDER BY id"))
    ids = [row[0] for row in result]
```
  </action>
  <verify>
```bash
python -m ta_lab2.scripts.regimes.refresh_cmc_regimes --help
```
Should print usage with all flags. Also:
```bash
python -m ta_lab2.scripts.regimes.refresh_cmc_regimes --ids 1 --dry-run --verbose
```
Should run without writing, showing regime labels for Bitcoin (id=1).
  </verify>
  <done>
- refresh_cmc_regimes.py has working CLI with --ids, --all, --cal-scheme, --policy-file, --dry-run
- Scoped DELETE + INSERT write pattern works
- Dry run shows computed regime labels without writing
- At least one asset (BTC, id=1) produces regime labels from DB data
  </done>
</task>

</tasks>

<verification>
- `python -m ta_lab2.scripts.regimes.refresh_cmc_regimes --ids 1 --dry-run -v` succeeds
- Output shows L0/L1/L2 labels, regime_key, policy fields
- Data budget correctly enables/disables layers based on available bar history
- Column names passed to labelers match exactly (close_ema_20, etc.)
</verification>

<success_criteria>
- refresh_cmc_regimes.py computes regimes for at least one asset from DB data
- Labelers produce non-trivial labels (not all Sideways from NaN columns)
- Policy resolver produces correct size_mult/stop_mult values
- Write path uses scoped DELETE + INSERT matching project conventions
</success_criteria>

<output>
After completion, create `.planning/phases/27-regime-integration/27-03-SUMMARY.md`
</output>
