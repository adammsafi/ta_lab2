---
phase: 07-ta_lab2-feature-pipeline
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/ta_lab2/scripts/features/base_feature.py
  - src/ta_lab2/features/feature_utils.py
  - tests/features/test_base_feature.py
  - tests/features/test_feature_utils.py
autonomous: true

must_haves:
  truths:
    - "BaseFeature provides template method pattern for feature computation"
    - "Null handling utilities implement skip, forward_fill, and interpolate strategies"
    - "Feature normalization (z-score) is available as utility function"
  artifacts:
    - path: "src/ta_lab2/scripts/features/base_feature.py"
      provides: "Abstract base class for features"
      exports: ["BaseFeature", "FeatureConfig"]
    - path: "src/ta_lab2/features/feature_utils.py"
      provides: "Null handling and normalization utilities"
      exports: ["apply_null_strategy", "add_zscore", "validate_min_data_points"]
    - path: "tests/features/test_base_feature.py"
      provides: "Tests for base feature class"
      min_lines: 100
    - path: "tests/features/test_feature_utils.py"
      provides: "Tests for null handling utilities"
      min_lines: 150
  key_links:
    - from: "base_feature.py"
      to: "BaseEMAFeature pattern"
      via: "ABC, abstractmethod, template method"
      pattern: "class BaseFeature.*ABC"
    - from: "feature_utils.py"
      to: "pandas"
      via: "interpolate, ffill, dropna"
      pattern: "def apply_null_strategy"
---

<objective>
Create the BaseFeature abstract class (following BaseEMAFeature pattern) and null handling utilities.

Purpose: Provides reusable foundation for returns, volatility, and TA feature modules with configurable null handling.
Output: Base class, null handling utilities, normalization helpers, and comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-ta_lab2-feature-pipeline/07-CONTEXT.md

# Key existing patterns to follow:
@src/ta_lab2/features/m_tf/base_ema_feature.py
@src/ta_lab2/features/returns.py
@src/ta_lab2/features/vol.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create feature_utils.py with null handling and normalization</name>
  <files>
    src/ta_lab2/features/feature_utils.py
  </files>
  <action>
    Create utility functions for null handling and feature normalization.

    **Null handling strategies (per CONTEXT.md decisions):**

    ```python
    def apply_null_strategy(
        series: pd.Series,
        strategy: str,
        *,
        limit: Optional[int] = None,
    ) -> pd.Series:
        """
        Apply null handling strategy to a series.

        Args:
            series: Input series with potential NULLs
            strategy: One of 'skip', 'forward_fill', 'interpolate'
            limit: Max consecutive NULLs to fill (None = unlimited)

        Returns:
            Series with nulls handled according to strategy

        Strategies:
        - 'skip': Return series as-is (calculations skip NULLs naturally)
        - 'forward_fill': ffill() then bfill() for leading NULLs
        - 'interpolate': Linear interpolation with limit
        """
    ```

    **Normalization utilities:**

    ```python
    def add_zscore(
        df: pd.DataFrame,
        col: str,
        *,
        window: int = 252,
        out_col: Optional[str] = None,
    ) -> pd.DataFrame:
        """
        Add rolling z-score column.

        z = (x - rolling_mean) / rolling_std

        Args:
            df: DataFrame with feature column
            col: Column name to normalize
            window: Rolling window for mean/std (default 252 = 1 year)
            out_col: Output column name (default: {col}_zscore)
        """
    ```

    **Data quality validation:**

    ```python
    def validate_min_data_points(
        series: pd.Series,
        min_required: int,
        feature_name: str,
    ) -> tuple[bool, int]:
        """
        Validate series has minimum required data points.

        Returns:
            (is_valid, actual_count)
        """

    def flag_outliers(
        series: pd.Series,
        *,
        n_sigma: float = 4.0,
        method: str = 'zscore',
    ) -> pd.Series:
        """
        Return boolean series marking outliers.

        Per CONTEXT.md: Flag but keep - mark as outlier, preserve original.

        Args:
            series: Input series
            n_sigma: Number of std devs for outlier threshold
            method: 'zscore' or 'iqr'

        Returns:
            Boolean series (True = outlier)
        """
    ```

    Include comprehensive docstrings with examples.
  </action>
  <verify>
    python -c "from ta_lab2.features.feature_utils import apply_null_strategy, add_zscore, validate_min_data_points, flag_outliers; print('imports OK')"
  </verify>
  <done>
    All utility functions import successfully with correct signatures
  </done>
</task>

<task type="auto">
  <name>Task 2: Create BaseFeature abstract class</name>
  <files>
    src/ta_lab2/scripts/features/base_feature.py
  </files>
  <action>
    Create abstract base class following BaseEMAFeature template pattern.

    **FeatureConfig dataclass:**
    ```python
    @dataclass(frozen=True)
    class FeatureConfig:
        feature_type: str           # 'returns', 'vol', 'ta'
        output_schema: str = "public"
        output_table: str = ""      # Set by subclass
        null_strategy: str = "skip"
        add_zscore: bool = True
        zscore_window: int = 252
    ```

    **BaseFeature abstract class:**
    ```python
    class BaseFeature(ABC):
        """
        Abstract base class for feature computation modules.

        Template Method Pattern (same as BaseEMAFeature):
        - Defines computation flow (load -> compute -> normalize -> write)
        - Delegates specifics to subclasses
        - Standardizes null handling, normalization, DB operations

        Subclasses must implement:
        - load_source_data(ids, start, end): Load price/bar data
        - compute_features(df_source): Core feature computation
        - get_output_schema(): Define output table schema
        - get_feature_columns(): List of computed feature columns
        """

        def __init__(self, engine: Engine, config: FeatureConfig):
            self.engine = engine
            self.config = config

        # Abstract methods (MUST override)
        @abstractmethod
        def load_source_data(self, ids, start, end) -> pd.DataFrame: ...

        @abstractmethod
        def compute_features(self, df_source: pd.DataFrame) -> pd.DataFrame: ...

        @abstractmethod
        def get_output_schema(self) -> dict[str, str]: ...

        @abstractmethod
        def get_feature_columns(self) -> list[str]: ...

        # Template method (concrete - defines flow)
        def compute_for_ids(self, ids, start=None, end=None) -> int:
            """
            Compute features for given IDs.

            Flow:
            1. Load source data
            2. Apply null handling (from config)
            3. Compute features
            4. Add z-score if configured
            5. Flag outliers
            6. Write to database

            Returns: Number of rows written
            """

        # Helper methods
        def apply_null_handling(self, df, cols): ...
        def add_normalizations(self, df): ...
        def write_to_db(self, df) -> int: ...
        def _ensure_output_table(self): ...
    ```

    Follow BaseEMAFeature structure exactly for consistency.
  </action>
  <verify>
    python -c "from ta_lab2.scripts.features.base_feature import BaseFeature, FeatureConfig; print('imports OK')"
  </verify>
  <done>
    BaseFeature class imports with all abstract methods defined
  </done>
</task>

<task type="auto">
  <name>Task 3: Create unit tests for utilities and base class</name>
  <files>
    tests/features/test_feature_utils.py
    tests/features/test_base_feature.py
  </files>
  <action>
    Create comprehensive unit tests for both modules.

    **test_feature_utils.py tests:**
    1. test_apply_null_strategy_skip - Series unchanged
    2. test_apply_null_strategy_forward_fill - NULLs filled forward
    3. test_apply_null_strategy_forward_fill_with_limit - Respects limit
    4. test_apply_null_strategy_interpolate - Linear interpolation
    5. test_apply_null_strategy_invalid - Raises ValueError
    6. test_add_zscore_basic - Correct z-score calculation
    7. test_add_zscore_custom_window - Respects window param
    8. test_add_zscore_custom_output_col - Correct output name
    9. test_validate_min_data_points_valid - Returns (True, count)
    10. test_validate_min_data_points_invalid - Returns (False, count)
    11. test_flag_outliers_zscore - Correct outlier flagging
    12. test_flag_outliers_iqr - IQR method works
    13. test_flag_outliers_no_outliers - All False when no outliers

    **test_base_feature.py tests:**
    1. test_feature_config_defaults - Default values correct
    2. test_feature_config_custom - Custom values preserved
    3. test_base_feature_is_abstract - Cannot instantiate directly
    4. test_concrete_feature_computes - Mock subclass works
    5. test_compute_for_ids_flow - Template method calls in order
    6. test_apply_null_handling - Delegates to feature_utils
    7. test_add_normalizations - Adds z-score when configured
    8. test_write_to_db - Calls pandas to_sql correctly

    Use unittest.mock throughout - no database required.
  </action>
  <verify>
    pytest tests/features/test_feature_utils.py tests/features/test_base_feature.py -v
    All tests pass (expect 20+ tests)
  </verify>
  <done>
    All unit tests pass, comprehensive coverage of utilities and base class
  </done>
</task>

</tasks>

<verification>
- [ ] apply_null_strategy handles all three strategies correctly
- [ ] add_zscore produces correct rolling z-scores
- [ ] flag_outliers identifies extreme values without removing them
- [ ] BaseFeature follows BaseEMAFeature template pattern exactly
- [ ] All 20+ unit tests pass without database
</verification>

<success_criteria>
- Null handling utilities work for skip, forward_fill, and interpolate
- Z-score normalization produces correct rolling values
- Outlier flagging marks extremes without data loss (per CONTEXT.md)
- BaseFeature provides clean template for subclasses
- Test coverage includes edge cases (empty series, all nulls, no outliers)
</success_criteria>

<output>
After completion, create `.planning/phases/07-ta_lab2-feature-pipeline/07-02-SUMMARY.md`
</output>
