---
phase: 02-memory-core-chromadb-integration
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/memory/update.py
  - src/ta_lab2/tools/ai_orchestrator/memory/__init__.py
  - tests/orchestrator/test_memory_update.py
autonomous: true

must_haves:
  truths:
    - "New memories can be added without corrupting existing embeddings"
    - "Adding duplicate memory IDs updates content without errors"
    - "Embedding generation uses same model as existing 3,763 memories"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/memory/update.py"
      provides: "Incremental memory update pipeline"
      exports: ["add_memories", "add_memory", "MemoryUpdateResult", "MemoryInput", "delete_memory", "get_embedding"]
    - path: "tests/orchestrator/test_memory_update.py"
      provides: "Update pipeline tests"
      min_lines: 60
  key_links:
    - from: "src/ta_lab2/tools/ai_orchestrator/memory/update.py"
      to: "OpenAI embeddings API"
      via: "openai.embeddings.create"
      pattern: "client\\.embeddings\\.create"
    - from: "src/ta_lab2/tools/ai_orchestrator/memory/update.py"
      to: "memory/client.py"
      via: "get_memory_client import"
      pattern: "from.*client.*import.*get_memory_client"
---

<objective>
Incremental memory update pipeline with batch embedding generation (MEMO-07)

Purpose: Enable adding new memories to ChromaDB without breaking the existing 3,763 embeddings. Uses OpenAI text-embedding-3-small model (same as existing memories) and ChromaDB upsert for atomic add-or-update operations.

Output: add_memories() function with batch embedding, upsert logic, validation, and comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-memory-core-chromadb-integration/02-RESEARCH.md

# Depends on client from Wave 1
@.planning/phases/02-memory-core-chromadb-integration/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create incremental update module</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/update.py</files>
  <action>
Create memory/update.py with incremental update functions:

```python
"""Incremental memory update pipeline.

Adds new memories without breaking existing embeddings.
Implements MEMO-07: Incremental update pipeline.
"""
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

# Embedding model constants (from existing 3,763 memories)
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIMENSIONS = 1536


@dataclass
class MemoryInput:
    """Input for adding a new memory."""

    memory_id: str
    content: str
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class MemoryUpdateResult:
    """Result of memory update operation."""

    added: int = 0
    updated: int = 0
    failed: int = 0
    errors: List[str] = field(default_factory=list)
    duration_ms: float = 0.0

    @property
    def total_processed(self) -> int:
        return self.added + self.updated + self.failed

    def __str__(self) -> str:
        return (
            f"MemoryUpdate: added={self.added}, updated={self.updated}, "
            f"failed={self.failed}, duration={self.duration_ms:.1f}ms"
        )


def get_embedding(
    texts: List[str],
    model: str = EMBEDDING_MODEL
) -> List[List[float]]:
    """Generate embeddings using OpenAI API.

    Args:
        texts: List of texts to embed
        model: OpenAI embedding model name

    Returns:
        List of embedding vectors (1536 dimensions each)

    Raises:
        ValueError: If OpenAI API key not configured
        Exception: If API call fails
    """
    try:
        from openai import OpenAI
    except ImportError:
        raise ImportError("openai package required. Install with: pip install openai")

    import os
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        from ta_lab2.tools.ai_orchestrator.config import load_config
        config = load_config()
        api_key = config.openai_api_key

    if not api_key:
        raise ValueError("OPENAI_API_KEY not configured")

    client = OpenAI(api_key=api_key)

    # Clean texts (replace newlines with spaces)
    cleaned_texts = [text.replace("\n", " ").strip() for text in texts]

    response = client.embeddings.create(
        input=cleaned_texts,
        model=model
    )

    embeddings = [item.embedding for item in response.data]

    # Validate dimensions
    for i, emb in enumerate(embeddings):
        if len(emb) != EMBEDDING_DIMENSIONS:
            raise ValueError(
                f"Embedding {i} has {len(emb)} dimensions, expected {EMBEDDING_DIMENSIONS}"
            )

    return embeddings


def add_memory(
    memory_id: str,
    content: str,
    metadata: Optional[Dict[str, Any]] = None,
    client=None
) -> MemoryUpdateResult:
    """Add a single memory to the store.

    Uses upsert to handle duplicates gracefully.

    Args:
        memory_id: Unique identifier for the memory
        content: Text content of the memory
        metadata: Optional metadata dict
        client: Optional MemoryClient instance

    Returns:
        MemoryUpdateResult with operation details
    """
    return add_memories(
        memories=[MemoryInput(
            memory_id=memory_id,
            content=content,
            metadata=metadata or {}
        )],
        client=client
    )


def add_memories(
    memories: List[MemoryInput],
    batch_size: int = 50,
    client=None
) -> MemoryUpdateResult:
    """Add multiple memories with batch embedding generation.

    Uses ChromaDB upsert for atomic add-or-update operations.
    Validates embedding dimensions before insertion.

    Args:
        memories: List of MemoryInput objects
        batch_size: Batch size for embedding generation (default 50)
        client: Optional MemoryClient instance

    Returns:
        MemoryUpdateResult with stats and any errors
    """
    import time
    start_time = time.perf_counter()

    if client is None:
        from .client import get_memory_client
        client = get_memory_client()

    result = MemoryUpdateResult()
    collection = client.collection

    # Process in batches
    for batch_start in range(0, len(memories), batch_size):
        batch = memories[batch_start:batch_start + batch_size]
        batch_num = batch_start // batch_size + 1

        try:
            # Prepare data
            ids = [m.memory_id for m in batch]
            documents = [m.content for m in batch]
            metadatas = [m.metadata for m in batch]

            # Generate embeddings
            try:
                embeddings = get_embedding(documents)
            except Exception as e:
                error_msg = f"Batch {batch_num}: Embedding generation failed: {e}"
                logger.error(error_msg)
                result.errors.append(error_msg)
                result.failed += len(batch)
                continue

            # Check which IDs already exist
            try:
                existing = collection.get(ids=ids, include=[])
                existing_ids = set(existing.get("ids", []))
            except Exception:
                existing_ids = set()

            # Upsert (atomic add-or-update)
            try:
                collection.upsert(
                    ids=ids,
                    embeddings=embeddings,
                    documents=documents,
                    metadatas=metadatas
                )

                # Count adds vs updates
                for memory_id in ids:
                    if memory_id in existing_ids:
                        result.updated += 1
                    else:
                        result.added += 1

                logger.info(f"Batch {batch_num}: Processed {len(batch)} memories")

            except Exception as e:
                error_msg = f"Batch {batch_num}: Upsert failed: {e}"
                logger.error(error_msg)
                result.errors.append(error_msg)
                result.failed += len(batch)

        except Exception as e:
            error_msg = f"Batch {batch_num}: Unexpected error: {e}"
            logger.error(error_msg)
            result.errors.append(error_msg)
            result.failed += len(batch)

    result.duration_ms = (time.perf_counter() - start_time) * 1000
    logger.info(f"Memory update complete: {result}")
    return result


def delete_memory(memory_id: str, client=None) -> bool:
    """Delete a memory by ID.

    Args:
        memory_id: ID of memory to delete
        client: Optional MemoryClient instance

    Returns:
        True if deleted, False if not found
    """
    if client is None:
        from .client import get_memory_client
        client = get_memory_client()

    try:
        # Check if exists
        existing = client.collection.get(ids=[memory_id], include=[])
        if not existing.get("ids"):
            return False

        client.collection.delete(ids=[memory_id])
        logger.info(f"Deleted memory: {memory_id}")
        return True
    except Exception as e:
        logger.error(f"Failed to delete memory {memory_id}: {e}")
        return False
```
  </action>
  <verify>Run `python -c "from ta_lab2.tools.ai_orchestrator.memory.update import MemoryInput, MemoryUpdateResult; print('Update module loads')"` - should load without error</verify>
  <done>Incremental update module with batch embedding, upsert, and validation</done>
</task>

<task type="auto">
  <name>Task 2: Update memory __init__.py with update exports</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/__init__.py</files>
  <action>
Update memory/__init__.py to export update module functions (assumes 02-02 exports already present):

Add these imports and exports to the existing __init__.py:

```python
from .update import (
    MemoryInput,
    MemoryUpdateResult,
    add_memory,
    add_memories,
    delete_memory,
    get_embedding,
    EMBEDDING_MODEL,
    EMBEDDING_DIMENSIONS,
)

# Add to __all__:
    # Update
    "MemoryInput",
    "MemoryUpdateResult",
    "add_memory",
    "add_memories",
    "delete_memory",
    "get_embedding",
    "EMBEDDING_MODEL",
    "EMBEDDING_DIMENSIONS",
```
  </action>
  <verify>Run `python -c "from ta_lab2.tools.ai_orchestrator.memory import add_memory, add_memories; print('Update exports OK')"` - should print without error</verify>
  <done>Update module functions exported from memory package</done>
</task>

<task type="auto">
  <name>Task 3: Create update module tests</name>
  <files>tests/orchestrator/test_memory_update.py</files>
  <action>
Create tests/orchestrator/test_memory_update.py:

```python
"""Tests for memory update module."""
import pytest
from unittest.mock import MagicMock, patch
from ta_lab2.tools.ai_orchestrator.memory.update import (
    MemoryInput,
    MemoryUpdateResult,
    add_memory,
    add_memories,
    delete_memory,
    get_embedding,
    EMBEDDING_MODEL,
    EMBEDDING_DIMENSIONS,
)
from ta_lab2.tools.ai_orchestrator.memory import reset_memory_client


class TestMemoryUpdateResult:
    """Tests for MemoryUpdateResult dataclass."""

    def test_result_str(self):
        """Test string representation."""
        result = MemoryUpdateResult(added=5, updated=2, failed=1, duration_ms=100.5)
        output = str(result)
        assert "added=5" in output
        assert "updated=2" in output
        assert "failed=1" in output

    def test_total_processed(self):
        """Test total_processed property."""
        result = MemoryUpdateResult(added=5, updated=2, failed=1)
        assert result.total_processed == 8


class TestGetEmbedding:
    """Tests for embedding generation."""

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.OpenAI')
    def test_get_embedding_calls_openai(self, mock_openai_class):
        """Test embedding generation calls OpenAI API."""
        mock_client = MagicMock()
        mock_response = MagicMock()
        mock_response.data = [MagicMock(embedding=[0.1] * EMBEDDING_DIMENSIONS)]
        mock_client.embeddings.create.return_value = mock_response
        mock_openai_class.return_value = mock_client

        with patch.dict('os.environ', {'OPENAI_API_KEY': 'test-key'}):
            embeddings = get_embedding(["test text"])

        assert len(embeddings) == 1
        assert len(embeddings[0]) == EMBEDDING_DIMENSIONS
        mock_client.embeddings.create.assert_called_once()

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.OpenAI')
    def test_get_embedding_validates_dimensions(self, mock_openai_class):
        """Test embedding validation rejects wrong dimensions."""
        mock_client = MagicMock()
        mock_response = MagicMock()
        mock_response.data = [MagicMock(embedding=[0.1] * 768)]  # Wrong size
        mock_client.embeddings.create.return_value = mock_response
        mock_openai_class.return_value = mock_client

        with patch.dict('os.environ', {'OPENAI_API_KEY': 'test-key'}):
            with pytest.raises(ValueError, match="dimensions"):
                get_embedding(["test text"])


class TestAddMemories:
    """Tests for add_memories function."""

    def setup_method(self):
        reset_memory_client()

    def teardown_method(self):
        reset_memory_client()

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_embedding')
    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_memory_client')
    def test_add_memories_upserts(self, mock_get_client, mock_get_embedding):
        """Test add_memories uses upsert."""
        mock_client = MagicMock()
        mock_collection = MagicMock()
        mock_collection.get.return_value = {"ids": []}  # No existing
        mock_client.collection = mock_collection
        mock_get_client.return_value = mock_client

        mock_get_embedding.return_value = [[0.1] * EMBEDDING_DIMENSIONS]

        memories = [MemoryInput(
            memory_id="test1",
            content="Test content",
            metadata={"type": "test"}
        )]

        result = add_memories(memories, client=mock_client)

        assert result.added == 1
        assert result.updated == 0
        assert result.failed == 0
        mock_collection.upsert.assert_called_once()

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_embedding')
    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_memory_client')
    def test_add_memories_counts_updates(self, mock_get_client, mock_get_embedding):
        """Test add_memories correctly counts updates vs adds."""
        mock_client = MagicMock()
        mock_collection = MagicMock()
        mock_collection.get.return_value = {"ids": ["existing1"]}  # One exists
        mock_client.collection = mock_collection
        mock_get_client.return_value = mock_client

        mock_get_embedding.return_value = [[0.1] * EMBEDDING_DIMENSIONS] * 2

        memories = [
            MemoryInput(memory_id="existing1", content="Updated", metadata={}),
            MemoryInput(memory_id="new1", content="New", metadata={})
        ]

        result = add_memories(memories, client=mock_client)

        assert result.added == 1
        assert result.updated == 1

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_embedding')
    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_memory_client')
    def test_add_memories_handles_embedding_failure(self, mock_get_client, mock_get_embedding):
        """Test add_memories handles embedding generation failure."""
        mock_client = MagicMock()
        mock_get_client.return_value = mock_client
        mock_get_embedding.side_effect = Exception("API error")

        memories = [MemoryInput(memory_id="test1", content="Test", metadata={})]

        result = add_memories(memories, client=mock_client)

        assert result.failed == 1
        assert len(result.errors) == 1
        assert "Embedding generation failed" in result.errors[0]


class TestAddMemory:
    """Tests for add_memory convenience function."""

    def setup_method(self):
        reset_memory_client()

    def teardown_method(self):
        reset_memory_client()

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_embedding')
    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_memory_client')
    def test_add_single_memory(self, mock_get_client, mock_get_embedding):
        """Test adding a single memory."""
        mock_client = MagicMock()
        mock_collection = MagicMock()
        mock_collection.get.return_value = {"ids": []}
        mock_client.collection = mock_collection
        mock_get_client.return_value = mock_client

        mock_get_embedding.return_value = [[0.1] * EMBEDDING_DIMENSIONS]

        result = add_memory(
            memory_id="single1",
            content="Single memory content",
            metadata={"type": "test"},
            client=mock_client
        )

        assert result.added == 1
        assert result.failed == 0


class TestDeleteMemory:
    """Tests for delete_memory function."""

    def setup_method(self):
        reset_memory_client()

    def teardown_method(self):
        reset_memory_client()

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_memory_client')
    def test_delete_existing_memory(self, mock_get_client):
        """Test deleting existing memory."""
        mock_client = MagicMock()
        mock_collection = MagicMock()
        mock_collection.get.return_value = {"ids": ["test1"]}
        mock_client.collection = mock_collection
        mock_get_client.return_value = mock_client

        result = delete_memory("test1", client=mock_client)

        assert result is True
        mock_collection.delete.assert_called_once_with(ids=["test1"])

    @patch('ta_lab2.tools.ai_orchestrator.memory.update.get_memory_client')
    def test_delete_nonexistent_memory(self, mock_get_client):
        """Test deleting non-existent memory returns False."""
        mock_client = MagicMock()
        mock_collection = MagicMock()
        mock_collection.get.return_value = {"ids": []}  # Not found
        mock_client.collection = mock_collection
        mock_get_client.return_value = mock_client

        result = delete_memory("nonexistent", client=mock_client)

        assert result is False
        mock_collection.delete.assert_not_called()


class TestMemoryInput:
    """Tests for MemoryInput dataclass."""

    def test_memory_input_defaults(self):
        """Test MemoryInput has correct defaults."""
        mem = MemoryInput(memory_id="id1", content="content")
        assert mem.metadata == {}

    def test_memory_input_with_metadata(self):
        """Test MemoryInput accepts metadata."""
        mem = MemoryInput(
            memory_id="id1",
            content="content",
            metadata={"type": "insight", "source": "test"}
        )
        assert mem.metadata["type"] == "insight"
```
  </action>
  <verify>Run `pytest tests/orchestrator/test_memory_update.py -v` - all tests pass</verify>
  <done>12+ tests covering update result, embedding generation, add/update/delete operations</done>
</task>

</tasks>

<verification>
1. `python -c "from ta_lab2.tools.ai_orchestrator.memory.update import add_memory, MemoryInput; print('Update module OK')"` - imports work
2. `pytest tests/orchestrator/test_memory_update.py -v` - all tests pass
</verification>

<success_criteria>
- add_memories() generates embeddings and upserts (MEMO-07 partially satisfied)
- Adding duplicate memory IDs updates content without errors (upsert behavior)
- Embedding validation ensures correct dimensions (1536)
- 12+ tests pass for update module
</success_criteria>

<output>
After completion, create `.planning/phases/02-memory-core-chromadb-integration/02-03-SUMMARY.md`
</output>
