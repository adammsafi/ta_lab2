---
phase: 02-memory-core-chromadb-integration
plan: 04
type: execute
wave: 3
depends_on: ["02-02", "02-03"]
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/memory/api.py
  - src/ta_lab2/tools/ai_orchestrator/memory/__init__.py
  - src/ta_lab2/tools/ai_orchestrator/__init__.py
  - tests/orchestrator/test_memory_api.py
autonomous: true

must_haves:
  truths:
    - "Memory API exposes search endpoint via HTTP"
    - "Claude/ChatGPT/Gemini can access memories through REST API"
    - "Health check endpoint reports memory store status"
    - "Context injection endpoint returns formatted memories for AI prompts"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/memory/api.py"
      provides: "FastAPI REST endpoint for cross-platform access"
      exports: ["create_memory_api", "MemorySearchRequest", "MemorySearchResponse", "app"]
    - path: "tests/orchestrator/test_memory_api.py"
      provides: "API endpoint tests"
      min_lines: 40
  key_links:
    - from: "src/ta_lab2/tools/ai_orchestrator/memory/api.py"
      to: "memory/query.py"
      via: "search_memories import"
      pattern: "from.*query.*import.*search_memories"
    - from: "src/ta_lab2/tools/ai_orchestrator/memory/api.py"
      to: "memory/injection.py"
      via: "inject_memory_context import"
      pattern: "from.*injection.*import.*inject_memory_context"
---

<objective>
Cross-platform REST API for memory access (MEMO-04)

Purpose: Expose memory search, context injection, and stats via HTTP endpoints. Claude, ChatGPT, and Gemini are cloud services that cannot access local filesystem - they need HTTP endpoints to query the memory layer. FastAPI is a required dependency for Phase 2 to satisfy MEMO-04.

Output: FastAPI application with /search, /context, /stats, and /health endpoints, comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-memory-core-chromadb-integration/02-RESEARCH.md

# Depends on search/injection from Wave 1 and update from Wave 2
@.planning/phases/02-memory-core-chromadb-integration/02-02-SUMMARY.md
@.planning/phases/02-memory-core-chromadb-integration/02-03-SUMMARY.md
</context>

<dependencies>
**Required packages for Phase 2 (MEMO-04):**
- fastapi (REST framework) - REQUIRED for cross-platform memory sharing
- uvicorn (ASGI server) - REQUIRED to run FastAPI server

Install with: `pip install fastapi uvicorn`

Note: These are NOT optional. MEMO-04 requires Claude/ChatGPT/Gemini to read from ChromaDB.
Since AI platforms are cloud services without filesystem access, HTTP is the only option.
</dependencies>

<tasks>

<task type="auto">
  <name>Task 1: Create FastAPI REST endpoint for cross-platform access</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/api.py</files>
  <action>
Create memory/api.py with FastAPI endpoints for cross-platform memory access:

```python
"""FastAPI REST API for cross-platform memory access.

Exposes memory search to Claude/ChatGPT/Gemini via HTTP.
Implements MEMO-04: Cross-platform memory sharing.

FastAPI is REQUIRED for Phase 2 - not optional.

Run server:
    uvicorn ta_lab2.tools.ai_orchestrator.memory.api:app --port 8080
"""
import logging
from typing import Optional, List

from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


# Request/Response Models
class MemorySearchRequest(BaseModel):
    """Request body for memory search."""
    query: str = Field(..., description="Search query text")
    max_results: int = Field(5, ge=1, le=20, description="Maximum results")
    min_similarity: float = Field(0.7, ge=0.0, le=1.0, description="Minimum similarity")
    memory_type: Optional[str] = Field(None, description="Filter by memory type")


class MemoryResult(BaseModel):
    """Individual memory result."""
    memory_id: str
    content: str
    metadata: dict
    similarity: float


class MemorySearchResponse(BaseModel):
    """Response from memory search."""
    query: str
    memories: List[MemoryResult]
    count: int
    threshold_used: float


class MemoryStatsResponse(BaseModel):
    """Response from stats endpoint."""
    total_memories: int
    collection_name: str
    distance_metric: str
    is_valid: bool


class ContextInjectionRequest(BaseModel):
    """Request for formatted context injection."""
    query: str = Field(..., description="Query for context retrieval")
    max_memories: int = Field(5, ge=1, le=10, description="Maximum memories")
    min_similarity: float = Field(0.7, ge=0.0, le=1.0, description="Minimum similarity")
    max_length: int = Field(4000, ge=100, le=10000, description="Maximum context length")


class ContextInjectionResponse(BaseModel):
    """Response with formatted context."""
    query: str
    context: str
    memory_count: int
    estimated_tokens: int


def create_memory_api() -> FastAPI:
    """Create FastAPI application for memory API.

    Returns:
        FastAPI application instance
    """
    app = FastAPI(
        title="ta_lab2 Memory API",
        description="Semantic memory search for cross-platform AI access",
        version="1.0.0"
    )

    @app.get("/health")
    async def health_check():
        """Health check endpoint."""
        from .validation import quick_health_check
        is_healthy = quick_health_check()
        return {"status": "healthy" if is_healthy else "unhealthy"}

    @app.get("/api/v1/memory/stats", response_model=MemoryStatsResponse)
    async def get_stats():
        """Get memory store statistics."""
        try:
            from .client import get_memory_client
            from .validation import validate_memory_store

            client = get_memory_client()
            validation = validate_memory_store(client)

            return MemoryStatsResponse(
                total_memories=validation.total_count,
                collection_name=client._collection_name,
                distance_metric=validation.distance_metric,
                is_valid=validation.is_valid
            )
        except Exception as e:
            logger.error(f"Stats failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    @app.post("/api/v1/memory/search", response_model=MemorySearchResponse)
    async def search_memories_endpoint(request: MemorySearchRequest):
        """Semantic search endpoint for cross-platform memory access.

        Used by Claude, ChatGPT, Gemini to retrieve relevant project memories.
        """
        try:
            from .query import search_memories

            response = search_memories(
                query=request.query,
                max_results=request.max_results,
                min_similarity=request.min_similarity,
                memory_type=request.memory_type
            )

            return MemorySearchResponse(
                query=request.query,
                memories=[
                    MemoryResult(
                        memory_id=r.memory_id,
                        content=r.content,
                        metadata=r.metadata,
                        similarity=r.similarity
                    )
                    for r in response.results
                ],
                count=response.filtered_count,
                threshold_used=response.threshold_used
            )
        except Exception as e:
            logger.error(f"Search failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    @app.post("/api/v1/memory/context", response_model=ContextInjectionResponse)
    async def get_context(request: ContextInjectionRequest):
        """Get formatted context for AI prompt injection.

        Returns memories formatted and ready to inject into prompts.
        """
        try:
            from .injection import inject_memory_context, estimate_context_tokens
            from .query import search_memories

            # Get search results for count
            search_response = search_memories(
                query=request.query,
                max_results=request.max_memories,
                min_similarity=request.min_similarity
            )

            # Get formatted context
            context = inject_memory_context(
                query=request.query,
                max_memories=request.max_memories,
                min_similarity=request.min_similarity,
                max_length=request.max_length
            )

            return ContextInjectionResponse(
                query=request.query,
                context=context,
                memory_count=search_response.filtered_count,
                estimated_tokens=estimate_context_tokens(context)
            )
        except Exception as e:
            logger.error(f"Context injection failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/api/v1/memory/types")
    async def get_memory_types():
        """Get list of available memory types."""
        try:
            from .query import get_memory_types
            types = get_memory_types()
            return {"types": types, "count": len(types)}
        except Exception as e:
            logger.error(f"Get types failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    return app


# Create app instance for uvicorn
app = create_memory_api()
```
  </action>
  <verify>Run `python -c "from ta_lab2.tools.ai_orchestrator.memory.api import app; print(f'API app created: {app.title}')"` - should print app title</verify>
  <done>FastAPI endpoints created for search, context injection, and stats</done>
</task>

<task type="auto">
  <name>Task 2: Update memory module exports and main orchestrator exports</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/__init__.py, src/ta_lab2/tools/ai_orchestrator/__init__.py</files>
  <action>
Update memory/__init__.py to export API modules (after 02-02 and 02-03 exports):

```python
"""Memory integration for AI orchestrator.

Provides ChromaDB client, semantic search, context injection,
incremental updates, and REST API for cross-platform access.

Quick start:
    from ta_lab2.tools.ai_orchestrator.memory import (
        search_memories,
        inject_memory_context,
        validate_memory_store
    )

    # Search memories
    results = search_memories("EMA calculation")

    # Get formatted context for AI prompt
    context = inject_memory_context("How do I backtest?")

Run API server:
    uvicorn ta_lab2.tools.ai_orchestrator.memory.api:app --port 8080
"""
from .client import MemoryClient, get_memory_client, reset_memory_client
from .validation import (
    MemoryValidationResult,
    validate_memory_store,
    quick_health_check
)
from .query import (
    SearchResult,
    SearchResponse,
    search_memories,
    get_memory_by_id,
    get_memory_types
)
from .injection import (
    format_memories_for_prompt,
    inject_memory_context,
    build_augmented_prompt,
    estimate_context_tokens
)
from .update import (
    MemoryInput,
    MemoryUpdateResult,
    add_memory,
    add_memories,
    delete_memory,
    get_embedding,
    EMBEDDING_MODEL,
    EMBEDDING_DIMENSIONS
)
from .api import (
    create_memory_api,
    MemorySearchRequest,
    MemorySearchResponse,
    MemoryStatsResponse,
    ContextInjectionRequest,
    ContextInjectionResponse,
)

__all__ = [
    # Client
    "MemoryClient",
    "get_memory_client",
    "reset_memory_client",
    # Validation
    "MemoryValidationResult",
    "validate_memory_store",
    "quick_health_check",
    # Query
    "SearchResult",
    "SearchResponse",
    "search_memories",
    "get_memory_by_id",
    "get_memory_types",
    # Injection
    "format_memories_for_prompt",
    "inject_memory_context",
    "build_augmented_prompt",
    "estimate_context_tokens",
    # Update
    "MemoryInput",
    "MemoryUpdateResult",
    "add_memory",
    "add_memories",
    "delete_memory",
    "get_embedding",
    "EMBEDDING_MODEL",
    "EMBEDDING_DIMENSIONS",
    # API
    "create_memory_api",
    "MemorySearchRequest",
    "MemorySearchResponse",
    "MemoryStatsResponse",
    "ContextInjectionRequest",
    "ContextInjectionResponse",
]
```

Update main orchestrator __init__.py to expose memory module:

Add to existing __init__.py imports:
```python
# Add after existing imports
from . import memory  # Expose memory submodule
```

Add to __all__ list:
```python
"memory",  # Memory submodule
```
  </action>
  <verify>Run `python -c "from ta_lab2.tools.ai_orchestrator import memory; print(dir(memory))"` - should list all exports</verify>
  <done>Memory module fully exported from orchestrator package</done>
</task>

<task type="auto">
  <name>Task 3: Create API endpoint tests</name>
  <files>tests/orchestrator/test_memory_api.py</files>
  <action>
Create tests/orchestrator/test_memory_api.py:

```python
"""Tests for memory REST API."""
import pytest
from unittest.mock import MagicMock, patch
from fastapi.testclient import TestClient
from ta_lab2.tools.ai_orchestrator.memory.api import create_memory_api


class TestMemoryAPI:
    """Tests for memory REST API endpoints."""

    @pytest.fixture
    def client(self):
        """Create test client."""
        app = create_memory_api()
        return TestClient(app)

    @patch('ta_lab2.tools.ai_orchestrator.memory.api.quick_health_check')
    def test_health_endpoint(self, mock_health, client):
        """Test health check endpoint."""
        mock_health.return_value = True

        response = client.get("/health")

        assert response.status_code == 200
        assert response.json()["status"] == "healthy"

    @patch('ta_lab2.tools.ai_orchestrator.memory.api.quick_health_check')
    def test_health_endpoint_unhealthy(self, mock_health, client):
        """Test health check reports unhealthy status."""
        mock_health.return_value = False

        response = client.get("/health")

        assert response.status_code == 200
        assert response.json()["status"] == "unhealthy"

    @patch('ta_lab2.tools.ai_orchestrator.memory.api.validate_memory_store')
    @patch('ta_lab2.tools.ai_orchestrator.memory.api.get_memory_client')
    def test_stats_endpoint(self, mock_get_client, mock_validate, client):
        """Test stats endpoint."""
        mock_client = MagicMock()
        mock_client._collection_name = "test_collection"
        mock_get_client.return_value = mock_client

        mock_validation = MagicMock()
        mock_validation.total_count = 3763
        mock_validation.distance_metric = "cosine"
        mock_validation.is_valid = True
        mock_validate.return_value = mock_validation

        response = client.get("/api/v1/memory/stats")

        assert response.status_code == 200
        data = response.json()
        assert data["total_memories"] == 3763
        assert data["distance_metric"] == "cosine"
        assert data["is_valid"] is True

    @patch('ta_lab2.tools.ai_orchestrator.memory.api.search_memories')
    def test_search_endpoint(self, mock_search, client):
        """Test search endpoint."""
        from ta_lab2.tools.ai_orchestrator.memory.query import SearchResult, SearchResponse

        mock_search.return_value = SearchResponse(
            query="test",
            results=[SearchResult(
                memory_id="id1",
                content="Test content",
                metadata={"type": "test"},
                similarity=0.9,
                distance=0.1
            )],
            total_found=1,
            filtered_count=1,
            search_time_ms=5.0,
            threshold_used=0.7
        )

        response = client.post(
            "/api/v1/memory/search",
            json={"query": "test query", "max_results": 5, "min_similarity": 0.7}
        )

        assert response.status_code == 200
        data = response.json()
        assert data["count"] == 1
        assert data["memories"][0]["similarity"] == 0.9
        assert data["memories"][0]["content"] == "Test content"

    @patch('ta_lab2.tools.ai_orchestrator.memory.api.search_memories')
    def test_search_endpoint_with_type_filter(self, mock_search, client):
        """Test search endpoint with memory_type filter."""
        from ta_lab2.tools.ai_orchestrator.memory.query import SearchResponse

        mock_search.return_value = SearchResponse(
            query="test",
            results=[],
            total_found=0,
            filtered_count=0,
            search_time_ms=2.0,
            threshold_used=0.7
        )

        response = client.post(
            "/api/v1/memory/search",
            json={"query": "test", "memory_type": "insight"}
        )

        assert response.status_code == 200
        # Verify filter was passed
        call_kwargs = mock_search.call_args.kwargs
        assert call_kwargs["memory_type"] == "insight"

    @patch('ta_lab2.tools.ai_orchestrator.memory.api.search_memories')
    @patch('ta_lab2.tools.ai_orchestrator.memory.api.inject_memory_context')
    @patch('ta_lab2.tools.ai_orchestrator.memory.api.estimate_context_tokens')
    def test_context_endpoint(self, mock_tokens, mock_inject, mock_search, client):
        """Test context injection endpoint."""
        from ta_lab2.tools.ai_orchestrator.memory.query import SearchResponse

        mock_search.return_value = SearchResponse(
            query="test",
            results=[],
            total_found=2,
            filtered_count=2,
            search_time_ms=5.0,
            threshold_used=0.7
        )
        mock_inject.return_value = "# Formatted Context\n\n## Memory 1..."
        mock_tokens.return_value = 100

        response = client.post(
            "/api/v1/memory/context",
            json={"query": "test query"}
        )

        assert response.status_code == 200
        data = response.json()
        assert data["context"] == "# Formatted Context\n\n## Memory 1..."
        assert data["memory_count"] == 2
        assert data["estimated_tokens"] == 100

    @patch('ta_lab2.tools.ai_orchestrator.memory.api.get_memory_types')
    def test_types_endpoint(self, mock_types, client):
        """Test memory types endpoint."""
        mock_types.return_value = ["insight", "code", "decision"]

        response = client.get("/api/v1/memory/types")

        assert response.status_code == 200
        data = response.json()
        assert data["count"] == 3
        assert "insight" in data["types"]
        assert "code" in data["types"]

    def test_search_endpoint_validation(self, client):
        """Test search endpoint validates input."""
        # Missing required query field
        response = client.post(
            "/api/v1/memory/search",
            json={"max_results": 5}
        )

        assert response.status_code == 422  # Validation error

    def test_search_endpoint_bounds_validation(self, client):
        """Test search endpoint validates parameter bounds."""
        # max_results out of bounds
        response = client.post(
            "/api/v1/memory/search",
            json={"query": "test", "max_results": 100}  # Max is 20
        )

        assert response.status_code == 422


class TestAPIDocumentation:
    """Tests for API documentation endpoints."""

    @pytest.fixture
    def client(self):
        """Create test client."""
        app = create_memory_api()
        return TestClient(app)

    def test_openapi_schema_available(self, client):
        """Test OpenAPI schema is available."""
        response = client.get("/openapi.json")

        assert response.status_code == 200
        data = response.json()
        assert data["info"]["title"] == "ta_lab2 Memory API"

    def test_docs_endpoint_available(self, client):
        """Test Swagger UI docs endpoint."""
        response = client.get("/docs")

        assert response.status_code == 200
```

Note: API tests use FastAPI's TestClient which tests the HTTP interface via mocked function imports.
For full HTTP server integration testing, you would run the server manually and use curl or httpx:
```bash
# Start server
uvicorn ta_lab2.tools.ai_orchestrator.memory.api:app --port 8080 &

# Test endpoints
curl http://localhost:8080/health
curl -X POST http://localhost:8080/api/v1/memory/search -H "Content-Type: application/json" -d '{"query": "EMA calculation"}'
```
  </action>
  <verify>Run `pytest tests/orchestrator/test_memory_api.py -v` - all tests pass</verify>
  <done>12+ tests covering all API endpoints, validation, and documentation</done>
</task>

</tasks>

<verification>
1. `python -c "from ta_lab2.tools.ai_orchestrator.memory import create_memory_api; print('API module OK')"` - imports work
2. `pytest tests/orchestrator/test_memory_api.py -v` - all tests pass
3. `uvicorn ta_lab2.tools.ai_orchestrator.memory.api:app --port 8080` starts server
4. `curl http://localhost:8080/health` returns healthy status
</verification>

<success_criteria>
- REST API exposes /search and /context endpoints
- Cross-platform access possible via HTTP (MEMO-04 satisfied)
- Health check and stats endpoints work
- 12+ tests pass for API module
- OpenAPI documentation available at /docs
</success_criteria>

<output>
After completion, create `.planning/phases/02-memory-core-chromadb-integration/02-04-SUMMARY.md`
</output>
