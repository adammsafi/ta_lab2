---
phase: 02-memory-core-chromadb-integration
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/memory/query.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Search returns relevant memories for a query"
    - "inject_memory_context() returns formatted memories"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/memory/query.py"
      provides: "Semantic search with correct 1536-dim embeddings"
      contains: "get_embedding"
  key_links:
    - from: "src/ta_lab2/tools/ai_orchestrator/memory/query.py"
      to: "src/ta_lab2/tools/ai_orchestrator/memory/update.py"
      via: "import get_embedding"
      pattern: "from \\.update import.*get_embedding"
---

<objective>
Fix semantic search embedding dimension mismatch causing query failures.

Purpose: ChromaDB collection has 1536-dim embeddings (text-embedding-3-small) but search_memories() uses query_texts which triggers ChromaDB's default 384-dim embedder, causing dimension mismatch crash.

Output: Working semantic search that generates 1536-dim query embeddings using the same model as stored memories.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Gap source
@.planning/phases/02-memory-core-chromadb-integration/02-VERIFICATION.md

# Files to modify
@src/ta_lab2/tools/ai_orchestrator/memory/query.py
@src/ta_lab2/tools/ai_orchestrator/memory/update.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix search_memories() to use 1536-dim query embeddings</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/query.py</files>
  <action>
Modify search_memories() function to generate query embeddings using the same model as stored memories:

1. Add import at top of search_memories() function (lazy import pattern):
   ```python
   from .update import get_embedding
   ```

2. Replace line 94-99 (the collection.query call) with:
   ```python
   # Generate query embedding using same model as collection (1536-dim)
   query_embedding = get_embedding([query])[0]

   raw_results = collection.query(
       query_embeddings=[query_embedding],  # NOT query_texts
       n_results=max_results,
       where=where_filter,
       include=["documents", "metadatas", "distances"]
   )
   ```

This ensures the query embedding has 1536 dimensions (text-embedding-3-small) matching the stored memories, instead of ChromaDB's default 384-dim embedder.
  </action>
  <verify>
Run Python to verify the fix:
```bash
python -c "
from ta_lab2.tools.ai_orchestrator.memory.query import search_memories
from ta_lab2.tools.ai_orchestrator.memory.client import get_memory_client
client = get_memory_client()
print(f'Collection count: {client.collection.count()}')
results = search_memories('EMA calculation', max_results=3)
print(f'Search returned {results.filtered_count} results')
for r in results.results:
    print(f'  - {r.similarity:.2f}: {r.content[:60]}...')
"
```
Should return results without dimension mismatch error.
  </verify>
  <done>
search_memories() returns relevant memories without dimension mismatch errors.
Query uses 1536-dim embedding matching stored memories.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify inject_memory_context() works transitively</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/injection.py</files>
  <action>
No code changes needed - inject_memory_context() calls search_memories() which is now fixed.

Verify the transitive fix by testing the full context injection flow.
  </action>
  <verify>
Run Python to verify context injection:
```bash
python -c "
from ta_lab2.tools.ai_orchestrator.memory.injection import inject_memory_context
context = inject_memory_context('How do I calculate multi-timeframe EMAs?', max_memories=3)
print('Context injection result:')
print(context[:500])
print(f'...[{len(context)} chars total]')
"
```
Should return formatted memory context without errors.
  </verify>
  <done>
inject_memory_context() returns formatted memories for AI prompts.
Full RAG pipeline operational: query -> embed -> search -> format.
  </done>
</task>

</tasks>

<verification>
1. Dimension mismatch error no longer occurs
2. search_memories() returns relevant results (similarity > 0.7)
3. inject_memory_context() returns formatted context string
4. Both success criteria from VERIFICATION.md gaps are satisfied
</verification>

<success_criteria>
- search_memories("EMA calculation") returns results without error
- inject_memory_context() returns formatted markdown context
- No 384-dim vs 1536-dim dimension mismatch errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-memory-core-chromadb-integration/02-05-SUMMARY.md`
</output>
