---
phase: 11-memory-preparation
plan: 03
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_external_dirs_snapshot.py
  - .planning/phases/11-memory-preparation/snapshots/external_dirs_snapshot.json
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Data_Tools directory indexed in memory with pre_integration_v0.5.0 tag"
    - "fredtools2 directory indexed in memory with pre_integration_v0.5.0 tag"
    - "fedtools2 directory indexed in memory with pre_integration_v0.5.0 tag"
    - "Memory queries can find files by directory name"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_external_dirs_snapshot.py"
      provides: "Executable script for external directory snapshots"
      exports: ["run_external_dirs_snapshot", "main"]
    - path: ".planning/phases/11-memory-preparation/snapshots/external_dirs_snapshot.json"
      provides: "Snapshot metadata for all external directories"
      contains: "directory_stats"
  key_links:
    - from: "run_external_dirs_snapshot.py"
      to: "extract_codebase.py"
      via: "extract_directory_tree call"
      pattern: "extract_directory_tree"
    - from: "run_external_dirs_snapshot.py"
      to: "batch_indexer.py"
      via: "batch_add_memories call"
      pattern: "batch_add_memories"
---

<objective>
Index external directories (Data_Tools, fredtools2, fedtools2) into memory system with pre_integration_v0.5.0 tag.

Purpose: Requirement MEMO-12 requires capturing current state of external directories before integration. This creates baseline snapshots that enable tracking what gets integrated vs archived during v0.5.0.

Output: All external Python files indexed in Mem0 with structured metadata, plus consolidated snapshot manifest.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-memory-preparation/11-CONTEXT.md
@.planning/phases/11-memory-preparation/11-RESEARCH.md
@.planning/phases/11-memory-preparation/11-01-SUMMARY.md

# Snapshot infrastructure from Plan 01
@src/ta_lab2/tools/ai_orchestrator/memory/snapshot/extract_codebase.py
@src/ta_lab2/tools/ai_orchestrator/memory/snapshot/batch_indexer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create external directories snapshot script</name>
  <files>
    src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_external_dirs_snapshot.py
  </files>
  <action>
Create run_external_dirs_snapshot.py with:

1. Define external directory configuration:
   ```python
   EXTERNAL_DIRS = [
       {
           "name": "Data_Tools",
           "path": Path("C:/Users/asafi/Downloads/Data_Tools"),
           "description": "Data processing and utility scripts"
       },
       {
           "name": "fredtools2",
           "path": Path("C:/Users/asafi/Downloads/fredtools2"),
           "description": "FRED economic data tools"
       },
       {
           "name": "fedtools2",
           "path": Path("C:/Users/asafi/Downloads/fedtools2"),
           "description": "Federal Reserve data tools"
       }
   ]

   EXCLUSIONS = [
       "__pycache__", ".pyc", ".venv", "venv", "env",
       ".git", "dist", "build", "*.egg-info",
       ".csv", ".xlsx", ".json"
   ]
   ```

2. `validate_directories() -> list[dict]`:
   - Check each directory in EXTERNAL_DIRS exists
   - Return list of valid directories (log warnings for missing)
   - Fail gracefully if directory doesn't exist (skip it, continue with others)

3. `run_external_dir_snapshot(dir_config: dict, dry_run: bool = False) -> dict`:
   - Similar to run_ta_lab2_snapshot but for external directory
   - Get git metadata if .git exists in directory, otherwise use file mtime
   - For each file_info, create memory dict:
     - content: format_file_content_for_memory(file_info)
     - metadata: create_snapshot_metadata with:
       - source="pre_integration_v0.5.0"
       - directory=dir_config["name"]
       - file_type="source_code"
       - file_path=relative path from dir root
   - Return stats dict per directory

4. `run_all_external_snapshots(dry_run: bool = False) -> dict`:
   - Validate directories first
   - Loop through each valid directory, call run_external_dir_snapshot
   - Aggregate stats into combined result:
     ```python
     {
         "directories": {
             "Data_Tools": {...stats...},
             "fredtools2": {...stats...},
             "fedtools2": {...stats...}
         },
         "totals": {
             "total_files": X,
             "total_functions": Y,
             "memories_added": Z
         }
     }
     ```
   - Return combined stats

5. `save_external_snapshot_manifest(stats: dict, output_path: Path)`:
   - Save JSON with all directory stats and totals
   - Include timestamp, list of missing directories (if any)

6. `main()` with CLI, --dry-run flag, logging config

Note: ProjectTT was mentioned in requirements but does not exist at expected location. Script should handle this gracefully (it's not in EXTERNAL_DIRS config).
  </action>
  <verify>
Run dry-run: `python src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_external_dirs_snapshot.py --dry-run`
Expected: Shows file counts for each accessible directory.
  </verify>
  <done>
run_external_dirs_snapshot.py exists and handles missing directories gracefully. Dry-run shows discovery working for available directories.
  </done>
</task>

<task type="auto">
  <name>Task 2: Execute external directories snapshot and validate</name>
  <files>
    .planning/phases/11-memory-preparation/snapshots/external_dirs_snapshot.json
  </files>
  <action>
Execute the snapshot process:

1. Run the snapshot script (not dry-run):
   ```bash
   python src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_external_dirs_snapshot.py
   ```

2. Verify memories were added by querying each directory:
   ```python
   from ta_lab2.tools.ai_orchestrator.memory.mem0_client import get_mem0_client
   client = get_mem0_client()

   for dir_name in ["Data_Tools", "fredtools2", "fedtools2"]:
       results = client.search(
           query=f"Files in {dir_name} directory",
           user_id="orchestrator",
           limit=10
       )
       print(f"{dir_name}: {len(results)} memories found")
   ```

3. Verify pre_integration tag filtering:
   ```python
   results = client.search(
       query="pre_integration snapshot external directories",
       user_id="orchestrator",
       limit=20
   )
   print(f"Total pre_integration tagged: {len(results)}")
   ```

4. Verify snapshot manifest was created at:
   .planning/phases/11-memory-preparation/snapshots/external_dirs_snapshot.json

5. Document results:
   - Files indexed per directory
   - Total functions discovered per directory
   - Any directories that were missing/skipped
   - Any errors encountered
  </action>
  <verify>
Check manifest exists: `cat .planning/phases/11-memory-preparation/snapshots/external_dirs_snapshot.json`
Query test for each directory: `python -c "from ta_lab2.tools.ai_orchestrator.memory.mem0_client import get_mem0_client; c = get_mem0_client(); r = c.search('Data_Tools files', 'orchestrator', limit=5); print(f'Data_Tools: {len(r)} results')"`
  </verify>
  <done>
external_dirs_snapshot.json exists with stats for all available directories. Memory queries return results for Data_Tools, fredtools2, fedtools2 with pre_integration_v0.5.0 tags.
  </done>
</task>

</tasks>

<verification>
1. Snapshot manifest exists: `.planning/phases/11-memory-preparation/snapshots/external_dirs_snapshot.json`
2. Search query "Files in Data_Tools" returns results
3. Search query "Files in fredtools2" returns results
4. Search query "Files in fedtools2" returns results
5. All results have pre_integration_v0.5.0 source metadata
</verification>

<success_criteria>
- run_external_dirs_snapshot.py exists and handles missing directories gracefully
- external_dirs_snapshot.json contains file inventory for all accessible directories
- Data_Tools, fredtools2, fedtools2 indexed in memory with pre_integration_v0.5.0 tag
- Memory queries can find files by directory name
- Script logs which directories were processed vs skipped
</success_criteria>

<output>
After completion, create `.planning/phases/11-memory-preparation/11-03-SUMMARY.md`
</output>
