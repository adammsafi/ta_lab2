---
phase: 11-memory-preparation
plan: 04
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py
  - .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json
autonomous: true
user_setup: []

must_haves:
  truths:
    - "v0.4.0 conversation history extracted from Claude Code transcripts"
    - "Conversations linked to phases 1-10 via timestamps"
    - "Conversations linked to code changes via git commit correlation"
    - "Memory contains development context from v0.4.0 work"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py"
      provides: "Executable script for conversation extraction"
      exports: ["run_conversation_snapshot", "main"]
    - path: ".planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json"
      provides: "Conversation history metadata and phase boundaries"
      contains: "phases"
  key_links:
    - from: "run_conversation_snapshot.py"
      to: "extract_conversations.py"
      via: "extract_conversation and link_conversations_to_phases calls"
      pattern: "from.*extract_conversations import"
    - from: "run_conversation_snapshot.py"
      to: "batch_indexer.py"
      via: "batch_add_memories call"
      pattern: "batch_add_memories"
---

<objective>
Extract v0.4.0 conversation history from Claude Code transcripts and index in memory system with links to code changes.

Purpose: Requirement MEMO-10 requires capturing v0.4.0 completion context. Conversation history provides development decisions, rationale, and context that will inform v0.5.0 work. Per CONTEXT.md, conversations must be linked to resulting code changes for full traceability.

Output: Key conversations from phases 1-10 indexed in Mem0 with phase linkage AND code change correlation, plus manifest documenting phase boundaries.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-memory-preparation/11-CONTEXT.md
@.planning/phases/11-memory-preparation/11-RESEARCH.md
@.planning/phases/11-memory-preparation/11-01-SUMMARY.md

# Snapshot infrastructure from Plan 01
@src/ta_lab2/tools/ai_orchestrator/memory/snapshot/extract_conversations.py
@src/ta_lab2/tools/ai_orchestrator/memory/snapshot/batch_indexer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create conversation snapshot script with code linking</name>
  <files>
    src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py
  </files>
  <action>
Create run_conversation_snapshot.py with:

1. Configuration:
   ```python
   CLAUDE_PROJECTS_DIR = Path.home() / ".claude" / "projects"
   PROJECT_FOLDER = "C--Users-asafi-Downloads-ta-lab2"
   PLANNING_DIR = Path("C:/Users/asafi/Downloads/ta_lab2/.planning")
   REPO_PATH = Path("C:/Users/asafi/Downloads/ta_lab2")
   ```

2. `get_commits_in_timerange(repo: Repo, start: datetime, end: datetime) -> list[dict]`:
   - Use GitPython to iterate commits between timestamps
   - Return list of {hash, message, author, timestamp, files_changed: [paths]}
   - This enables conversation-to-code linking per CONTEXT.md

3. `link_conversation_to_commits(conversation_timestamp: datetime, phase_commits: list[dict], window_hours: int = 24) -> list[str]`:
   - Find commits within window_hours of the conversation
   - Return list of commit hashes that likely resulted from the conversation
   - Heuristic: commits made 0-24 hours AFTER a conversation are likely related

4. `extract_conversation_summaries(messages: list[dict], max_per_phase: int = 10) -> list[dict]`:
   - Filter to most significant conversations (not every message)
   - Prioritize: user messages with questions, assistant messages with decisions/conclusions
   - Skip tool-use messages unless they show important operations
   - Return list of summary dicts with: role, content (truncated to 500 chars), timestamp, phase

5. `format_conversation_for_memory(conversation: dict, phase: int, linked_commits: list[str]) -> str`:
   - Create memory-suitable content with code change links:
     ```
     Phase {phase} conversation ({date}):
     {role}: {content_summary}

     Context: Development discussion during v0.4.0 Phase {phase}
     Related commits: {commit_hashes, comma-separated, or "none identified"}
     ```
   - Keep under 1000 chars for embedding efficiency

6. `run_conversation_snapshot(repo_path: Path, dry_run: bool = False) -> dict`:
   - Find all JSONL files using find_conversation_files()
   - Extract all messages from all files
   - Get phase boundaries using extract_phase_boundaries()
   - Link conversations to phases using link_conversations_to_phases()
   - Get commits per phase using get_commits_in_timerange()
   - For each conversation, find linked commits using link_conversation_to_commits()
   - For each phase, extract conversation summaries
   - Create memory entries with:
     - content: format_conversation_for_memory() (includes linked commits)
     - metadata: create_snapshot_metadata with:
       - source="v0.4.0_conversations"
       - directory="conversations"
       - file_type="conversation"
       - phase=phase_number
       - conversation_date=timestamp
       - linked_commits=[list of commit hashes]
   - If not dry_run: call batch_add_memories()
   - Return stats: {phases_processed, conversations_indexed, conversations_with_code_links, phase_breakdown: {1: N, 2: M, ...}}

7. `save_conversation_manifest(stats: dict, phase_boundaries: dict, output_path: Path)`:
   - Save JSON with:
     - snapshot_type: "v0.4.0_conversations"
     - timestamp: ISO format
     - phases: phase_boundaries
     - stats: conversation counts per phase
     - code_links: count of conversations with linked commits
     - jsonl_files_processed: list of files

8. `main()` with CLI, --dry-run flag, --max-per-phase option (default 10)

Handle large JSONL files (some are >100MB) by reading line-by-line, not loading entire file.
  </action>
  <verify>
Run dry-run: `python src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py --dry-run`
Expected: Shows phase boundaries, conversation counts, and code link statistics without indexing.
  </verify>
  <done>
run_conversation_snapshot.py exists with conversation-to-code linking. Dry-run shows phase boundary detection and code correlation working. Script handles large JSONL files.
  </done>
</task>

<task type="auto">
  <name>Task 2: Execute conversation snapshot and validate</name>
  <files>
    .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json
  </files>
  <action>
Execute the conversation snapshot:

1. Run the snapshot script (not dry-run):
   ```bash
   python src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py
   ```

2. Verify conversation memories were added:
   ```python
   from ta_lab2.tools.ai_orchestrator.memory.mem0_client import get_mem0_client
   client = get_mem0_client()

   # Query for conversation memories
   results = client.search(
       query="v0.4.0 phase development discussion",
       user_id="orchestrator",
       limit=20
   )
   print(f"Found {len(results)} conversation memories")

   # Check specific phases
   for phase in [1, 5, 10]:
       results = client.search(
           query=f"Phase {phase} conversation context",
           user_id="orchestrator",
           limit=5
       )
       print(f"Phase {phase}: {len(results)} conversation memories")
   ```

3. Verify conversation-code linking:
   ```python
   # Query for conversations with code links
   results = client.search(
       query="conversation with commit changes code",
       user_id="orchestrator",
       limit=10
   )
   # Check if results contain linked_commits in metadata
   linked_count = sum(1 for r in results if r.get('metadata', {}).get('linked_commits'))
   print(f"Conversations with code links: {linked_count}")
   ```

4. Verify manifest was created at:
   .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json

5. Validate manifest contains:
   - Phase boundaries with dates
   - Conversation counts per phase
   - Code link statistics (conversations_with_code_links count)
   - Total conversations indexed
   - List of processed JSONL files

6. Document any phases with no conversations found (may indicate missing transcripts).
  </action>
  <verify>
Check manifest: `cat .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json`
Query test: `python -c "from ta_lab2.tools.ai_orchestrator.memory.mem0_client import get_mem0_client; c = get_mem0_client(); r = c.search('v0.4.0 phase development', 'orchestrator', limit=5); print(f'Conversations: {len(r)} results')"`
  </verify>
  <done>
conversations_snapshot.json exists with phase boundaries and code link statistics. Memory contains v0.4.0 conversation context with linked commits. Queries return development discussions by phase.
  </done>
</task>

</tasks>

<verification>
1. Snapshot manifest exists: `.planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json`
2. Manifest contains phase boundaries with start/end dates
3. Manifest contains code_links count (conversations linked to commits)
4. Search query "Phase 1 conversation" returns results
5. Search query "v0.4.0 development context" returns results
6. No memory errors in execution log
</verification>

<success_criteria>
- run_conversation_snapshot.py exists and processes JSONL files efficiently
- conversations_snapshot.json documents phase boundaries, counts, and code link statistics
- Key conversations from phases 1-10 indexed in memory
- Memory queries can retrieve development context by phase
- Conversations are linked to resulting code changes via commit correlation
- Script handles large (100MB+) JSONL files without memory issues
</success_criteria>

<output>
After completion, create `.planning/phases/11-memory-preparation/11-04-SUMMARY.md`
</output>
