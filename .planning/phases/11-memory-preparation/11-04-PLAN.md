---
phase: 11-memory-preparation
plan: 04
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py
  - .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json
autonomous: true
user_setup: []

must_haves:
  truths:
    - "v0.4.0 conversation history extracted from Claude Code transcripts"
    - "Conversations linked to phases 1-10 via timestamps"
    - "Memory contains development context from v0.4.0 work"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py"
      provides: "Executable script for conversation extraction"
      exports: ["run_conversation_snapshot", "main"]
    - path: ".planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json"
      provides: "Conversation history metadata and phase boundaries"
      contains: "phases"
  key_links:
    - from: "run_conversation_snapshot.py"
      to: "extract_conversations.py"
      via: "extract_conversation and link_conversations_to_phases calls"
      pattern: "from.*extract_conversations import"
    - from: "run_conversation_snapshot.py"
      to: "batch_indexer.py"
      via: "batch_add_memories call"
      pattern: "batch_add_memories"
---

<objective>
Extract v0.4.0 conversation history from Claude Code transcripts and index in memory system.

Purpose: Requirement MEMO-10 requires capturing v0.4.0 completion context. Conversation history provides development decisions, rationale, and context that will inform v0.5.0 work.

Output: Key conversations from phases 1-10 indexed in Mem0 with phase linkage, plus manifest documenting phase boundaries.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-memory-preparation/11-CONTEXT.md
@.planning/phases/11-memory-preparation/11-RESEARCH.md
@.planning/phases/11-memory-preparation/11-01-SUMMARY.md

# Snapshot infrastructure from Plan 01
@src/ta_lab2/tools/ai_orchestrator/memory/snapshot/extract_conversations.py
@src/ta_lab2/tools/ai_orchestrator/memory/snapshot/batch_indexer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create conversation snapshot script</name>
  <files>
    src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py
  </files>
  <action>
Create run_conversation_snapshot.py with:

1. Configuration:
   ```python
   CLAUDE_PROJECTS_DIR = Path.home() / ".claude" / "projects"
   PROJECT_FOLDER = "C--Users-asafi-Downloads-ta-lab2"
   PLANNING_DIR = Path("C:/Users/asafi/Downloads/ta_lab2/.planning")
   ```

2. `extract_conversation_summaries(messages: list[dict], max_per_phase: int = 10) -> list[dict]`:
   - Filter to most significant conversations (not every message)
   - Prioritize: user messages with questions, assistant messages with decisions/conclusions
   - Skip tool-use messages unless they show important operations
   - Return list of summary dicts with: role, content (truncated to 500 chars), timestamp, phase

3. `format_conversation_for_memory(conversation: dict, phase: int) -> str`:
   - Create memory-suitable content:
     ```
     Phase {phase} conversation ({date}):
     {role}: {content_summary}

     Context: Development discussion during v0.4.0 Phase {phase}
     ```
   - Keep under 1000 chars for embedding efficiency

4. `run_conversation_snapshot(repo_path: Path, dry_run: bool = False) -> dict`:
   - Find all JSONL files using find_conversation_files()
   - Extract all messages from all files
   - Get phase boundaries using extract_phase_boundaries()
   - Link conversations to phases using link_conversations_to_phases()
   - For each phase, extract conversation summaries
   - Create memory entries with:
     - content: format_conversation_for_memory()
     - metadata: create_snapshot_metadata with:
       - source="v0.4.0_conversations"
       - directory="conversations"
       - file_type="conversation"
       - phase=phase_number
       - conversation_date=timestamp
   - If not dry_run: call batch_add_memories()
   - Return stats: {phases_processed, conversations_indexed, phase_breakdown: {1: N, 2: M, ...}}

5. `save_conversation_manifest(stats: dict, phase_boundaries: dict, output_path: Path)`:
   - Save JSON with:
     - snapshot_type: "v0.4.0_conversations"
     - timestamp: ISO format
     - phases: phase_boundaries
     - stats: conversation counts per phase
     - jsonl_files_processed: list of files

6. `main()` with CLI, --dry-run flag, --max-per-phase option (default 10)

Handle large JSONL files (some are >100MB) by reading line-by-line, not loading entire file.
  </action>
  <verify>
Run dry-run: `python src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py --dry-run`
Expected: Shows phase boundaries and conversation counts without indexing.
  </verify>
  <done>
run_conversation_snapshot.py exists and dry-run shows phase boundary detection working. Script handles large JSONL files.
  </done>
</task>

<task type="auto">
  <name>Task 2: Execute conversation snapshot and validate</name>
  <files>
    .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json
  </files>
  <action>
Execute the conversation snapshot:

1. Run the snapshot script (not dry-run):
   ```bash
   python src/ta_lab2/tools/ai_orchestrator/memory/snapshot/run_conversation_snapshot.py
   ```

2. Verify conversation memories were added:
   ```python
   from ta_lab2.tools.ai_orchestrator.memory.mem0_client import get_mem0_client
   client = get_mem0_client()

   # Query for conversation memories
   results = client.search(
       query="v0.4.0 phase development discussion",
       user_id="orchestrator",
       limit=20
   )
   print(f"Found {len(results)} conversation memories")

   # Check specific phases
   for phase in [1, 5, 10]:
       results = client.search(
           query=f"Phase {phase} conversation context",
           user_id="orchestrator",
           limit=5
       )
       print(f"Phase {phase}: {len(results)} conversation memories")
   ```

3. Verify manifest was created at:
   .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json

4. Validate manifest contains:
   - Phase boundaries with dates
   - Conversation counts per phase
   - Total conversations indexed
   - List of processed JSONL files

5. Document any phases with no conversations found (may indicate missing transcripts).
  </action>
  <verify>
Check manifest: `cat .planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json`
Query test: `python -c "from ta_lab2.tools.ai_orchestrator.memory.mem0_client import get_mem0_client; c = get_mem0_client(); r = c.search('v0.4.0 phase development', 'orchestrator', limit=5); print(f'Conversations: {len(r)} results')"`
  </verify>
  <done>
conversations_snapshot.json exists with phase boundaries. Memory contains v0.4.0 conversation context. Queries return development discussions by phase.
  </done>
</task>

</tasks>

<verification>
1. Snapshot manifest exists: `.planning/phases/11-memory-preparation/snapshots/conversations_snapshot.json`
2. Manifest contains phase boundaries with start/end dates
3. Search query "Phase 1 conversation" returns results
4. Search query "v0.4.0 development context" returns results
5. No memory errors in execution log
</verification>

<success_criteria>
- run_conversation_snapshot.py exists and processes JSONL files efficiently
- conversations_snapshot.json documents phase boundaries and counts
- Key conversations from phases 1-10 indexed in memory
- Memory queries can retrieve development context by phase
- Script handles large (100MB+) JSONL files without memory issues
</success_criteria>

<output>
After completion, create `.planning/phases/11-memory-preparation/11-04-SUMMARY.md`
</output>
