---
phase: 05-orchestrator-coordination
plan: 04
type: execute
wave: 2
depends_on: ["05-02"]
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/cost.py
  - tests/orchestrator/test_cost_tracking.py
autonomous: true

must_haves:
  truths:
    - "Per-task costs recorded to SQLite"
    - "Chain-level cost aggregation works"
    - "Platform totals queryable"
    - "Session summary available"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/cost.py"
      provides: "CostTracker with SQLite persistence"
      exports: ["CostTracker", "CostRecord", "PRICING"]
      contains: "cost_records"
    - path: "tests/orchestrator/test_cost_tracking.py"
      provides: "Cost tracking test coverage"
      min_lines: 60
  key_links:
    - from: "cost.py"
      to: "sqlite3"
      via: "database connection"
      pattern: "sqlite3.connect"
---

<objective>
Implement per-task cost tracking with SQLite persistence

Purpose: Implement ORCH-09 - track per-task costs, per-platform totals, per-workflow chains, and session totals with SQLite persistence (per CONTEXT.md decision).

Output: New cost.py module with CostTracker, pricing tables, and comprehensive tests
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-orchestrator-coordination/05-CONTEXT.md
@.planning/phases/05-orchestrator-coordination/05-RESEARCH.md
@.planning/phases/05-orchestrator-coordination/05-02-SUMMARY.md
@src/ta_lab2/tools/ai_orchestrator/core.py
@src/ta_lab2/tools/ai_orchestrator/execution.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CostTracker with SQLite persistence</name>
  <files>src/ta_lab2/tools/ai_orchestrator/cost.py</files>
  <action>
Create new cost.py module:

```python
"""Cost tracking for orchestrator tasks with SQLite persistence."""

from __future__ import annotations

import sqlite3
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, TYPE_CHECKING

if TYPE_CHECKING:
    from .core import Task, Result


# Model pricing (USD per 1M tokens)
# Per CONTEXT.md: Track at all levels (per-task, per-platform, per-chain, session)
PRICING = {
    # Gemini models (free tier uses request count, not tokens)
    "gemini_cli": {"input": 0.0, "output": 0.0},  # Free tier
    "gemini-2.0-flash-exp": {"input": 0.0, "output": 0.0},  # Free tier
    "gemini_api": {"input": 0.075, "output": 0.30},  # Paid API

    # OpenAI models
    "gpt-4o-mini": {"input": 0.15, "output": 0.60},
    "gpt-4o": {"input": 2.50, "output": 10.00},
    "gpt-4-turbo": {"input": 10.00, "output": 30.00},

    # Claude models
    "claude-3-5-sonnet": {"input": 3.00, "output": 15.00},
    "claude-3-opus": {"input": 15.00, "output": 75.00},
    "claude-3-haiku": {"input": 0.25, "output": 1.25},

    # Default/unknown
    "unknown": {"input": 0.0, "output": 0.0},
}


@dataclass
class CostRecord:
    """Single cost record for persistence."""
    task_id: str
    platform: str
    chain_id: Optional[str]
    model: str
    input_tokens: int
    output_tokens: int
    cost_usd: float
    timestamp: datetime


class CostTracker:
    """
    Track and persist task costs to SQLite.

    Per CONTEXT.md decisions:
    - Granularity: All levels (per-task, per-platform, per-chain, session)
    - Persistence: Database table (SQLite for queries/analytics)
    - Budget limits: Soft warnings only (user stays in control)
    """

    def __init__(self, db_path: str = ".memory/cost_tracking.db"):
        """
        Initialize cost tracker.

        Args:
            db_path: Path to SQLite database file
        """
        self.db_path = db_path
        self._ensure_dir()
        self._init_db()

    def _ensure_dir(self):
        """Ensure parent directory exists."""
        path = Path(self.db_path)
        path.parent.mkdir(parents=True, exist_ok=True)

    def _init_db(self):
        """Initialize database schema."""
        conn = sqlite3.connect(self.db_path)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS cost_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_id TEXT NOT NULL,
                platform TEXT NOT NULL,
                chain_id TEXT,
                model TEXT NOT NULL,
                input_tokens INTEGER NOT NULL,
                output_tokens INTEGER NOT NULL,
                cost_usd REAL NOT NULL,
                timestamp TEXT NOT NULL,
                UNIQUE(task_id)
            )
        """)
        # Indexes for common queries
        conn.execute("CREATE INDEX IF NOT EXISTS idx_chain ON cost_records(chain_id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_platform ON cost_records(platform)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_timestamp ON cost_records(timestamp)")
        conn.commit()
        conn.close()

    def record(
        self,
        task: Task,
        result: Result,
        chain_id: Optional[str] = None
    ):
        """
        Record cost from a completed task.

        Args:
            task: The executed task
            result: Result from execution
            chain_id: Optional chain ID (overrides task metadata)
        """
        # Extract model and token info from result
        model = result.metadata.get("model", "unknown")
        pricing = PRICING.get(model, PRICING["unknown"])

        input_tokens = result.metadata.get("input_tokens", 0)
        output_tokens = result.metadata.get("output_tokens", result.tokens_used)

        # Calculate cost
        cost = (
            input_tokens * pricing["input"] / 1_000_000 +
            output_tokens * pricing["output"] / 1_000_000
        )

        # Create record
        record = CostRecord(
            task_id=task.task_id or f"unknown_{datetime.now().timestamp()}",
            platform=result.platform.value,
            chain_id=chain_id or task.metadata.get("chain_id"),
            model=model,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            cost_usd=cost,
            timestamp=datetime.now(timezone.utc)
        )

        self._persist(record)

    def _persist(self, record: CostRecord):
        """Persist a cost record to database."""
        conn = sqlite3.connect(self.db_path)
        conn.execute("""
            INSERT OR REPLACE INTO cost_records
            (task_id, platform, chain_id, model, input_tokens, output_tokens, cost_usd, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            record.task_id,
            record.platform,
            record.chain_id,
            record.model,
            record.input_tokens,
            record.output_tokens,
            record.cost_usd,
            record.timestamp.isoformat()
        ))
        conn.commit()
        conn.close()

    def get_task_cost(self, task_id: str) -> Optional[float]:
        """Get cost for a specific task."""
        conn = sqlite3.connect(self.db_path)
        result = conn.execute(
            "SELECT cost_usd FROM cost_records WHERE task_id = ?",
            (task_id,)
        ).fetchone()
        conn.close()
        return result[0] if result else None

    def get_chain_cost(self, chain_id: str) -> float:
        """Get total cost for a workflow chain."""
        conn = sqlite3.connect(self.db_path)
        result = conn.execute(
            "SELECT SUM(cost_usd) FROM cost_records WHERE chain_id = ?",
            (chain_id,)
        ).fetchone()
        conn.close()
        return result[0] or 0.0

    def get_platform_totals(self, since: Optional[datetime] = None) -> Dict[str, float]:
        """
        Get total costs by platform.

        Args:
            since: Optional datetime to filter records (default: all time)

        Returns:
            Dict of platform -> total cost USD
        """
        conn = sqlite3.connect(self.db_path)
        if since:
            rows = conn.execute(
                """SELECT platform, SUM(cost_usd) as total
                   FROM cost_records
                   WHERE timestamp >= ?
                   GROUP BY platform""",
                (since.isoformat(),)
            ).fetchall()
        else:
            rows = conn.execute(
                """SELECT platform, SUM(cost_usd) as total
                   FROM cost_records
                   GROUP BY platform"""
            ).fetchall()
        conn.close()
        return {row[0]: row[1] for row in rows}

    def get_session_summary(self, date: Optional[datetime] = None) -> Dict:
        """
        Get cost summary for a session (default: today).

        Returns:
            Dict with per-platform stats and totals
        """
        target_date = date or datetime.now(timezone.utc)
        date_str = target_date.strftime("%Y-%m-%d")

        conn = sqlite3.connect(self.db_path)
        rows = conn.execute("""
            SELECT platform,
                   COUNT(*) as tasks,
                   SUM(cost_usd) as total_cost,
                   SUM(input_tokens + output_tokens) as total_tokens
            FROM cost_records
            WHERE date(timestamp) = date(?)
            GROUP BY platform
        """, (date_str,)).fetchall()
        conn.close()

        summary = {
            "date": date_str,
            "by_platform": {},
            "total_cost": 0.0,
            "total_tasks": 0,
            "total_tokens": 0,
        }

        for row in rows:
            platform, tasks, cost, tokens = row
            summary["by_platform"][platform] = {
                "tasks": tasks,
                "cost": cost or 0.0,
                "tokens": tokens or 0,
            }
            summary["total_cost"] += cost or 0.0
            summary["total_tasks"] += tasks
            summary["total_tokens"] += tokens or 0

        return summary

    def get_chain_tasks(self, chain_id: str) -> List[CostRecord]:
        """Get all task records for a chain."""
        conn = sqlite3.connect(self.db_path)
        rows = conn.execute("""
            SELECT task_id, platform, chain_id, model,
                   input_tokens, output_tokens, cost_usd, timestamp
            FROM cost_records
            WHERE chain_id = ?
            ORDER BY timestamp
        """, (chain_id,)).fetchall()
        conn.close()

        return [
            CostRecord(
                task_id=row[0],
                platform=row[1],
                chain_id=row[2],
                model=row[3],
                input_tokens=row[4],
                output_tokens=row[5],
                cost_usd=row[6],
                timestamp=datetime.fromisoformat(row[7])
            )
            for row in rows
        ]

    def estimate_cost(self, prompt: str, model: str = "gpt-4o-mini") -> float:
        """
        Estimate cost for a prompt before execution.

        Per CONTEXT.md: Estimate for expensive only (>10k tokens).
        This method can be called to check if estimation is needed.

        Args:
            prompt: Prompt text
            model: Model to estimate for

        Returns:
            Estimated cost in USD
        """
        # Rough token estimate: ~4 chars per token
        estimated_input_tokens = len(prompt) // 4
        # Assume output ~= input for estimation
        estimated_output_tokens = estimated_input_tokens

        pricing = PRICING.get(model, PRICING["unknown"])
        return (
            estimated_input_tokens * pricing["input"] / 1_000_000 +
            estimated_output_tokens * pricing["output"] / 1_000_000
        )

    def should_warn_cost(self, prompt: str, threshold_tokens: int = 10000) -> bool:
        """
        Check if prompt is large enough to warrant cost warning.

        Per CONTEXT.md: Estimate cost when prompt > threshold (e.g., 10k tokens).

        Args:
            prompt: Prompt text
            threshold_tokens: Token threshold for warning (default 10k)

        Returns:
            True if cost estimation/warning recommended
        """
        estimated_tokens = len(prompt) // 4
        return estimated_tokens > threshold_tokens

    def display_summary(self, date: Optional[datetime] = None) -> str:
        """Format cost summary for CLI display."""
        summary = self.get_session_summary(date)

        lines = [
            f"Cost Summary for {summary['date']}",
            "=" * 50,
            f"\nTotal: ${summary['total_cost']:.4f} ({summary['total_tasks']} tasks, {summary['total_tokens']:,} tokens)",
            "\nBy Platform:",
        ]

        for platform, stats in summary["by_platform"].items():
            lines.append(
                f"  {platform}: ${stats['cost']:.4f} "
                f"({stats['tasks']} tasks, {stats['tokens']:,} tokens)"
            )

        return "\n".join(lines)
```
  </action>
  <verify>
Import verification: `python -c "from ta_lab2.tools.ai_orchestrator.cost import CostTracker, CostRecord, PRICING; print('Models:', len(PRICING))"`
  </verify>
  <done>
CostTracker class exists with SQLite persistence, PRICING table defines model costs, methods for per-task/chain/platform/session queries work
  </done>
</task>

<task type="auto">
  <name>Task 2: Create comprehensive tests for cost tracking</name>
  <files>tests/orchestrator/test_cost_tracking.py</files>
  <action>
Create test file with comprehensive coverage:

```python
"""Tests for cost tracking with SQLite persistence."""
import pytest
import tempfile
from datetime import datetime, timezone
from pathlib import Path

from ta_lab2.tools.ai_orchestrator.cost import (
    CostTracker,
    CostRecord,
    PRICING,
)
from ta_lab2.tools.ai_orchestrator.core import Task, Result, TaskType, Platform


class TestPricing:
    """Test PRICING configuration."""

    def test_gemini_free_is_zero(self):
        """Gemini free tier has zero cost."""
        assert PRICING["gemini_cli"]["input"] == 0.0
        assert PRICING["gemini_cli"]["output"] == 0.0

    def test_openai_models_have_pricing(self):
        """OpenAI models have non-zero pricing."""
        assert PRICING["gpt-4o-mini"]["input"] > 0
        assert PRICING["gpt-4o"]["input"] > 0


class TestCostTracker:
    """Test CostTracker class."""

    @pytest.fixture
    def tracker(self, tmp_path):
        """Create tracker with temp database."""
        db_path = tmp_path / "test_costs.db"
        return CostTracker(str(db_path))

    @pytest.fixture
    def sample_task(self):
        """Create sample task for testing."""
        return Task(
            type=TaskType.CODE_GENERATION,
            prompt="Test prompt",
            task_id="test_task_123",
            metadata={"chain_id": "chain_abc"},
        )

    @pytest.fixture
    def sample_result(self, sample_task):
        """Create sample result for testing."""
        return Result(
            task=sample_task,
            platform=Platform.CHATGPT,
            output="Test output",
            success=True,
            tokens_used=150,
            metadata={
                "model": "gpt-4o-mini",
                "input_tokens": 100,
                "output_tokens": 50,
            },
        )

    def test_record_creates_entry(self, tracker, sample_task, sample_result):
        """record() creates database entry."""
        tracker.record(sample_task, sample_result)
        cost = tracker.get_task_cost("test_task_123")
        assert cost is not None
        assert cost >= 0

    def test_get_chain_cost_sums_tasks(self, tracker, sample_task, sample_result):
        """get_chain_cost returns sum of all tasks in chain."""
        # Record multiple tasks in same chain
        tracker.record(sample_task, sample_result)

        task2 = Task(
            type=TaskType.CODE_GENERATION,
            prompt="Test 2",
            task_id="test_task_456",
            metadata={"chain_id": "chain_abc"},
        )
        result2 = Result(
            task=task2,
            platform=Platform.CHATGPT,
            output="Output 2",
            success=True,
            metadata={"model": "gpt-4o-mini", "input_tokens": 200, "output_tokens": 100},
        )
        tracker.record(task2, result2)

        chain_cost = tracker.get_chain_cost("chain_abc")
        task1_cost = tracker.get_task_cost("test_task_123")
        task2_cost = tracker.get_task_cost("test_task_456")

        assert chain_cost == pytest.approx(task1_cost + task2_cost, rel=1e-6)

    def test_get_platform_totals(self, tracker, sample_task, sample_result):
        """get_platform_totals groups by platform."""
        tracker.record(sample_task, sample_result)
        totals = tracker.get_platform_totals()
        assert "chatgpt" in totals

    def test_get_session_summary(self, tracker, sample_task, sample_result):
        """get_session_summary returns today's stats."""
        tracker.record(sample_task, sample_result)
        summary = tracker.get_session_summary()
        assert summary["total_tasks"] >= 1
        assert "chatgpt" in summary["by_platform"]


class TestCostEstimation:
    """Test cost estimation functionality."""

    @pytest.fixture
    def tracker(self, tmp_path):
        db_path = tmp_path / "test_costs.db"
        return CostTracker(str(db_path))

    def test_estimate_cost_returns_positive(self, tracker):
        """Estimate returns positive cost for paid models."""
        cost = tracker.estimate_cost("Hello world", model="gpt-4o-mini")
        assert cost >= 0

    def test_should_warn_cost_above_threshold(self, tracker):
        """Warns when prompt above token threshold."""
        # ~40k chars = ~10k tokens
        long_prompt = "x" * 50000
        assert tracker.should_warn_cost(long_prompt) is True

    def test_should_warn_cost_below_threshold(self, tracker):
        """No warning for short prompts."""
        short_prompt = "Hello world"
        assert tracker.should_warn_cost(short_prompt) is False


class TestCostRecord:
    """Test CostRecord dataclass."""

    def test_dataclass_fields(self):
        """CostRecord has all required fields."""
        record = CostRecord(
            task_id="task_1",
            platform="chatgpt",
            chain_id="chain_1",
            model="gpt-4o-mini",
            input_tokens=100,
            output_tokens=50,
            cost_usd=0.0001,
            timestamp=datetime.now(timezone.utc),
        )
        assert record.task_id == "task_1"
        assert record.cost_usd == 0.0001
```
  </action>
  <verify>
Run tests: `pytest tests/orchestrator/test_cost_tracking.py -v`
  </verify>
  <done>
All cost tracking tests pass, covering record creation, chain aggregation, platform totals, session summary, and cost estimation
  </done>
</task>

</tasks>

<verification>
1. Import verification: `python -c "from ta_lab2.tools.ai_orchestrator.cost import CostTracker, PRICING"`
2. Test suite: `pytest tests/orchestrator/test_cost_tracking.py -v`
3. All orchestrator tests pass: `pytest tests/orchestrator/ -v`
</verification>

<success_criteria>
- CostTracker persists to SQLite with cost_records table
- PRICING constant has correct costs for Gemini/OpenAI/Claude models
- get_chain_cost aggregates costs for workflow chains
- get_session_summary provides daily cost overview
- estimate_cost and should_warn_cost support pre-execution warnings
</success_criteria>

<output>
After completion, create `.planning/phases/05-orchestrator-coordination/05-04-SUMMARY.md`
</output>
