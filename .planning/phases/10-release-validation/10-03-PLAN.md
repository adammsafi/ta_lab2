---
phase: 10-release-validation
plan: 03
type: execute
wave: 2
depends_on: [10-01]
files_modified:
  - tests/validation/test_backtest_reproducibility.py
autonomous: true

must_haves:
  truths:
    - "Backtest reproducibility validation confirms identical results on reruns"
    - "Feature hash validation detects data changes"
    - "Reproducibility tests are CI blockers"
  artifacts:
    - path: "tests/validation/test_backtest_reproducibility.py"
      provides: "Backtest reproducibility validation tests"
      min_lines: 100
  key_links:
    - from: "tests/validation/test_backtest_reproducibility.py"
      to: "src/ta_lab2/scripts/signals/validate_reproducibility.py"
      via: "import"
      pattern: "from ta_lab2.scripts.signals.validate_reproducibility import"
---

<objective>
Create backtest reproducibility validation tests

Purpose: Implement SIG-06 (backtest reproducibility validation) as CI blocker. Wraps existing validate_reproducibility.py functionality into pytest tests that can run in CI with real database.

Output: Pytest test module that validates backtest determinism using existing reproducibility infrastructure
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-release-validation/10-CONTEXT.md
@.planning/phases/10-release-validation/10-RESEARCH.md

# Existing reproducibility validation (from Phase 8)
@src/ta_lab2/scripts/signals/validate_reproducibility.py

# Existing reproducibility tests (reference)
@tests/signals/test_reproducibility.py

# Validation fixtures
@tests/validation/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create backtest reproducibility validation tests</name>
  <files>tests/validation/test_backtest_reproducibility.py</files>
  <action>
Create CI-ready backtest reproducibility validation tests (SIG-06):

1. Imports:
   - pytest, sqlalchemy, os
   - from ta_lab2.scripts.signals.validate_reproducibility import (
       validate_backtest_reproducibility,
       validate_feature_hash_current,
       ReproducibilityReport
     )
   - from ta_lab2.scripts.signals.signal_utils import compute_feature_hash

2. Class `TestBacktestReproducibilityValidation`:

   a. `test_backtest_produces_identical_results_on_rerun`:
      - For each signal type (ema_crossover, rsi_mean_revert, atr_breakout):
        - If signal table has data, run validate_backtest_reproducibility
        - Assert report.is_reproducible == True
        - Assert len(report.differences) == 0
      - Skip signal types with no data
      - Mark as @pytest.mark.validation_gate

   b. `test_feature_hash_validates_current_data`:
      - For sample signal from database, call validate_feature_hash_current with mode='strict'
      - Assert returns True (hash matches current feature data)
      - If hash mismatch found, test should FAIL (strict mode per CONTEXT.md)

   c. `test_pnl_determinism_within_tolerance`:
      - Run same backtest twice via SignalBacktester
      - Compare total_pnl values
      - Assert abs(pnl1 - pnl2) < 1e-10 (floating point tolerance)

   d. `test_trade_count_determinism`:
      - Run backtest twice
      - Assert trade_count1 == trade_count2 exactly (integer, no tolerance)

   e. `test_metric_reproducibility`:
      - Run backtest twice
      - Compare key metrics: sharpe_ratio, win_rate, profit_factor
      - Assert all within 1e-10 tolerance

3. Helper fixtures:
   - `sample_signal(db_session)` -> returns first valid signal from any signal table
   - `backtester(db_session)` -> returns configured SignalBacktester instance

4. Graceful handling:
   - Skip tests if no signals exist in database (early project state)
   - Clear error messages on failure explaining which value differed

5. All tests use @pytest.mark.validation_gate marker

Note: This wraps existing validate_reproducibility.py (Phase 8) into CI-runnable tests. The core logic already exists; we're creating the pytest wrapper for CI integration.
  </action>
  <verify>
`pytest tests/validation/test_backtest_reproducibility.py --collect-only` shows 5 test methods collected
  </verify>
  <done>Backtest reproducibility tests validate SIG-06 using existing validate_reproducibility infrastructure</done>
</task>

<task type="auto">
  <name>Task 2: Create validation report generator</name>
  <files>tests/validation/conftest.py</files>
  <action>
Extend conftest.py with validation report generation:

1. Add `pytest_sessionfinish` hook to generate markdown summary:
   ```python
   def pytest_sessionfinish(session, exitstatus):
       """Generate validation summary after all tests complete."""
       if not hasattr(session.config, '_validation_results'):
           return

       results = session.config._validation_results
       # Generate reports/validation_summary.md
   ```

2. Add fixture to collect validation results:
   ```python
   @pytest.fixture(autouse=True)
   def collect_validation_result(request, record_property):
       """Collect validation test results for summary report."""
       yield
       # Record pass/fail status
   ```

3. Add `validation_summary` fixture:
   ```python
   @pytest.fixture(scope="session")
   def validation_summary():
       """Track validation test outcomes."""
       return {
           "time_alignment": {"passed": 0, "failed": 0},
           "data_consistency": {"passed": 0, "failed": 0},
           "backtest_reproducibility": {"passed": 0, "failed": 0},
       }
   ```

Note: This enables dual-output (JSON from pytest-json-report + markdown from this hook) per CONTEXT.md requirement.
  </action>
  <verify>
`python -c "from tests.validation.conftest import validation_summary; print('Hook importable')"` succeeds
  </verify>
  <done>Validation conftest extended with report generation hooks</done>
</task>

</tasks>

<verification>
1. `pytest tests/validation/ --collect-only` shows all 3 validation test modules
2. Reproducibility tests import from existing validate_reproducibility.py
3. Tests skip gracefully if database or signals not available
4. All tests have validation_gate marker
</verification>

<success_criteria>
- test_backtest_reproducibility.py validates SIG-06 (5 tests)
- Tests reuse existing validate_reproducibility.py infrastructure
- Dual-output reporting enabled (JSON + markdown)
- Zero tolerance for reproducibility failures (strict mode)
</success_criteria>

<output>
After completion, create `.planning/phases/10-release-validation/10-03-SUMMARY.md`
</output>
