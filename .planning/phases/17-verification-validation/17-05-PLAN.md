---
phase: 17-verification-validation
plan: 05
type: execute
wave: 3
depends_on: ["17-01"]
files_modified:
  - tests/validation/test_data_loss.py
autonomous: true

must_haves:
  truths:
    - "No files lost during v0.5.0 reorganization (verified via checksums)"
    - "File count equation holds: baseline_count <= current_count + archived_count (secondary safety net)"
    - "Memory can answer 'where did file X go?' for moved files"
  artifacts:
    - path: "tests/validation/test_data_loss.py"
      provides: "Data loss validation tests"
      exports: ["test_no_files_lost_from_baseline", "test_file_count_accounting", "test_memory_tracks_file_moves"]
  key_links:
    - from: "tests/validation/test_data_loss.py"
      to: "ta_lab2.tools.archive.validate"
      via: "Import validation functions"
      pattern: "from ta_lab2\\.tools\\.archive"
    - from: "tests/validation/test_data_loss.py"
      to: ".planning/phases/12-archive-foundation/baseline/pre_reorg_snapshot.json"
      via: "Baseline loading"
      pattern: "pre_reorg_snapshot"
---

<objective>
Create data loss validation tests using Phase 12 baseline

Purpose: Verify no files were lost during v0.5.0 reorganization (Phases 11-16)
Output: tests/validation/test_data_loss.py with checksum and memory verification
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-verification-validation/17-CONTEXT.md
@.planning/phases/17-verification-validation/17-RESEARCH.md

# Phase 12 validation tooling (provides create_snapshot, validate_no_data_loss)
@.planning/phases/12-archive-foundation/12-03-SUMMARY.md
@src/ta_lab2/tools/archive/validate.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create data loss validation test suite</name>
  <files>tests/validation/test_data_loss.py</files>
  <action>
Create tests/validation/test_data_loss.py with comprehensive data loss validation.

Include these tests:

1. **test_no_files_lost_from_baseline():** (PRIMARY VALIDATION)
   - Load Phase 12 baseline snapshot from .planning/phases/12-archive-foundation/baseline/pre_reorg_snapshot.json
   - Create current snapshot of src/ta_lab2, tests, AND .archive (not .venv)
   - Use checksum-based validation: for each baseline checksum, verify it exists SOMEWHERE in current codebase
   - Files can move (checksum in different location), but checksum MUST exist
   - This is the primary data loss detection - if checksum missing, file content is lost
   - Skip if baseline not found

2. **test_file_count_accounting():** (SECONDARY SAFETY NET)
   - Count files in src/ta_lab2 (current)
   - Count files in .archive (archived)
   - Count files in tests (current)
   - Verify: baseline_src_tests_count <= current_total + archived_count
   - NOTE: This uses inequality intentionally because:
     a) New files may be added (current > baseline is fine)
     b) Primary validation is checksum-based (test_no_files_lost_from_baseline)
     c) This test catches edge case where file replaced with different content but same filename
   - If count drops BELOW baseline, something was deleted without archiving
   - Skip if baseline not found

3. **test_memory_tracks_file_moves():** (MEMORY SYSTEM VALIDATION)
   - Marked with @pytest.mark.orchestrator (requires chromadb/mem0)
   - Query memory for representative sample of moved files (from Phases 13-16)
   - Uses sampling approach with 8 representative files (justification: validates memory system works correctly; comprehensive moved_to tracking is documented in Phase 14 summaries)
   - Sample includes files from different migration phases and different destination types
   - Skip if chromadb not installed

```python
"""Validate no data loss during v0.5.0 reorganization.

Uses Phase 12 baseline (9,620 files with SHA256 checksums) to verify
all files still exist, potentially at new locations after moves.

Validation Strategy:
1. PRIMARY: Checksum validation (test_no_files_lost_from_baseline)
   - Every baseline checksum must exist somewhere in current codebase
   - Files can move, but content cannot be lost

2. SECONDARY: File count check (test_file_count_accounting)
   - Catches edge case where file replaced with different content
   - Uses inequality (baseline <= current) because new files are fine

3. MEMORY: Moved file tracking (test_memory_tracks_file_moves)
   - Validates memory system can answer "where did X go?"
   - Uses representative sampling across migration phases
"""
from pathlib import Path
import pytest

# Import Phase 12 validation tooling
from ta_lab2.tools.archive.validate import (
    create_snapshot,
    load_snapshot,
    validate_no_data_loss,
)


BASELINE_PATH = Path(".planning/phases/12-archive-foundation/baseline/pre_reorg_snapshot.json")


def test_no_files_lost_from_baseline():
    """PRIMARY VALIDATION: All src/tests files from Phase 12 baseline still exist.

    Files can move (checksum same, path different), but cannot be deleted.
    Uses checksum-based validation that tracks files through moves.

    This is the primary data loss detection mechanism. If a checksum from
    baseline is not found anywhere in current codebase (src + tests + archive),
    that file's content has been lost.
    """
    if not BASELINE_PATH.exists():
        pytest.skip(f"Baseline not found: {BASELINE_PATH}")

    # Load Phase 12 baseline
    baseline = load_snapshot(BASELINE_PATH)

    # Create current snapshot of ALL locations where files might exist
    # This includes src, tests, and .archive (files may have been archived)
    current_src = create_snapshot(Path("src"), pattern="**/*.py", compute_checksums=True)
    current_tests = create_snapshot(Path("tests"), pattern="**/*.py", compute_checksums=True)

    # Check .archive if it exists (files may have been archived, not deleted)
    archive_path = Path(".archive")
    current_archive = None
    if archive_path.exists():
        current_archive = create_snapshot(archive_path, pattern="**/*.py", compute_checksums=True)

    # Build set of ALL current checksums (files can be anywhere)
    all_current_checksums = set()
    all_current_checksums.update(current_src.file_checksums.values())
    all_current_checksums.update(current_tests.file_checksums.values())
    if current_archive:
        all_current_checksums.update(current_archive.file_checksums.values())

    # Get baseline checksums for src and tests only (not .venv or other dirs)
    baseline_src_tests = {
        path: checksum
        for path, checksum in baseline.file_checksums.items()
        if path.startswith("src/") or path.startswith("tests/")
    }

    # PRIMARY CHECK: Every baseline checksum must exist somewhere
    missing = []
    for path, checksum in baseline_src_tests.items():
        if checksum not in all_current_checksums:
            missing.append(f"{path} (checksum: {checksum[:16]}...)")

    if missing:
        pytest.fail(
            f"DATA LOSS DETECTED - {len(missing)} files from baseline not found anywhere:\n"
            f"(Searched: src/, tests/, .archive/)\n"
            + "\n".join(f"  - {m}" for m in missing[:20])
            + (f"\n  ... and {len(missing) - 20} more" if len(missing) > 20 else "")
        )


def test_file_count_accounting():
    """SECONDARY SAFETY NET: Verify file counts haven't dropped.

    Equation: baseline_count <= current + archived

    Why inequality (<=) not equality (=)?
    - New files may be added during development (current > baseline is expected)
    - Primary validation is checksum-based (test_no_files_lost_from_baseline)
    - This test catches edge case: file replaced with different content but same name

    If baseline > current + archived, files were deleted without archiving.
    This is a secondary check - checksum validation is primary.
    """
    if not BASELINE_PATH.exists():
        pytest.skip(f"Baseline not found: {BASELINE_PATH}")

    baseline = load_snapshot(BASELINE_PATH)

    # Count baseline src + tests files (not .venv)
    baseline_src_tests_count = sum(
        1 for path in baseline.file_checksums.keys()
        if path.startswith("src/") or path.startswith("tests/")
    )

    # Count current files in all locations
    current_src = create_snapshot(Path("src"), pattern="**/*.py", compute_checksums=False)
    current_tests = create_snapshot(Path("tests"), pattern="**/*.py", compute_checksums=False)

    archive_count = 0
    archive_path = Path(".archive")
    if archive_path.exists():
        current_archive = create_snapshot(archive_path, pattern="**/*.py", compute_checksums=False)
        archive_count = current_archive.total_files

    current_total = current_src.total_files + current_tests.total_files + archive_count

    # SECONDARY CHECK: Count should not drop below baseline
    # (New files being added is fine, that's why we use <=)
    if baseline_src_tests_count > current_total:
        pytest.fail(
            f"FILE COUNT DROPPED - potential data loss:\n"
            f"  Baseline (src+tests): {baseline_src_tests_count}\n"
            f"  Current src: {current_src.total_files}\n"
            f"  Current tests: {current_tests.total_files}\n"
            f"  Archived: {archive_count}\n"
            f"  Current total: {current_total}\n"
            f"  Missing: {baseline_src_tests_count - current_total} files\n"
            f"\n"
            f"NOTE: This is a secondary check. Primary validation (checksum-based)\n"
            f"in test_no_files_lost_from_baseline provides definitive data loss detection."
        )


@pytest.mark.orchestrator
def test_memory_tracks_file_moves():
    """MEMORY VALIDATION: Verify memory answers 'where did file X go?' for moved files.

    Queries memory for moved_to relationships created during Phases 13-16.

    Sampling Approach Justification:
    - Uses 8 representative files across different migration phases and destinations
    - Validates memory system works correctly (can store and retrieve moved_to relationships)
    - Comprehensive moved_to tracking documented in Phase 14 summaries
    - Full enumeration would be redundant with checksum validation

    Sample Selection Criteria:
    - Files from different phases (13, 14, 15, 16)
    - Different destination types (tools/, archive/, scripts/)
    - Mix of core functionality and utilities
    """
    pytest.importorskip("chromadb", reason="chromadb required for memory queries")
    pytest.importorskip("mem0ai", reason="mem0ai required for memory queries")

    try:
        from ta_lab2.tools.ai_orchestrator.memory import get_client
    except ImportError:
        pytest.skip("Memory client not available")

    # Representative sample of files moved in Phases 13-16
    # 8 files covering different phases and destination types
    moved_files = [
        # Phase 14: Data_Tools migration to tools/data_tools/
        ("generate_function_map.py", "ta_lab2.tools.data_tools.analysis"),
        ("tree_structure.py", "ta_lab2.tools.data_tools.analysis"),
        ("db_utils.py", "ta_lab2.tools.data_tools.db"),

        # Phase 14: Documentation archiving
        ("ProjectTT_overview.md", ".archive/documentation"),
        ("DATA_TOOLS_README.md", ".archive/documentation"),

        # Phase 13: Script consolidation
        ("refresh_ema_daily_stats.py", "ta_lab2.scripts.emas.stats"),

        # Phase 15: Feature reorganization (if applicable)
        ("ema_utils.py", "ta_lab2.features"),

        # Phase 16: Test reorganization
        ("test_ema_calculation.py", "tests/features"),
    ]

    try:
        client = get_client()
    except Exception as e:
        pytest.skip(f"Could not initialize memory client: {e}")

    missing_tracking = []
    found_tracking = []

    for old_name, expected_location in moved_files:
        # Query memory for this file's new location
        results = client.search(
            f"where is {old_name} now? moved_to relationship",
            user_id="ta_lab2",
            limit=5
        )

        # Check if any result mentions the expected location
        found = False
        for result in results:
            if expected_location in str(result):
                found = True
                found_tracking.append(f"{old_name} -> {expected_location}")
                break

        if not found:
            missing_tracking.append(f"{old_name} -> expected in {expected_location}")

    # Report results
    if missing_tracking:
        # Allow some failures (files may not have been migrated or memory not populated)
        # But fail if majority are missing (indicates memory system issue)
        failure_rate = len(missing_tracking) / len(moved_files)
        if failure_rate > 0.5:
            pytest.fail(
                f"Memory missing moved_to relationships for {len(missing_tracking)}/{len(moved_files)} sampled files:\n"
                + "\n".join(f"  - {m}" for m in missing_tracking)
                + f"\n\nFound tracking for:\n"
                + "\n".join(f"  + {f}" for f in found_tracking)
            )
        else:
            # Partial success - warn but don't fail
            import warnings
            warnings.warn(
                f"Memory has partial moved_to coverage: {len(found_tracking)}/{len(moved_files)} files tracked.\n"
                f"Missing: {', '.join(m.split(' ->')[0] for m in missing_tracking)}"
            )
```
  </action>
  <verify>pytest tests/validation/test_data_loss.py --collect-only shows 3 tests</verify>
  <done>tests/validation/test_data_loss.py exists with checksum-primary validation, count-secondary safety net, and expanded memory sampling (8 files)</done>
</task>

<task type="auto">
  <name>Task 2: Run data loss validation</name>
  <files></files>
  <action>
Run the data loss validation tests to verify v0.5.0 reorganization integrity.

Commands:
1. Run non-orchestrator tests (checksum validation):
   pytest tests/validation/test_data_loss.py -m "not orchestrator" -v

2. If orchestrator deps installed, run memory tracking test:
   pytest tests/validation/test_data_loss.py -v

Expected outcomes:
- test_no_files_lost_from_baseline: PASS (all checksums found in src/tests/archive)
- test_file_count_accounting: PASS (baseline <= current + archived)
- test_memory_tracks_file_moves: PASS or SKIP (depending on deps), may WARN on partial coverage

Validation Hierarchy:
1. PRIMARY: test_no_files_lost_from_baseline - definitive data loss detection via checksums
2. SECONDARY: test_file_count_accounting - catches replaced-content edge case
3. MEMORY: test_memory_tracks_file_moves - validates memory system functionality

If failures:
- For checksum failures: Document which files are missing, check git history
- For count failures: Compare with baseline, identify deleted files
- For memory failures: Check if memory was populated during Phase 14
- Check .archive/ for accidentally deleted files
- Check git history with `git log --all -- <filename>`
  </action>
  <verify>pytest tests/validation/test_data_loss.py -m "not orchestrator" -v passes or documents issues</verify>
  <done>Data loss validation complete with results documented</done>
</task>

</tasks>

<verification>
1. tests/validation/test_data_loss.py exists
2. Test uses Phase 12 baseline (9,620 files)
3. Checksum validation is PRIMARY (covers src + tests + .archive)
4. File count is SECONDARY safety net with clear justification for inequality
5. Memory tracking test samples 8 representative files across phases
6. Memory test has clear sampling justification in docstring
7. Tests pass or clearly document missing files
</verification>

<success_criteria>
- No files lost from baseline (checksum-verified as PRIMARY validation)
- File count equation holds: baseline <= current + archived (SECONDARY safety net)
- Memory tracks moved_to relationships for sampled files (8 representative files)
- Validation hierarchy clearly documented (primary checksum, secondary count, memory system)
- Zero data loss from v0.5.0 reorganization
</success_criteria>

<output>
After completion, create `.planning/phases/17-verification-validation/17-05-SUMMARY.md`
</output>
