---
phase: 17-verification-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test_imports.py
  - pyproject.toml
autonomous: true

must_haves:
  truths:
    - "All ta_lab2 modules importable without errors"
    - "All ta_lab2.tools modules importable without errors"
    - "Test file imports validated"
    - "Optional dependency tests skip gracefully when deps missing"
  artifacts:
    - path: "tests/test_imports.py"
      provides: "Dynamic import validation tests"
      exports: ["test_ta_lab2_module_import", "test_tools_module_import", "test_orchestrator_imports"]
    - path: "pyproject.toml"
      provides: "Updated pytest markers"
      contains: "orchestrator"
  key_links:
    - from: "tests/test_imports.py"
      to: "pkgutil.walk_packages"
      via: "Dynamic module discovery"
      pattern: "pkgutil\\.walk_packages"
    - from: "tests/test_imports.py"
      to: "pytest.mark.parametrize"
      via: "Test parametrization"
      pattern: "@pytest\\.mark\\.parametrize"
---

<objective>
Create comprehensive import validation test suite using dynamic module discovery

Purpose: Validate all ta_lab2 modules can be imported without errors after v0.5.0 reorganization
Output: tests/test_imports.py with parametrized tests for every module in ta_lab2
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-verification-validation/17-CONTEXT.md
@.planning/phases/17-verification-validation/17-RESEARCH.md

# Existing import test (static, replace with dynamic)
@tests/test_smoke_imports.py

# Existing pyproject.toml for marker configuration
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create dynamic import validation test suite</name>
  <files>tests/test_imports.py</files>
  <action>
Create tests/test_imports.py with dynamic module discovery using pkgutil.walk_packages.

Include:
1. `discover_package_modules(package_name, package_path)` helper that:
   - Uses pkgutil.walk_packages to recursively find all modules
   - Returns list of module name strings (not objects)
   - Has onerror callback to log but not fail on discovery issues

2. Module discovery at collection time:
   - TA_LAB2_MODULES: All modules in src/ta_lab2 (excluding tools)
   - TOOLS_MODULES: All modules in src/ta_lab2/tools
   - TEST_MODULES: All modules in tests/ directory

3. Parametrized test functions:
   - `test_ta_lab2_module_import(module_name)`: Test core ta_lab2 modules
   - `test_tools_module_import(module_name)`: Test ta_lab2.tools modules
   - `test_test_module_import(module_name)`: Test that test files can be imported

4. Optional dependency tests with markers:
   - `test_orchestrator_imports()`: Marked with @pytest.mark.orchestrator
   - Uses pytest.importorskip for chromadb, mem0ai
   - Tests ta_lab2.tools.ai_orchestrator modules

Use importlib.import_module() inside test functions (not at parametrize time).
Handle ImportError gracefully with pytest.fail() for clear error messages.
  </action>
  <verify>pytest tests/test_imports.py -v --collect-only shows parametrized tests discovered</verify>
  <done>tests/test_imports.py exists with parametrized tests for all discovered modules</done>
</task>

<task type="auto">
  <name>Task 2: Update pyproject.toml with orchestrator marker</name>
  <files>pyproject.toml</files>
  <action>
Add orchestrator marker to pytest.ini_options markers list in pyproject.toml.

Add this line to the markers array:
```
"orchestrator: Tests requiring chromadb/mem0ai optional dependencies",
```

This marker allows running tests with/without optional dependencies:
- `pytest -m "not orchestrator"` - core tests only
- `pytest -m "orchestrator"` - optional dependency tests only
- `pytest` - all tests (skips orchestrator if deps missing)
  </action>
  <verify>grep -n "orchestrator:" pyproject.toml shows marker defined</verify>
  <done>pyproject.toml has orchestrator marker in pytest markers list</done>
</task>

<task type="auto">
  <name>Task 3: Run import validation tests</name>
  <files></files>
  <action>
Run the new import validation test suite to verify all modules import successfully.

Commands:
1. Run core import tests (exclude orchestrator):
   pytest tests/test_imports.py -m "not orchestrator" -v

2. If orchestrator deps installed, run those too:
   pytest tests/test_imports.py -v

Report any import failures - these indicate issues from v0.5.0 reorganization that need fixing.
  </action>
  <verify>pytest tests/test_imports.py -m "not orchestrator" exits with code 0</verify>
  <done>All core module imports pass, orchestrator tests skip if deps missing</done>
</task>

</tasks>

<verification>
1. tests/test_imports.py exists with pkgutil-based discovery
2. pytest --collect-only shows 50+ parametrized import tests
3. pytest -m "not orchestrator" passes for core modules
4. orchestrator marker defined in pyproject.toml
</verification>

<success_criteria>
- All ta_lab2 modules importable without errors
- All ta_lab2.tools modules importable without errors
- Test discovery is dynamic (no hardcoded module lists that go stale)
- Optional dependency tests skip gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/17-verification-validation/17-01-SUMMARY.md`
</output>
