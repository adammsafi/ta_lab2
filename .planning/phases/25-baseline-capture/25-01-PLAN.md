---
phase: 25-baseline-capture
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - sql/ddl/create_dim_assets.sql
  - sql/baseline/.gitkeep
  - src/ta_lab2/scripts/baseline/__init__.py
  - src/ta_lab2/scripts/baseline/comparison_utils.py
  - src/ta_lab2/scripts/baseline/metadata_tracker.py
autonomous: true

must_haves:
  truths:
    - "dim_assets table exists with CRYPTO assets from dim_sessions"
    - "Comparison utilities handle epsilon tolerance with hybrid bounds (rtol + atol)"
    - "Metadata tracker captures git hash, timestamp, config for reproducibility"
  artifacts:
    - path: "sql/ddl/create_dim_assets.sql"
      provides: "DDL for dim_assets table"
      contains: "CREATE TABLE"
    - path: "sql/baseline/.gitkeep"
      provides: "Directory structure for baseline SQL files"
    - path: "src/ta_lab2/scripts/baseline/comparison_utils.py"
      provides: "Epsilon-aware comparison functions"
      exports: ["compare_with_hybrid_tolerance", "summarize_comparison"]
    - path: "src/ta_lab2/scripts/baseline/metadata_tracker.py"
      provides: "Audit trail capture and serialization"
      exports: ["BaselineMetadata", "capture_metadata"]
  key_links:
    - from: "comparison_utils.py"
      to: "numpy.allclose"
      via: "rtol/atol tolerance formula"
      pattern: "np\\.isclose|rtol|atol"
    - from: "metadata_tracker.py"
      to: "git subprocess"
      via: "commit hash capture"
      pattern: "subprocess.*git.*rev-parse"
---

<objective>
Create infrastructure for baseline capture: dim_assets table, comparison utilities, and metadata tracking.

Purpose: Provide the foundational components needed by the main orchestration script (Plan 02) to snapshot, compare, and audit the baseline capture process.

Output: Three artifacts ready for Plan 02:
1. SQL DDL to create dim_assets table from dim_sessions WHERE asset_class = 'CRYPTO'
2. Python module with epsilon-aware comparison using NumPy allclose hybrid tolerance
3. Python module with metadata capture (git hash, timestamp, config) for reproducibility
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/25-baseline-capture/25-CONTEXT.md
@.planning/phases/25-baseline-capture/25-RESEARCH.md
@src/ta_lab2/scripts/emas/logging_config.py
@src/ta_lab2/scripts/bars/common_snapshot_contract.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create dim_assets DDL and sql/baseline directory</name>
  <files>sql/ddl/create_dim_assets.sql, sql/baseline/.gitkeep</files>
  <action>
1. Create `sql/baseline/` directory with .gitkeep file to ensure the directory exists for Plan 02's snapshot_template.sql.

2. Create SQL DDL file `sql/ddl/create_dim_assets.sql` that:
   - Creates `public.dim_assets` table from `dim_sessions` WHERE `asset_class = 'CRYPTO'`
   - Includes columns: id, asset_class, symbol (from dim_sessions)
   - Uses CREATE TABLE AS SELECT pattern (consistent with sql/snapshots/ examples)
   - Adds PRIMARY KEY on id
   - Includes IF NOT EXISTS guard for idempotence

Example pattern from existing codebase (sql/snapshots/20251213__bars_snapshots.sql):
```sql
CREATE TABLE IF NOT EXISTS public.dim_assets AS
SELECT DISTINCT id, asset_class, symbol
FROM public.dim_sessions
WHERE asset_class = 'CRYPTO'
ORDER BY id;

ALTER TABLE public.dim_assets
  ADD CONSTRAINT dim_assets_pkey PRIMARY KEY (id);
```

AVOID: Creating a full dim_assets migration - this is just a simple filter table for baseline capture scope.
  </action>
  <verify>test -d sql/baseline && cat sql/ddl/create_dim_assets.sql shows CREATE TABLE with CRYPTO filter</verify>
  <done>DDL file exists with correct pattern, sql/baseline directory exists, ready for Plan 02</done>
</task>

<task type="auto">
  <name>Task 2: Create comparison utilities module</name>
  <files>
src/ta_lab2/scripts/baseline/__init__.py
src/ta_lab2/scripts/baseline/comparison_utils.py
  </files>
  <action>
Create comparison utilities following Phase 25 RESEARCH.md Pattern 2 (Epsilon-Aware Comparison with Hybrid Bounds).

1. Create `src/ta_lab2/scripts/baseline/__init__.py` with module exports.

2. Create `src/ta_lab2/scripts/baseline/comparison_utils.py` with:

**Constants:**
```python
# From RESEARCH.md - column-specific tolerances
COLUMN_TOLERANCES = {
    "open": {"atol": 1e-6, "rtol": 1e-5},
    "high": {"atol": 1e-6, "rtol": 1e-5},
    "low": {"atol": 1e-6, "rtol": 1e-5},
    "close": {"atol": 1e-6, "rtol": 1e-5},
    "volume": {"atol": 1e-2, "rtol": 1e-4},
    "market_cap": {"atol": 1e-2, "rtol": 1e-4},
    "ema": {"atol": 1e-6, "rtol": 1e-5},
}
```

**Functions to implement:**

1. `compare_with_hybrid_tolerance(baseline_df, rebuilt_df, float_columns, rtol, atol)` -> pd.DataFrame
   - Uses NumPy `np.isclose()` with `equal_nan=True`
   - Returns DataFrame of mismatches (empty if all match)
   - Columns: id, tf, key columns, column_name, baseline_value, rebuilt_value, abs_diff, rel_diff, within_tolerance

2. `summarize_comparison(mismatch_df, total_rows)` -> dict
   - Returns: match_rate, mismatch_count, max_diff, mean_diff, std_diff, severity (CRITICAL/WARNING/INFO)
   - Severity per CONTEXT.md: CRITICAL (>1% diff), WARNING (>epsilon but <1%), INFO (expected)

3. `compare_tables(baseline_df, rebuilt_df, key_columns, float_columns, column_tolerances)` -> ComparisonResult
   - High-level function that merges on keys, compares all float columns
   - Returns ComparisonResult dataclass with passed (bool), summary (dict), mismatches (DataFrame)

**Pitfall avoidance (from RESEARCH.md):**
- Use `equal_nan=True` to treat NaN == NaN as match
- Handle columns with different tolerances (volume vs price)
- Never stop on first mismatch - collect ALL mismatches (CONTEXT.md requirement)

Follow existing code style from common_snapshot_contract.py (docstrings, type hints).
  </action>
  <verify>python -c "from ta_lab2.scripts.baseline.comparison_utils import compare_with_hybrid_tolerance, summarize_comparison; print('OK')"</verify>
  <done>Comparison module imports successfully, exports compare_with_hybrid_tolerance and summarize_comparison</done>
</task>

<task type="auto">
  <name>Task 3: Create metadata tracker module</name>
  <files>src/ta_lab2/scripts/baseline/metadata_tracker.py</files>
  <action>
Create metadata tracker following Phase 25 RESEARCH.md Pattern 4 (Metadata Capture for Reproducibility).

Implement:

1. `@dataclass BaselineMetadata` with fields:
   - capture_timestamp: str (ISO-8601 UTC)
   - git_commit_hash: str
   - git_branch: str
   - git_is_dirty: bool
   - asset_count: int
   - asset_ids: list[int]
   - date_range_start: str
   - date_range_end: str
   - bar_builders_invoked: list[str]
   - ema_refreshers_invoked: list[str]
   - db_url: str (redacted for logging)
   - snapshot_table_suffix: str
   - epsilon_rtol: float
   - epsilon_atol: float
   - sampling_strategy: dict

2. `to_dict(self) -> dict` method for JSON serialization

3. `capture_metadata(config) -> BaselineMetadata` function:
   - Uses subprocess to get git hash: `git rev-parse HEAD`
   - Uses subprocess to get branch: `git rev-parse --abbrev-ref HEAD`
   - Checks dirty status: `git diff --quiet` return code
   - Generates timestamp: `datetime.utcnow().strftime("%Y%m%d_%H%M%S")`
   - Redacts password from db_url: `.split("@")[-1]` for logging

4. `save_metadata(metadata, output_path)` function:
   - Saves metadata as JSON to output path
   - Used for audit trail

5. `@dataclass BaselineConfig` for configuration:
   - assets: list[int]
   - start_date: str
   - end_date: str
   - bar_scripts: list[str]
   - ema_scripts: list[str]
   - db_url: str
   - epsilon_rtol: float = 1e-5
   - epsilon_atol: float = 1e-8
   - sampling: dict = field(default_factory=dict)

Follow existing patterns from logging_config.py (imports, type hints, docstrings).
  </action>
  <verify>python -c "from ta_lab2.scripts.baseline.metadata_tracker import BaselineMetadata, capture_metadata; print('OK')"</verify>
  <done>Metadata module imports successfully, BaselineMetadata and capture_metadata available</done>
</task>

</tasks>

<verification>
1. SQL DDL file exists: `test -f sql/ddl/create_dim_assets.sql`
2. sql/baseline directory exists: `test -d sql/baseline`
3. Python module structure exists: `test -d src/ta_lab2/scripts/baseline`
4. All imports work: `python -c "from ta_lab2.scripts.baseline import comparison_utils, metadata_tracker; print('OK')"`
5. Comparison handles NaN correctly: Write quick test with np.nan values
</verification>

<success_criteria>
- dim_assets DDL file ready for database execution
- sql/baseline directory exists for Plan 02's snapshot_template.sql
- comparison_utils.py provides compare_with_hybrid_tolerance with NumPy allclose semantics
- metadata_tracker.py captures git hash, timestamp, and full audit trail
- All modules follow existing code style (type hints, docstrings)
- No new external dependencies (all using numpy, pandas, subprocess already in project)
</success_criteria>

<output>
After completion, create `.planning/phases/25-baseline-capture/25-01-SUMMARY.md`
</output>
