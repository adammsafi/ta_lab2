---
phase: 25-baseline-capture
plan: 02
type: execute
wave: 2
depends_on: ["25-01"]
files_modified:
  - src/ta_lab2/scripts/baseline/capture_baseline.py
  - sql/baseline/snapshot_template.sql
autonomous: true

must_haves:
  truths:
    - "Orchestration script runs full workflow: Snapshot -> Truncate -> Rebuild -> Compare"
    - "All 6 bar tables and all 6 EMA tables are included in the capture"
    - "Comparison report shows pass/fail with severity levels and statistics"
    - "Metadata captured and saved for reproducibility"
  artifacts:
    - path: "src/ta_lab2/scripts/baseline/capture_baseline.py"
      provides: "Main orchestration script for baseline capture"
      min_lines: 300
    - path: "sql/baseline/snapshot_template.sql"
      provides: "SQL template for creating timestamped snapshots"
      contains: "CREATE TABLE"
  key_links:
    - from: "capture_baseline.py"
      to: "run_all_bar_builders.py"
      via: "subprocess.run"
      pattern: "subprocess\\.run.*run_all_bar_builders"
    - from: "capture_baseline.py"
      to: "run_all_ema_refreshes.py"
      via: "subprocess.run"
      pattern: "subprocess\\.run.*run_all_ema_refreshes"
    - from: "capture_baseline.py"
      to: "comparison_utils.py"
      via: "import"
      pattern: "from.*comparison_utils import"
    - from: "capture_baseline.py"
      to: "metadata_tracker.py"
      via: "import"
      pattern: "from.*metadata_tracker import"
---

<objective>
Create the main orchestration script that implements the Snapshot -> Truncate -> Rebuild -> Compare workflow.

Purpose: Provide a single command that validates the entire bar/EMA pipeline by comparing pre-refactoring snapshots against rebuilt data, proving calculation correctness.

Output: `capture_baseline.py` script following Phase 23 orchestration patterns (subprocess isolation, dry-run, verbose, summary reporting) that:
1. Creates timestamped snapshots of all bar and EMA tables
2. Truncates the existing tables
3. Rebuilds bars then EMAs via subprocess
4. Compares snapshots to rebuilt tables with epsilon tolerance
5. Generates comprehensive report with pass/fail, severity, statistics
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/25-baseline-capture/25-CONTEXT.md
@.planning/phases/25-baseline-capture/25-RESEARCH.md
@.planning/phases/25-baseline-capture/25-01-SUMMARY.md
@src/ta_lab2/scripts/run_daily_refresh.py
@src/ta_lab2/scripts/emas/run_all_ema_refreshes.py
@src/ta_lab2/scripts/bars/run_all_bar_builders.py
@src/ta_lab2/scripts/emas/logging_config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SQL snapshot template</name>
  <files>sql/baseline/snapshot_template.sql</files>
  <action>
Create SQL template for timestamped snapshot creation in the sql/baseline/ directory (created by Plan 01). This is a reference template showing the pattern - the Python script will generate actual DDL dynamically.

Template contents:

```sql
-- =============================================================================
-- File: sql/baseline/snapshot_template.sql
-- Purpose: Template for baseline snapshot creation
-- Generated by: capture_baseline.py
-- =============================================================================

-- Tables to snapshot (each gets _snapshot_{YYYYMMDD_HHMMSS} suffix):
--
-- Bar tables (6 total):
--   - public.cmc_price_bars_1d
--   - public.cmc_price_bars_multi_tf
--   - public.cmc_price_bars_multi_tf_cal_iso
--   - public.cmc_price_bars_multi_tf_cal_us
--   - public.cmc_price_bars_multi_tf_cal_anchor_iso
--   - public.cmc_price_bars_multi_tf_cal_anchor_us
--
-- EMA tables (6 total):
--   - public.cmc_ema_multi_tf
--   - public.cmc_ema_multi_tf_v2
--   - public.cmc_ema_multi_tf_cal_us
--   - public.cmc_ema_multi_tf_cal_iso
--   - public.cmc_ema_multi_tf_cal_anchor_us
--   - public.cmc_ema_multi_tf_cal_anchor_iso

-- Example snapshot creation pattern:
-- CREATE TABLE public.cmc_price_bars_1d_snapshot_20260205_143022
-- AS SELECT * FROM public.cmc_price_bars_1d;

-- Example truncate pattern (after snapshot confirmed):
-- TRUNCATE TABLE public.cmc_price_bars_1d;

-- Snapshot primary key pattern (for efficient comparison):
-- ALTER TABLE public.cmc_price_bars_1d_snapshot_20260205_143022
--   ADD CONSTRAINT cmc_price_bars_1d_snapshot_20260205_143022_pkey
--   PRIMARY KEY (id, tf, bar_seq, time_close);

-- EMA table key pattern:
-- ALTER TABLE public.cmc_ema_multi_tf_snapshot_20260205_143022
--   ADD CONSTRAINT cmc_ema_multi_tf_snapshot_20260205_143022_pkey
--   PRIMARY KEY (id, tf, period, ts);
```

This documents the snapshot naming convention and provides the pattern for capture_baseline.py to follow.
  </action>
  <verify>cat sql/baseline/snapshot_template.sql shows template comments and all 12 tables (6 bar + 6 EMA)</verify>
  <done>Template file exists documenting snapshot patterns for all 12 tables</done>
</task>

<task type="auto">
  <name>Task 2: Create orchestration script</name>
  <files>src/ta_lab2/scripts/baseline/capture_baseline.py</files>
  <action>
Create main orchestration script following Phase 23 patterns (run_all_ema_refreshes.py, run_daily_refresh.py).

**CLI Interface:**
```
python capture_baseline.py --ids 1,52,825 [options]

Options:
  --ids             Comma-separated IDs or "all" (required)
  --db-url          Database URL (default: from config)
  --dry-run         Show commands without executing
  --verbose         Show subprocess output
  --skip-rebuild    Only snapshot + compare (don't truncate/rebuild)
  --output-dir      Output directory for logs/reports (default: .logs/baseline)
  --log-level       DEBUG, INFO, WARNING, ERROR
```

**Workflow implementation:**

1. **Phase 1: Snapshot**
   - Load asset IDs (from dim_assets or --ids)
   - Generate timestamp suffix: `YYYYMMDD_HHMMSS`
   - Create snapshot tables using CREATE TABLE AS SELECT
   - Add primary keys for efficient comparison
   - Log snapshot metadata

2. **Phase 2: Truncate (unless --skip-rebuild)**
   - TRUNCATE each table (bars first, then EMAs)
   - Confirm via COUNT(*) = 0

3. **Phase 3: Rebuild (unless --skip-rebuild)**
   - Run bar builders via subprocess (run_all_bar_builders.py)
   - Run EMA refreshers via subprocess (run_all_ema_refreshes.py)
   - Follow Phase 23 subprocess isolation pattern
   - Support --verbose passthrough
   - Capture success/failure + duration

4. **Phase 4: Compare**
   - Load snapshot samples (intelligent sampling per RESEARCH.md)
   - Load rebuilt table samples
   - Compare using comparison_utils.compare_with_hybrid_tolerance
   - Generate summary statistics per table per column

5. **Generate Report**
   - Overall pass/fail (all tables within tolerance = pass)
   - Per-table summary: match_rate, max_diff, severity
   - Top mismatches for investigation
   - Save to output_dir as JSON + log file

**Key implementation details:**

```python
# Tables to process - COMPLETE list from Phase 21 documentation
# 6 bar tables + 6 EMA tables = 12 total

BAR_TABLES = [
    "public.cmc_price_bars_1d",
    "public.cmc_price_bars_multi_tf",
    "public.cmc_price_bars_multi_tf_cal_iso",
    "public.cmc_price_bars_multi_tf_cal_us",
    "public.cmc_price_bars_multi_tf_cal_anchor_iso",
    "public.cmc_price_bars_multi_tf_cal_anchor_us",
]

# 6 EMA tables (multi_tf, v2, plus cal and cal_anchor each with us/iso variants)
EMA_TABLES = [
    "public.cmc_ema_multi_tf",
    "public.cmc_ema_multi_tf_v2",
    "public.cmc_ema_multi_tf_cal_us",
    "public.cmc_ema_multi_tf_cal_iso",
    "public.cmc_ema_multi_tf_cal_anchor_us",
    "public.cmc_ema_multi_tf_cal_anchor_iso",
]

# Bar table primary key columns (for comparison merge)
BAR_KEY_COLUMNS = ["id", "tf", "bar_seq", "time_close"]
BAR_FLOAT_COLUMNS = ["open", "high", "low", "close", "volume", "market_cap"]

# EMA table primary key columns
EMA_KEY_COLUMNS = ["id", "tf", "period", "ts"]
EMA_FLOAT_COLUMNS = ["ema"]
```

**Subprocess execution (following Phase 23 pattern):**
```python
def run_bar_builders(ids: str, db_url: str, verbose: bool, dry_run: bool) -> dict:
    script_dir = Path(__file__).parent.parent / "bars"
    cmd = [
        sys.executable,
        str(script_dir / "run_all_bar_builders.py"),
        "--ids", ids,
        "--db-url", db_url,
    ]
    if verbose:
        cmd.append("--verbose")

    if dry_run:
        print(f"[DRY RUN] {' '.join(cmd)}")
        return {"success": True, "duration_sec": 0.0}

    # Execute with Phase 23 pattern
    start = time.perf_counter()
    result = subprocess.run(cmd, check=False, capture_output=not verbose, text=True)
    duration = time.perf_counter() - start

    return {
        "success": result.returncode == 0,
        "duration_sec": duration,
        "returncode": result.returncode,
    }
```

**Failure handling per CONTEXT.md:** Always run to completion, report only (never fail early).

Use existing infrastructure:
- logging_config.py for logging setup
- common_snapshot_contract.py utilities where applicable
- metadata_tracker.py for audit trail
- comparison_utils.py for epsilon comparison
  </action>
  <verify>python src/ta_lab2/scripts/baseline/capture_baseline.py --help shows CLI options</verify>
  <done>Script runs with --help, shows workflow options, follows Phase 23 patterns</done>
</task>

<task type="auto">
  <name>Task 3: Add sampling utilities to capture script</name>
  <files>src/ta_lab2/scripts/baseline/capture_baseline.py</files>
  <action>
Extend capture_baseline.py with intelligent sampling utilities per RESEARCH.md Pattern 3.

Add functions:

1. `sample_table_for_comparison(engine, table_name, asset_ids, sample_config) -> pd.DataFrame`
   - Parameters: beginning_days=30, end_days=30, random_sample_pct=0.05
   - Strategy:
     a. Get min/max timestamp per asset from table
     b. Sample first N days (beginning focus)
     c. Sample last N days (end focus)
     d. Stratified random sample from interior (5% default)
   - Returns combined DataFrame preserving temporal order

2. `execute_comparison(engine, snapshot_table, rebuilt_table, key_columns, float_columns, sample_config) -> dict`
   - Sample both snapshot and rebuilt tables
   - Merge on key columns
   - Compare float columns with hybrid tolerance
   - Return comparison summary

SQL for intelligent sampling:
```sql
-- Beginning sample (first 30 days per asset)
SELECT * FROM {table}
WHERE id = ANY(:ids)
  AND timestamp <= (
    SELECT MIN(timestamp) + INTERVAL '30 days'
    FROM {table}
    WHERE id = ANY(:ids)
  )
ORDER BY id, timestamp;

-- End sample (last 30 days per asset)
SELECT * FROM {table}
WHERE id = ANY(:ids)
  AND timestamp >= (
    SELECT MAX(timestamp) - INTERVAL '30 days'
    FROM {table}
    WHERE id = ANY(:ids)
  )
ORDER BY id, timestamp;

-- Random interior sample (5% stratified)
SELECT * FROM {table}
WHERE id = ANY(:ids)
  AND random() < 0.05
  AND timestamp > (SELECT MIN(timestamp) + INTERVAL '30 days' FROM {table} WHERE id = ANY(:ids))
  AND timestamp < (SELECT MAX(timestamp) - INTERVAL '30 days' FROM {table} WHERE id = ANY(:ids))
ORDER BY id, timestamp;
```

Also add:
- Update __init__.py exports if needed
- Add --sample-beginning, --sample-end, --sample-random-pct CLI options
- Default to intelligent sampling (not full comparison)
  </action>
  <verify>python src/ta_lab2/scripts/baseline/capture_baseline.py --dry-run --ids 1 shows sampling config in output</verify>
  <done>Sampling utilities integrated, CLI shows sampling parameters</done>
</task>

</tasks>

<verification>
1. Script runs: `python src/ta_lab2/scripts/baseline/capture_baseline.py --help`
2. Dry-run shows workflow: `python src/ta_lab2/scripts/baseline/capture_baseline.py --dry-run --ids 1`
3. All imports work: `python -c "from ta_lab2.scripts.baseline.capture_baseline import main; print('OK')"`
4. SQL template exists: `test -f sql/baseline/snapshot_template.sql`
5. Template lists all 12 tables: `grep -c "cmc_" sql/baseline/snapshot_template.sql` shows 12+ matches
</verification>

<success_criteria>
- capture_baseline.py runs with --help and shows CLI options
- --dry-run shows the Snapshot -> Truncate -> Rebuild -> Compare workflow steps
- Script handles all 6 bar tables and all 6 EMA tables (12 total)
- Script imports comparison_utils and metadata_tracker from Plan 01
- Subprocess calls follow Phase 23 pattern (isolation, summary reporting)
- Intelligent sampling implemented per RESEARCH.md
- Never fails early - always runs to completion and reports all issues
- Output includes pass/fail summary with severity levels
</success_criteria>

<output>
After completion, create `.planning/phases/25-baseline-capture/25-02-SUMMARY.md`
</output>
