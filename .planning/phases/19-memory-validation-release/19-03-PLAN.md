---
phase: 19-memory-validation-release
plan: 03
type: execute
wave: 2
depends_on: [19-01]
files_modified:
  - src/ta_lab2/tools/ai_orchestrator/memory/similarity.py
  - src/ta_lab2/tools/ai_orchestrator/memory/__init__.py
autonomous: true

must_haves:
  truths:
    - "Duplicate detection uses difflib.SequenceMatcher with three tiers"
    - "95%+ similarity = exact duplicates (flagged for consolidation)"
    - "85-95% similarity = very similar (flagged for review)"
    - "70-85% similarity = related (informational only)"
    - "Canonical version recommendation provided for 95%+ duplicates"
  artifacts:
    - path: "src/ta_lab2/tools/ai_orchestrator/memory/similarity.py"
      provides: "Duplicate detection with three-tier thresholds"
      exports: ["SimilarityResult", "DuplicateReport", "compute_similarity", "detect_duplicates", "suggest_canonical"]
  key_links:
    - from: "similarity.py"
      to: "indexing.py"
      via: "uses extracted function source"
      pattern: "from .indexing import"
    - from: "similarity.py"
      to: "relationships.py"
      via: "creates similar_to relationships"
      pattern: "RelationshipType.SIMILAR_TO"
---

<objective>
Create duplicate detection with three-tier similarity thresholds

Purpose: Detect duplicate/similar functions using difflib.SequenceMatcher with three tiers (95%+, 85-95%, 70-85%) per CONTEXT.md decisions. 95%+ duplicates get full treatment: flag for consolidation, add similar_to relationship, and suggest canonical version.

Output: similarity.py module with DuplicateReport and canonical version suggestion
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-memory-validation-release/19-CONTEXT.md
@.planning/phases/19-memory-validation-release/19-RESEARCH.md

# Function extraction from Plan 19-01
@src/ta_lab2/tools/ai_orchestrator/memory/indexing.py
@src/ta_lab2/tools/ai_orchestrator/memory/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create similarity detection module with three tiers</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/similarity.py</files>
  <action>
Create similarity.py following the research patterns:

```python
"""Duplicate detection with three-tier similarity thresholds.

Detects duplicate/similar functions using difflib.SequenceMatcher:
- 95%+ (exact): Flag for consolidation, recommend canonical version
- 85-95% (very_similar): Flag for review, assess if variation meaningful
- 70-85% (related): Document in appendix, informational only

Usage:
    from ta_lab2.tools.ai_orchestrator.memory.similarity import (
        detect_duplicates,
        suggest_canonical
    )

    # Detect duplicates across extracted functions
    report = detect_duplicates(functions)
    print(report.markdown_summary())

    # Get canonical version suggestion for exact duplicates
    for dup in report.exact_duplicates:
        suggestion = suggest_canonical(dup.func_a, dup.func_b)
"""
```

1. **SimilarityTier enum:**
   - EXACT = "exact"  # 95%+
   - VERY_SIMILAR = "very_similar"  # 85-95%
   - RELATED = "related"  # 70-85%

2. **SimilarityResult dataclass:**
   - func_a_name: str
   - func_a_file: str
   - func_a_lineno: int
   - func_b_name: str
   - func_b_file: str
   - func_b_lineno: int
   - similarity: float
   - tier: SimilarityTier
   - func_a_source: str (for canonical suggestion)
   - func_b_source: str

3. **compute_similarity(source_a: str, source_b: str) -> float:**
   - Use difflib.SequenceMatcher(None, source_a, source_b).ratio()
   - Return float in [0, 1]

4. **classify_tier(similarity: float) -> Optional[SimilarityTier]:**
   - >= 0.95: EXACT
   - >= 0.85: VERY_SIMILAR
   - >= 0.70: RELATED
   - < 0.70: None (not similar enough)

5. **CanonicalSuggestion dataclass:**
   - canonical_file: str
   - canonical_function: str
   - reason: str (e.g., "more docstring", "more type hints", "in core module")
   - remove_file: str
   - remove_function: str
   - confidence: str ("high", "medium", "low")

6. **suggest_canonical(result: SimilarityResult) -> CanonicalSuggestion:**
   Heuristics for determining canonical version:
   - Prefer function WITH docstring over without
   - Prefer function WITH type hints over without
   - Prefer function in src/ over tests/
   - Prefer function in core modules (features/, signals/) over utils/scripts/
   - Prefer shorter file path (less deeply nested)
   - Prefer alphabetically first if all else equal
   Return suggestion with reason and confidence

7. **DuplicateReport dataclass:**
   - exact_duplicates: List[SimilarityResult]  # 95%+
   - very_similar: List[SimilarityResult]  # 85-95%
   - related: List[SimilarityResult]  # 70-85%
   - canonical_suggestions: List[CanonicalSuggestion]  # for 95%+ only
   - comparison_count: int  # total pairs compared
   - duration_seconds: float

   Methods:
   - markdown_summary() -> str: Generate markdown for VALIDATION.md
   - _format_tier(pairs, limit=None) -> str: Format as markdown table

8. **detect_duplicates(functions: List[FunctionInfo], min_threshold: float = 0.70) -> DuplicateReport:**
   - Compare all function pairs (N*(N-1)/2 comparisons)
   - Use function source for comparison
   - Classify by tier
   - Generate canonical suggestions for exact duplicates
   - Track timing for performance metrics
   - Skip comparing function to itself
   - Skip very short functions (< 3 lines) to avoid false positives

Use only stdlib (difflib, dataclasses, typing, enum, time).
  </action>
  <verify>
`python -c "from ta_lab2.tools.ai_orchestrator.memory.similarity import detect_duplicates, SimilarityTier; print('Import OK')"`
  </verify>
  <done>Similarity detection module created with three tiers and canonical suggestions</done>
</task>

<task type="auto">
  <name>Task 2: Add similarity exports to memory __init__.py</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/__init__.py</files>
  <action>
Add similarity module exports to memory package __init__.py:

1. Add import after relationships imports:
   ```python
   from .similarity import (
       SimilarityTier,
       SimilarityResult,
       CanonicalSuggestion,
       DuplicateReport,
       compute_similarity,
       detect_duplicates,
       suggest_canonical,
   )
   ```

2. Add to __all__ list in "# Similarity" section:
   ```python
   # Similarity
   "SimilarityTier",
   "SimilarityResult",
   "CanonicalSuggestion",
   "DuplicateReport",
   "compute_similarity",
   "detect_duplicates",
   "suggest_canonical",
   ```

3. Update module docstring to mention duplicate detection capability
  </action>
  <verify>
`python -c "from ta_lab2.tools.ai_orchestrator.memory import detect_duplicates, DuplicateReport; print('Package exports OK')"`
  </verify>
  <done>similarity module exports available from memory package</done>
</task>

<task type="auto">
  <name>Task 3: Validate duplicate detection on sample functions</name>
  <files>src/ta_lab2/tools/ai_orchestrator/memory/similarity.py</files>
  <action>
Add validation at module level (guarded by __name__ == "__main__"):

```python
if __name__ == "__main__":
    from pathlib import Path
    from .indexing import extract_functions

    # Test similarity computation
    source_a = '''def foo(x: int) -> int:
    """Return x squared."""
    return x * x
'''
    source_b = '''def bar(x: int) -> int:
    """Return x squared."""
    return x * x
'''
    source_c = '''def baz(x: int) -> int:
    """Return x cubed."""
    return x * x * x
'''

    print("Similarity tests:")
    print(f"  foo vs bar (identical logic): {compute_similarity(source_a, source_b):.2%}")
    print(f"  foo vs baz (different logic): {compute_similarity(source_a, source_c):.2%}")

    # Test on actual codebase (memory module)
    memory_dir = Path(__file__).parent
    all_functions = []
    for py_file in memory_dir.glob("*.py"):
        all_functions.extend(extract_functions(py_file))

    print(f"\nAnalyzing {len(all_functions)} functions from memory module...")
    report = detect_duplicates(all_functions)

    print(f"\nDuplicate Detection Report:")
    print(f"  Comparisons: {report.comparison_count}")
    print(f"  Duration: {report.duration_seconds:.2f}s")
    print(f"  Exact duplicates (95%+): {len(report.exact_duplicates)}")
    print(f"  Very similar (85-95%): {len(report.very_similar)}")
    print(f"  Related (70-85%): {len(report.related)}")

    if report.exact_duplicates:
        print("\n  Exact duplicates found:")
        for dup in report.exact_duplicates[:3]:
            print(f"    - {dup.func_a_name} <-> {dup.func_b_name}: {dup.similarity:.1%}")
```

This validates:
- compute_similarity() returns expected ratios
- detect_duplicates() processes function list correctly
- Three-tier classification works
- markdown_summary() generates valid markdown
  </action>
  <verify>
`python -m ta_lab2.tools.ai_orchestrator.memory.similarity` runs and shows similarity analysis
  </verify>
  <done>Duplicate detection validated with three-tier thresholds working correctly</done>
</task>

</tasks>

<verification>
1. `python -c "from ta_lab2.tools.ai_orchestrator.memory.similarity import detect_duplicates; print('OK')"` passes
2. `python -c "from ta_lab2.tools.ai_orchestrator.memory import DuplicateReport; print('OK')"` passes
3. `python -m ta_lab2.tools.ai_orchestrator.memory.similarity` shows correct tier classification
4. Three tiers correctly classified (95%+, 85-95%, 70-85%)
5. suggest_canonical() provides reasonable recommendations
</verification>

<success_criteria>
- compute_similarity() uses difflib.SequenceMatcher correctly
- Three tiers implemented with correct thresholds
- suggest_canonical() recommends which version to keep for 95%+ duplicates
- DuplicateReport.markdown_summary() generates VALIDATION.md-ready output
- No new dependencies (stdlib only: difflib, dataclasses, typing, enum, time)
</success_criteria>

<output>
After completion, create `.planning/phases/19-memory-validation-release/19-03-SUMMARY.md`
</output>
