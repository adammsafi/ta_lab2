---
phase: 13-documentation-consolidation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/ta_lab2/tools/docs/discover_projecttt.py
  - .planning/phases/13-documentation-consolidation/projecttt_inventory.json
autonomous: true

must_haves:
  truths:
    - "Complete inventory of ProjectTT documents exists"
    - "Documents are categorized by content type"
    - "Conversion priority is determined"
  artifacts:
    - path: "src/ta_lab2/tools/docs/discover_projecttt.py"
      provides: "Discovery script for ProjectTT analysis"
      exports: ["discover_projecttt", "categorize_documents"]
    - path: ".planning/phases/13-documentation-consolidation/projecttt_inventory.json"
      provides: "Complete document inventory with categories"
      contains: "files"
  key_links:
    - from: "discover_projecttt.py"
      to: "C:/Users/asafi/Documents/ProjectTT"
      via: "pathlib.rglob"
      pattern: "rglob.*\\.(docx|xlsx)"
---

<objective>
Discover and categorize all ProjectTT documents for conversion planning.

Purpose: Create a complete inventory of .docx and .xlsx files with size, location, and content category. This enables efficient batch conversion and accurate memory tracking.
Output: Discovery script and projecttt_inventory.json with categorized document list
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-documentation-consolidation/13-CONTEXT.md
@.planning/phases/13-documentation-consolidation/13-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ProjectTT discovery script</name>
  <files>src/ta_lab2/tools/docs/discover_projecttt.py</files>
  <action>
Create discovery script to inventory and categorize ProjectTT documents.

1. Create discover_projecttt.py implementing:

   @dataclass
   class DocumentInfo:
       path: Path
       name: str
       size_bytes: int
       extension: str
       subdirectory: str  # Features, Foundational, Plans&Status, root
       category: str  # architecture, features, planning, development
       priority: int  # 1=high, 2=medium, 3=low (based on size/importance)
       has_txt_version: bool  # Some already have .txt conversions

   - discover_projecttt(root_path: Path = None) -> list[DocumentInfo]
     - Default root: C:/Users/asafi/Documents/ProjectTT
     - Find all .docx and .xlsx files (excluding ~$* temp files)
     - Extract subdirectory info
     - Check for existing .txt versions
     - Return sorted list (by priority, then path)

   - categorize_document(doc_path: Path, subdirectory: str) -> str
     - Foundational/* -> "architecture" (CoreComponents, KeyTerms, GenesisFiles, TimeFrames)
     - Features/EMAs/* -> "features/emas"
     - Features/Bars/* -> "features/bars"
     - Features/Memory/* -> "features/memory"
     - Plans&Status/* -> "planning"
     - Root level Excel (Schemas, EMA Study) -> "architecture"
     - Root level workspace doc -> "architecture"
     - Other root level -> "reference"

   - determine_priority(doc_path: Path, size_bytes: int) -> int
     - Priority 1: >100KB or key docs (Workspace, Schemas, KeyTerms, CoreComponents)
     - Priority 2: 20KB-100KB or feature-specific docs
     - Priority 3: <20KB or status/temp docs

   - generate_inventory_report(docs: list[DocumentInfo]) -> dict
     - Return JSON-serializable inventory with:
       - total_files, total_size_bytes
       - by_category: {category: [docs]}
       - by_priority: {1: [docs], 2: [docs], 3: [docs]}
       - conversion_order: list of paths sorted by priority

2. Add to __init__.py exports
  </action>
  <verify>
    python -c "from ta_lab2.tools.docs.discover_projecttt import discover_projecttt; docs = discover_projecttt(); print(f'Found {len(docs)} documents')"
  </verify>
  <done>
    - discover_projecttt.py created with DocumentInfo dataclass
    - Discovery functions find all ProjectTT documents
    - Categorization rules implemented per CONTEXT.md
  </done>
</task>

<task type="auto">
  <name>Task 2: Generate ProjectTT inventory</name>
  <files>.planning/phases/13-documentation-consolidation/projecttt_inventory.json</files>
  <action>
Run discovery and save inventory to JSON.

1. Execute discovery script:
   python -c "
   from ta_lab2.tools.docs.discover_projecttt import discover_projecttt, generate_inventory_report
   import json
   from pathlib import Path

   docs = discover_projecttt()
   inventory = generate_inventory_report(docs)
   output_path = Path('.planning/phases/13-documentation-consolidation/projecttt_inventory.json')
   output_path.write_text(json.dumps(inventory, indent=2, default=str))
   print(f'Inventory saved: {len(docs)} documents')
   "

2. Verify inventory structure:
   - Contains total_files (expected: ~45-50)
   - Contains by_category breakdown
   - Contains conversion_order list
   - All paths are valid

3. Log summary:
   - Total .docx files
   - Total .xlsx files
   - Files by category
   - Files by priority
   - Estimated conversion effort (count * ~2 min each)
  </action>
  <verify>
    python -c "import json; inv = json.loads(open('.planning/phases/13-documentation-consolidation/projecttt_inventory.json').read()); print(f'Total: {inv[\"total_files\"]} files')"
  </verify>
  <done>
    - projecttt_inventory.json created with complete document list
    - Inventory includes categories, priorities, and conversion order
    - File counts match actual ProjectTT content
  </done>
</task>

</tasks>

<verification>
All verification commands must pass:

```bash
# Module imports
python -c "from ta_lab2.tools.docs.discover_projecttt import discover_projecttt, categorize_document"

# Inventory exists and valid
python -c "import json; inv = json.loads(open('.planning/phases/13-documentation-consolidation/projecttt_inventory.json').read()); assert 'total_files' in inv; assert 'by_category' in inv"

# Discovery finds expected file count (should be 40-50)
python -c "from ta_lab2.tools.docs.discover_projecttt import discover_projecttt; docs = discover_projecttt(); assert len(docs) >= 30, f'Expected 30+ docs, got {len(docs)}'"
```
</verification>

<success_criteria>
- [ ] discover_projecttt.py module created with discovery functions
- [ ] DocumentInfo dataclass captures all relevant metadata
- [ ] Categorization rules match CONTEXT.md categories
- [ ] projecttt_inventory.json saved with complete inventory
- [ ] Inventory includes all .docx and .xlsx files (excluding temp ~$* files)
- [ ] Files categorized into architecture, features, planning, reference
</success_criteria>

<output>
After completion, create `.planning/phases/13-documentation-consolidation/13-02-SUMMARY.md`
</output>
