---
phase: 13-documentation-consolidation
plan: 03
type: execute
wave: 2
depends_on: [13-01, 13-02]
files_modified:
  - docs/architecture/*.md
  - docs/features/**/*.md
  - docs/planning/*.md
  - docs/reference/*.md
  - docs/assets/**/*
autonomous: true

must_haves:
  truths:
    - "All ProjectTT .docx files converted to Markdown"
    - "Markdown files have YAML front matter with original metadata"
    - "Images extracted to docs/assets/"
    - "Files organized by content category"
  artifacts:
    - path: "docs/architecture/"
      provides: "Architecture documentation from Foundational/"
      min_lines: 100
    - path: "docs/features/"
      provides: "Feature documentation from Features/"
      min_lines: 50
    - path: "docs/planning/"
      provides: "Planning documentation from Plans&Status/"
      min_lines: 50
  key_links:
    - from: "docs/**/*.md"
      to: "YAML front matter"
      via: "metadata header"
      pattern: "^---\\n.*original_path"
---

<objective>
Convert all ProjectTT Word documents (.docx) to Markdown with YAML front matter.

Purpose: Transform ProjectTT documentation into navigable Markdown format integrated with ta_lab2's docs/ structure. Each converted document preserves original metadata and extracted images.
Output: Markdown files in docs/architecture/, docs/features/, docs/planning/, docs/reference/
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-documentation-consolidation/13-CONTEXT.md
@.planning/phases/13-documentation-consolidation/13-RESEARCH.md

# Prior plan outputs
@.planning/phases/13-documentation-consolidation/13-01-SUMMARY.md
@.planning/phases/13-documentation-consolidation/13-02-SUMMARY.md
@.planning/phases/13-documentation-consolidation/projecttt_inventory.json

# Conversion utilities
@src/ta_lab2/tools/docs/convert_docx.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create docs/ directory structure</name>
  <files>docs/architecture/.gitkeep, docs/features/emas/.gitkeep, docs/features/bars/.gitkeep, docs/features/memory/.gitkeep, docs/planning/.gitkeep, docs/reference/.gitkeep, docs/assets/.gitkeep</files>
  <action>
Create category directories in docs/ for converted documents.

1. Create directory structure:
   docs/
   ├── architecture/      # CoreComponents, KeyTerms, Workspace, Schemas docs
   ├── features/
   │   ├── emas/         # EMA-specific documentation
   │   ├── bars/         # Bar processing documentation
   │   └── memory/       # Memory system documentation
   ├── planning/         # Plans, status, roadmaps from Plans&Status/
   ├── reference/        # Reference materials, miscellaneous docs
   └── assets/           # Extracted images from converted documents

2. Add .gitkeep to empty directories

3. Do NOT modify existing docs/ content (index.md, DESIGN.md, deployment.md, etc.)
  </action>
  <verify>
    ls docs/architecture docs/features/emas docs/features/bars docs/features/memory docs/planning docs/reference docs/assets
  </verify>
  <done>
    - All category directories created under docs/
    - Feature subdirectories created (emas, bars, memory)
    - Existing docs/ content preserved
  </done>
</task>

<task type="auto">
  <name>Task 2: Convert DOCX files to Markdown</name>
  <files>docs/architecture/*.md, docs/features/**/*.md, docs/planning/*.md, docs/reference/*.md</files>
  <action>
Convert all ProjectTT .docx files using convert_docx_to_markdown.

NOTE: ~27 files to convert. Use checkpointing approach - log progress after each
file so partial failures don't lose work.

1. Load inventory from projecttt_inventory.json

2. Create batch conversion with progress tracking:
   - Filter for .docx files only
   - Sort by priority (priority 1 first)
   - Map categories to output directories:
     - "architecture" -> docs/architecture/
     - "features/emas" -> docs/features/emas/
     - "features/bars" -> docs/features/bars/
     - "features/memory" -> docs/features/memory/
     - "planning" -> docs/planning/
     - "reference" -> docs/reference/

3. For each document (with progress logging):
   - Log: "[{n}/{total}] Converting: {input_file}"
   - Generate output filename: lowercase, hyphens, no special chars
     - "CoreComponents.docx" -> "core-components.md"
     - "ta_lab2 Workspace v.1.1.docx" -> "workspace-v1.1.md"
   - Convert using convert_docx_to_markdown()
   - Extract images to docs/assets/{document-name}/
   - Log: "[{n}/{total}] Complete: {output_file}"
   - Write checkpoint file every 5 documents:
     docs/conversion_checkpoint.json with list of completed files

4. Handle conversion issues:
   - If conversion fails, log error and continue (don't fail batch)
   - Track failed conversions in conversion_errors.json for manual review
   - Large files (>200KB) may take longer - log progress

5. Key documents to prioritize:
   - ta_lab2 Workspace v.1.1.docx (363KB) - main architecture doc
   - CoreComponents.docx - foundational concepts
   - KeyTerms.docx - terminology definitions
   - Schemas_20260114.xlsx (will be Plan 04, but note here)

Expected conversions (~27 .docx files):
- Foundational/: 12 docs -> docs/architecture/
- Plans&Status/: 10 docs -> docs/planning/
- Features/: ~3 docs -> docs/features/
- Root: 2 docs -> docs/architecture/
  </action>
  <verify>
    # Count converted files
    python -c "from pathlib import Path; md_files = list(Path('docs').rglob('*.md')); print(f'Found {len(md_files)} markdown files in docs/')"

    # Validate YAML front matter present (check core-components.md)
    head -10 docs/architecture/core-components.md | grep "^---"

    # Validate original_path in YAML front matter
    head -15 docs/architecture/core-components.md | grep "original_path"

    # Spot check 3 random converted files for YAML
    python -c "
from pathlib import Path
import random
md_files = [f for f in Path('docs').rglob('*.md') if f.name not in ['index.md', 'DESIGN.md', 'deployment.md']]
sample = random.sample(md_files, min(3, len(md_files)))
for f in sample:
    content = f.read_text()[:200]
    has_yaml = content.startswith('---') and 'original_path' in content
    print(f'{f.name}: YAML={has_yaml}')
"
  </verify>
  <done>
    - All .docx files converted to Markdown
    - YAML front matter includes original_path, author, created metadata
    - Images extracted to docs/assets/
    - Files organized by category
    - Conversion log shows success/failure counts with progress checkpoints
  </done>
</task>

</tasks>

<verification>
All verification commands must pass:

```bash
# Directory structure exists
ls docs/architecture docs/features docs/planning docs/reference docs/assets

# Converted files exist
ls docs/architecture/*.md docs/planning/*.md

# YAML front matter present AND contains original_path (quality check)
head -20 docs/architecture/core-components.md | grep -A10 "^---" | grep "original_path"

# Validate multiple files have proper YAML front matter
python -c "
from pathlib import Path
converted = [f for f in Path('docs').rglob('*.md') if f.name not in ['index.md', 'DESIGN.md', 'deployment.md']]
valid = 0
for f in converted:
    content = f.read_text()
    if content.startswith('---') and 'original_path' in content[:500]:
        valid += 1
print(f'{valid}/{len(converted)} files have valid YAML front matter')
assert valid >= len(converted) * 0.9, 'Less than 90% have valid YAML'
"
```
</verification>

<success_criteria>
- [ ] docs/ directory structure created with all categories
- [ ] All ProjectTT .docx files converted (25+ files)
- [ ] Each converted file has YAML front matter with original_path, author, created
- [ ] At least 90% of converted files pass YAML front matter validation
- [ ] Images extracted to docs/assets/{document}/ directories
- [ ] Files named with lowercase-hyphen convention
- [ ] No existing docs/ content modified (index.md, DESIGN.md preserved)
</success_criteria>

<output>
After completion, create `.planning/phases/13-documentation-consolidation/13-03-SUMMARY.md`
</output>
