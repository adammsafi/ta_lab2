---
phase: 06-ta-lab2-time-model
plan: 04
type: execute
wave: 2
depends_on:
  - "06-01"
files_modified:
  - tests/time/test_time_alignment.py
  - tests/time/test_dst_handling.py
autonomous: true

must_haves:
  truths:
    - "TF window calculations produce correct day counts"
    - "Calendar roll dates align to expected boundaries (EOM, EOQ)"
    - "DST transitions don't create duplicate or missing timestamps"
    - "Session boundaries convert correctly between local and UTC"
  artifacts:
    - path: "tests/time/test_time_alignment.py"
      provides: "Time alignment validation tests (TF windows, calendar rolls)"
      min_lines: 80
    - path: "tests/time/test_dst_handling.py"
      provides: "DST transition validation tests"
      min_lines: 50
  key_links:
    - from: "tests/time/test_time_alignment.py"
      to: "src/ta_lab2/time/dim_timeframe.py"
      via: "Uses TFMeta bounds validation"
      pattern: "realized_tf_days_ok|tf_days_bounds"
    - from: "tests/time/test_dst_handling.py"
      to: "src/ta_lab2/time/dim_sessions.py"
      via: "Uses session_windows_utc_by_key"
      pattern: "session_windows_utc"
---

<objective>
Create time alignment and DST validation tests

Purpose: Build test suite for SUCCESS CRITERION #5 - Time alignment validation tests pass (TF windows, calendar rolls, session boundaries). Cover the error types identified in CONTEXT.md: off-by-one, calendar roll misalignment, session boundary violations, DST bugs.

Output: Comprehensive validation test suite for time calculations
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-ta-lab2-time-model/06-CONTEXT.md
@.planning/phases/06-ta-lab2-time-model/06-RESEARCH.md

# Time infrastructure
@src/ta_lab2/time/dim_timeframe.py
@src/ta_lab2/time/dim_sessions.py

# Existing DST test (reference pattern)
@tests/test_sessions_dst.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create time alignment validation tests</name>
  <files>tests/time/test_time_alignment.py</files>
  <action>
Create tests/time/test_time_alignment.py with TF and calendar alignment tests:

**TF Day Count Tests:**
1. **test_1d_tf_days_nominal** - Verify 1D has tf_days_nominal=1
2. **test_7d_tf_days_nominal** - Verify 7D has tf_days_nominal=7
3. **test_30d_tf_days_nominal** - Verify 30D has tf_days_nominal=30

**TF Bounds Validation Tests:**
4. **test_realized_tf_days_ok_exact** - realized_tf_days_ok("1D", 1) returns True
5. **test_realized_tf_days_ok_within_bounds** - For TFs with bounds, values within bounds return True
6. **test_realized_tf_days_ok_out_of_bounds** - Values outside bounds return False

**Calendar Alignment Tests:**
7. **test_calendar_tf_has_anchor** - TFs with alignment_type="calendar" have calendar_anchor set (e.g., "EOM", "EOQ")
8. **test_tf_day_tf_no_anchor** - TFs with alignment_type="tf_day" have calendar_anchor=None

**Alignment Type Distribution:**
9. **test_alignment_types_coverage** - Query dim_timeframe and verify both "tf_day" and "calendar" alignment_types exist

**Off-by-One Edge Cases:**
10. **test_tf_days_min_max_relationship** - For all TFs with bounds, verify tf_days_min <= tf_days_nominal <= tf_days_max (or all None)

Use pytest fixtures for db_url. Skip gracefully if no database. Use DimTimeframe.from_db() for data access.
  </action>
  <verify>
pytest tests/time/test_time_alignment.py -v passes all 10 tests
  </verify>
  <done>
10 time alignment tests covering TF day counts, bounds validation, and calendar anchors
  </done>
</task>

<task type="auto">
  <name>Task 2: Create DST handling validation tests</name>
  <files>tests/time/test_dst_handling.py</files>
  <action>
Create tests/time/test_dst_handling.py with DST transition tests:

**Basic DST Tests (extend existing test_sessions_dst.py pattern):**
1. **test_ny_winter_offset** - NY 9:30 local in January = 14:30 UTC (EST = UTC-5)
2. **test_ny_summer_offset** - NY 9:30 local in July = 13:30 UTC (EDT = UTC-4)
3. **test_spring_forward_transition** - Test March DST transition day (US spring forward)
4. **test_fall_back_transition** - Test November DST transition day (US fall back)

**Database Session Window Tests (requires TARGET_DB_URL):**
5. **test_session_windows_span_dst** - Call session_windows_utc_by_key spanning March 8-12, verify no duplicate dates and no missing dates
6. **test_session_windows_december_january** - Call across year boundary, verify correct handling
7. **test_crypto_session_no_dst** - Crypto 24h sessions should have consistent UTC times (no DST shift)

**Timezone Validation:**
8. **test_iana_timezone_parsing** - Verify ZoneInfo parses all timezones in dim_sessions (no ValueError)
9. **test_no_numeric_offsets** - Query dim_sessions and verify no timezone values match pattern r'^[+-]\d+' (no numeric offsets)

**Edge Cases:**
10. **test_leap_year_feb29** - Verify session window for 2024-02-29 (leap year) works correctly

Use zoneinfo.ZoneInfo for timezone handling. Use pytest.mark.skipif for tests requiring database.
  </action>
  <verify>
pytest tests/time/test_dst_handling.py -v passes all 10 tests
  </verify>
  <done>
10 DST handling tests covering transitions, session windows, and timezone validation
  </done>
</task>

</tasks>

<verification>
1. pytest tests/time/test_time_alignment.py tests/time/test_dst_handling.py -v
2. All 20 tests pass (or skip gracefully if no database for DB-dependent tests)
3. Tests cover all 4 error types from CONTEXT.md: off-by-one, calendar roll, session boundary, DST
</verification>

<success_criteria>
- 10 time alignment tests validating TF windows and calendar rolls
- 10 DST handling tests covering transitions and session boundaries
- Tests use actual dim_timeframe and dim_sessions data
- Edge cases covered: DST transitions, leap year, year boundary
- SUCCESS CRITERION #5 satisfied: validation tests for time alignment
</success_criteria>

<output>
After completion, create `.planning/phases/06-ta-lab2-time-model/06-04-SUMMARY.md`
</output>
